{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Master Profile Notebook\n",
        "This notebook combines all the profiling experiments we have done so far into one notebook: uses the optimal hyperparameters, knowledge distillation, trains using AMP, and uses FP16 weights.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports\n",
        "We import the necessary libraries and modules, including the custom `finbert` modules we have defined that allow for profiling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Helper utilities loaded\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import time\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "from finbert.finbert import *\n",
        "from finbert.finbert_profile import *\n",
        "from finbert.profile_utils import get_model_size_mb, print_device_info, setup_nltk_data\n",
        "import finbert.utils as tools\n",
        "from finbert.distillFinBert import *\n",
        "\n",
        "import wandb\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "project_dir = Path.cwd().parent\n",
        "pd.set_option('max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths\n",
        "cl_path = project_dir / 'models' / 'master-profile'\n",
        "cl_path_baseline = project_dir / 'models' / 'master-profile' / 'baseline'\n",
        "cl_path_amp = project_dir / 'models' / 'master-profile' / 'amp'\n",
        "cl_data_path = project_dir / 'data' / 'sentiment_data'\n",
        "\n",
        "# Clean up previous run\n",
        "try:\n",
        "    shutil.rmtree(cl_path)\n",
        "except:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 00:53:54 - WARNING - torchao -   Skipping import of cpp extensions due to incompatible torch version 2.9.1+cu128 for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "12/17/2025 00:53:56 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "12/17/2025 00:53:57 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:53:57 - INFO - finbert.utils -   guid: train-1\n",
            "12/17/2025 00:53:57 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/17/2025 00:53:57 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:53:57 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:53:57 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:53:57 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/17/2025 00:53:58 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 00:53:58 - INFO - finbert.finbert -     Num examples = 3488\n",
            "12/17/2025 00:53:58 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 00:53:58 - INFO - finbert.finbert -     Num steps = 72\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Starting Profiled Training\n",
            "Device: cuda\n",
            "Profiling activities: [<ProfilerActivity.CPU: 0>, <ProfilerActivity.CUDA: 2>]\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration:  17%|█▋        | 19/109 [00:06<00:31,  2.84it/s]\n",
            "Epoch:   0%|          | 0/6 [00:06<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Profiling complete for first epoch (20 steps)\n",
            "Continuing full training without profiling...\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "PROFILING RESULTS - Training\n",
            "================================================================================\n",
            "\n",
            "\n",
            "By CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                  cudaStreamSynchronize        60.68%        4.531s        60.68%        4.531s      28.318ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           160  \n",
            "                                             aten::item         0.18%      13.596ms        36.09%        2.695s     333.437us       0.000us         0.00%      65.856us       0.008us           0 B           0 B           0 B           0 B          8082  \n",
            "                              aten::_local_scalar_dense         0.10%       7.352ms        35.91%        2.681s     331.755us      65.856us         0.00%      65.856us       0.008us           0 B           0 B           0 B           0 B          8082  \n",
            "                                               aten::to         0.05%       3.889ms        25.17%        1.879s     377.235us       0.000us         0.00%     462.042us       0.093us           0 B           0 B      13.47 MB           0 B          4981  \n",
            "                                            aten::copy_         0.07%       4.934ms        25.14%        1.877s       4.267ms       1.593ms         0.03%       1.633ms       3.711us           0 B           0 B           0 B           0 B           440  \n",
            "                                         aten::_to_copy         0.02%       1.640ms        25.11%        1.875s      11.720ms       0.000us         0.00%     462.042us       2.888us           0 B           0 B      13.47 MB           0 B           160  \n",
            "                                       loss_calculation         0.16%      12.011ms        19.22%        1.435s      71.753ms       0.000us         0.00%     186.330us       9.316us           0 B           0 B      21.00 KB     -19.00 KB            20  \n",
            "                                          backward_pass         9.89%     738.151ms        12.65%     944.448ms      47.222ms       0.000us         0.00%      52.064us       2.603us      -3.75 KB      -3.75 KB     -15.27 GB     -15.28 GB            20  \n",
            "                                       cudaLaunchKernel         4.30%     321.081ms         8.72%     651.385ms      45.545us       0.000us         0.00%      99.095ms       6.929us           0 B           0 B           0 B           0 B         14302  \n",
            "                                           forward_pass         1.62%     120.715ms         8.63%     644.442ms      32.222ms       0.000us         0.00%        1.898s      94.880ms       3.75 KB         -80 B      23.61 GB      -6.00 GB            20  \n",
            "                       Runtime Triggered Module Loading         7.08%     528.567ms         7.08%     528.567ms       8.009ms      61.413ms         0.98%      61.413ms     930.503us           0 B           0 B           0 B           0 B            66  \n",
            "                                          data_transfer         0.04%       2.642ms         6.34%     473.099ms      23.655ms       0.000us         0.00%     198.460us       9.923us           0 B           0 B      49.00 KB    -931.00 KB            20  \n",
            "                                         optimizer_step         0.69%      51.698ms         5.58%     416.564ms      20.828ms       0.000us         0.00%     942.348ms      47.117ms         804 B           0 B      -7.51 GB      -2.03 MB            20  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.43%      32.238ms         3.83%     286.204ms     193.381us       0.000us         0.00%        3.017s       2.039ms           0 B           0 B      -2.01 GB     -21.22 GB          1480  \n",
            "                                           aten::linear         0.22%      16.446ms         3.70%     276.560ms     186.865us       0.000us         0.00%        1.668s       1.127ms           0 B           0 B      12.67 GB           0 B          1480  \n",
            "                              Optimizer.step#AdamW.step         1.06%      78.836ms         3.38%     252.663ms      12.633ms       0.000us         0.00%     816.535ms      40.827ms         804 B        -160 B     836.46 MB      -8.22 GB            20  \n",
            "                                            aten::addmm         0.98%      73.145ms         3.02%     225.397ms     152.295us        1.660s        26.53%        1.668s       1.127ms           0 B           0 B      12.67 GB      12.67 GB          1480  \n",
            "                                         AddmmBackward0         0.28%      21.025ms         2.45%     182.846ms     123.544us       0.000us         0.00%        2.931s       1.980ms           0 B           0 B      19.20 GB           0 B          1480  \n",
            "autograd::engine::evaluate_function: EmbeddingBackwa...         0.01%     514.247us         2.11%     157.912ms       2.632ms       0.000us         0.00%      14.923ms     248.719us           0 B           0 B       1.67 GB    -123.75 MB            60  \n",
            "                                     EmbeddingBackward0         0.00%     273.288us         2.11%     157.397ms       2.623ms       0.000us         0.00%      14.923ms     248.719us           0 B           0 B       1.79 GB           0 B            60  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 7.466s\n",
            "Self CUDA time total: 6.256s\n",
            "\n",
            "\n",
            "By CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.43%      32.238ms         3.83%     286.204ms     193.381us       0.000us         0.00%        3.017s       2.039ms           0 B           0 B      -2.01 GB     -21.22 GB          1480  \n",
            "                                         AddmmBackward0         0.28%      21.025ms         2.45%     182.846ms     123.544us       0.000us         0.00%        2.931s       1.980ms           0 B           0 B      19.20 GB           0 B          1480  \n",
            "                                               aten::mm         1.09%      81.644ms         1.65%     123.041ms      41.568us        2.931s        46.85%        2.931s     990.199us           0 B           0 B      19.20 GB      19.20 GB          2960  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us        2.030s        32.46%        2.030s     101.524ms           0 B           0 B           0 B           0 B            20  \n",
            "                                           forward_pass         1.62%     120.715ms         8.63%     644.442ms      32.222ms       0.000us         0.00%        1.898s      94.880ms       3.75 KB         -80 B      23.61 GB      -6.00 GB            20  \n",
            "                                           aten::linear         0.22%      16.446ms         3.70%     276.560ms     186.865us       0.000us         0.00%        1.668s       1.127ms           0 B           0 B      12.67 GB           0 B          1480  \n",
            "                                            aten::addmm         0.98%      73.145ms         3.02%     225.397ms     152.295us        1.660s        26.53%        1.668s       1.127ms           0 B           0 B      12.67 GB      12.67 GB          1480  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us        1.120s        17.91%        1.120s     933.555us           0 B           0 B           0 B           0 B          1200  \n",
            "                                  volta_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us     989.917ms        15.82%     989.917ms     824.930us           0 B           0 B           0 B           0 B          1200  \n",
            "                                  volta_sgemm_128x64_nt         0.00%       0.000us         0.00%       0.000us       0.000us     971.661ms        15.53%     971.661ms     796.444us           0 B           0 B           0 B           0 B          1220  \n",
            "                                         optimizer_step         0.69%      51.698ms         5.58%     416.564ms      20.828ms       0.000us         0.00%     942.348ms      47.117ms         804 B           0 B      -7.51 GB      -2.03 MB            20  \n",
            "                              Optimizer.step#AdamW.step         1.06%      78.836ms         3.38%     252.663ms      12.633ms       0.000us         0.00%     816.535ms      40.827ms         804 B        -160 B     836.46 MB      -8.22 GB            20  \n",
            "                              Optimizer.step#AdamW.step         0.00%       0.000us         0.00%       0.000us       0.000us     771.510ms        12.33%     771.510ms      38.575ms           0 B           0 B           0 B           0 B            20  \n",
            "                                 volta_sgemm_128x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     537.893ms         8.60%     537.893ms       2.241ms           0 B           0 B           0 B           0 B           240  \n",
            "                                 volta_sgemm_128x128_nt         0.00%       0.000us         0.00%       0.000us       0.000us     483.151ms         7.72%     483.151ms       2.013ms           0 B           0 B           0 B           0 B           240  \n",
            "                                 volta_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     482.693ms         7.72%     482.693ms       2.011ms           0 B           0 B           0 B           0 B           240  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.08%       6.055ms         1.08%      80.574ms     335.724us       0.000us         0.00%     248.546ms       1.036ms      -3.75 KB      -3.75 KB      -2.84 GB      -7.06 GB           240  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.04%       3.020ms         1.00%      74.519ms     310.496us       0.000us         0.00%     248.546ms       1.036ms           0 B           0 B       4.22 GB           0 B           240  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.08%       5.826ms         0.96%      71.499ms     297.912us       0.000us         0.00%     248.546ms       1.036ms           0 B           0 B       4.22 GB           0 B           240  \n",
            "                    aten::_efficient_attention_backward         0.13%       9.934ms         0.77%      57.419ms     239.246us     216.771ms         3.47%     248.546ms       1.036ms           0 B           0 B       4.22 GB      -2.86 GB           240  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 7.466s\n",
            "Self CUDA time total: 6.256s\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:35<00:00,  3.03it/s]\n",
            "12/17/2025 00:55:19 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:55:19 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 00:55:19 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 00:55:19 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:55:19 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:55:19 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:55:19 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 00:55:19 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 00:55:19 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 00:55:19 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 00:55:19 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6550192695397598]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:37<00:00,  2.91it/s]\n",
            "12/17/2025 00:55:59 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:55:59 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 00:55:59 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 00:55:59 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:55:59 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:55:59 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:55:59 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 00:55:59 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 00:55:59 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 00:55:59 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 00:55:59 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6550192695397598, 0.5654788040197812]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:36<00:00,  3.00it/s]\n",
            "12/17/2025 00:56:37 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:56:37 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 00:56:37 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 00:56:37 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:56:37 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:56:37 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:56:37 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 00:56:37 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 00:56:37 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 00:56:37 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 00:56:37 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6550192695397598, 0.5654788040197812, 0.5654788040197812]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:36<00:00,  2.96it/s]\n",
            "12/17/2025 00:57:16 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:57:16 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 00:57:16 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 00:57:16 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:57:16 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:57:16 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:57:16 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 00:57:16 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 00:57:16 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 00:57:16 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 00:57:16 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6550192695397598, 0.5654788040197812, 0.5654788040197812, 0.5654788040197812]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:36<00:00,  2.98it/s]\n",
            "12/17/2025 00:57:55 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:57:55 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 00:57:55 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 00:57:55 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:57:55 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:57:55 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:57:55 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 00:57:55 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 00:57:55 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 00:57:55 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 00:57:55 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6550192695397598, 0.5654788040197812, 0.5654788040197812, 0.5654788040197812, 0.5654788040197812]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:36<00:00,  2.98it/s]\n",
            "12/17/2025 00:58:34 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:58:34 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 00:58:34 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 00:58:34 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:58:34 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:58:34 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:58:34 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 00:58:34 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 00:58:34 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 00:58:34 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 00:58:34 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6550192695397598, 0.5654788040197812, 0.5654788040197812, 0.5654788040197812, 0.5654788040197812, 0.5654788040197812]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 6/6 [03:52<00:00, 38.77s/it]\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The anonymous setting has no effect and will be removed in a future version.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtfs2123\u001b[0m (\u001b[33msi2449-columbia-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/tfs2123/hpml-project/pipelines/finBERT/notebooks/wandb/run-20251217_005838-88ij0tox</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/si2449-columbia-university/Project-Runs/runs/88ij0tox' target=\"_blank\">master-profile</a></strong> to <a href='https://wandb.ai/si2449-columbia-university/Project-Runs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/si2449-columbia-university/Project-Runs' target=\"_blank\">https://wandb.ai/si2449-columbia-university/Project-Runs</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/si2449-columbia-university/Project-Runs/runs/88ij0tox' target=\"_blank\">https://wandb.ai/si2449-columbia-university/Project-Runs/runs/88ij0tox</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 00:58:39 - INFO - finbert.distillFinBert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "12/17/2025 00:58:40 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:58:40 - INFO - finbert.utils -   guid: train-1\n",
            "12/17/2025 00:58:40 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/17/2025 00:58:40 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:58:40 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:58:40 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:58:40 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/17/2025 00:58:40 - INFO - finbert.distillFinBert -   ***** Loading data *****\n",
            "12/17/2025 00:58:40 - INFO - finbert.distillFinBert -     Num examples = 3488\n",
            "12/17/2025 00:58:40 - INFO - finbert.distillFinBert -     Batch size = 32\n",
            "12/17/2025 00:58:40 - INFO - finbert.distillFinBert -     Num steps = 72\n",
            "/home/tfs2123/hpml-project/pipelines/finBERT/notebooks/../finbert/distillFinBert.py:369: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=self.config.use_amp)\n",
            "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]/home/tfs2123/hpml-project/pipelines/finBERT/notebooks/../finbert/distillFinBert.py:426: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config.use_amp):\n",
            "/home/tfs2123/hpml-project/pipelines/finBERT/notebooks/../finbert/distillFinBert.py:430: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config.use_amp):\n",
            "Iteration:  17%|█▋        | 19/109 [00:01<00:06, 12.93it/s]\n",
            "Epoch:   0%|          | 0/6 [00:01<?, ?it/s]\n",
            "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]/home/tfs2123/hpml-project/pipelines/finBERT/notebooks/../finbert/distillFinBert.py:527: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config.use_amp):\n",
            "Iteration: 100%|██████████| 109/109 [00:07<00:00, 15.02it/s]\n",
            "12/17/2025 00:59:08 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:59:08 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 00:59:08 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 00:59:08 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:08 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:08 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:08 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 00:59:08 - INFO - finbert.distillFinBert -   ***** Loading data *****\n",
            "12/17/2025 00:59:08 - INFO - finbert.distillFinBert -     Num examples = 388\n",
            "12/17/2025 00:59:08 - INFO - finbert.distillFinBert -     Batch size = 32\n",
            "12/17/2025 00:59:08 - INFO - finbert.distillFinBert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 19.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6041506987351638]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:07<00:00, 15.04it/s]\n",
            "12/17/2025 00:59:16 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:59:16 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 00:59:16 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 00:59:16 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:16 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:16 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:16 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 00:59:16 - INFO - finbert.distillFinBert -   ***** Loading data *****\n",
            "12/17/2025 00:59:16 - INFO - finbert.distillFinBert -     Num examples = 388\n",
            "12/17/2025 00:59:16 - INFO - finbert.distillFinBert -     Batch size = 32\n",
            "12/17/2025 00:59:16 - INFO - finbert.distillFinBert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 19.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6041506987351638, 0.5348695379037124]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:07<00:00, 14.95it/s]\n",
            "12/17/2025 00:59:25 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:59:25 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 00:59:25 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 00:59:25 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:25 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:25 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:25 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 00:59:25 - INFO - finbert.distillFinBert -   ***** Loading data *****\n",
            "12/17/2025 00:59:25 - INFO - finbert.distillFinBert -     Num examples = 388\n",
            "12/17/2025 00:59:25 - INFO - finbert.distillFinBert -     Batch size = 32\n",
            "12/17/2025 00:59:25 - INFO - finbert.distillFinBert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 19.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6041506987351638, 0.5348695379037124, 0.5348695379037124]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:07<00:00, 14.84it/s]\n",
            "12/17/2025 00:59:33 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:59:33 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 00:59:33 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 00:59:33 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:33 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:33 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:33 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 00:59:33 - INFO - finbert.distillFinBert -   ***** Loading data *****\n",
            "12/17/2025 00:59:33 - INFO - finbert.distillFinBert -     Num examples = 388\n",
            "12/17/2025 00:59:33 - INFO - finbert.distillFinBert -     Batch size = 32\n",
            "12/17/2025 00:59:33 - INFO - finbert.distillFinBert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 18.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6041506987351638, 0.5348695379037124, 0.5348695379037124, 0.5348695379037124]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:07<00:00, 14.85it/s]\n",
            "12/17/2025 00:59:42 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:59:42 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 00:59:42 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 00:59:42 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:42 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:42 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:42 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 00:59:42 - INFO - finbert.distillFinBert -   ***** Loading data *****\n",
            "12/17/2025 00:59:42 - INFO - finbert.distillFinBert -     Num examples = 388\n",
            "12/17/2025 00:59:42 - INFO - finbert.distillFinBert -     Batch size = 32\n",
            "12/17/2025 00:59:42 - INFO - finbert.distillFinBert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 19.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6041506987351638, 0.5348695379037124, 0.5348695379037124, 0.5348695379037124, 0.5348695379037124]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:07<00:00, 14.93it/s]\n",
            "12/17/2025 00:59:50 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:59:50 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 00:59:50 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 00:59:50 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:50 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:50 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:50 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 00:59:50 - INFO - finbert.distillFinBert -   ***** Loading data *****\n",
            "12/17/2025 00:59:50 - INFO - finbert.distillFinBert -     Num examples = 388\n",
            "12/17/2025 00:59:50 - INFO - finbert.distillFinBert -     Batch size = 32\n",
            "12/17/2025 00:59:50 - INFO - finbert.distillFinBert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 19.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6041506987351638, 0.5348695379037124, 0.5348695379037124, 0.5348695379037124, 0.5348695379037124, 0.5348695379037124]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 6/6 [00:50<00:00,  8.50s/it]\n"
          ]
        }
      ],
      "source": [
        "# Baseline model and training (no AMP)\n",
        "bertmodel_baseline = AutoModelForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased', cache_dir=None, num_labels=3\n",
        ")\n",
        "\n",
        "config_baseline = Config(\n",
        "    data_dir=cl_data_path,\n",
        "    bert_model=bertmodel_baseline,\n",
        "    num_train_epochs=6,\n",
        "    model_dir=cl_path_baseline,  # Use baseline path\n",
        "    max_seq_length=64,\n",
        "    train_batch_size=32,\n",
        "    learning_rate=0.00001420326287435756,\n",
        "    output_mode='classification',\n",
        "    warm_up_proportion=0.14386028719686458,\n",
        "    local_rank=-1,\n",
        "    discriminate=False,\n",
        "    gradual_unfreeze=False,\n",
        "    use_amp=False,  # Baseline: AMP is off\n",
        ")\n",
        "config_baseline.profile_train_steps = 20\n",
        "\n",
        "finbert_baseline = ProfiledFinBert(config_baseline)\n",
        "finbert_baseline.base_model = 'bert-base-uncased'\n",
        "finbert_baseline.prepare_model(label_list=['positive', 'negative', 'neutral'])\n",
        "\n",
        "train_data_baseline = finbert_baseline.get_data('train')\n",
        "test_data_baseline = finbert_baseline.get_data('test')\n",
        "\n",
        "model_baseline = finbert_baseline.create_the_model()\n",
        "    \n",
        "# Train baseline\n",
        "start = time.perf_counter()\n",
        "trained_model_baseline = finbert_baseline.train(train_examples=train_data_baseline, model=model_baseline)\n",
        "baseline_train_wall_s = time.perf_counter() - start\n",
        "\n",
        "# AMP model and training\n",
        "bertmodel_amp = AutoModelForSequenceClassification.from_pretrained(\n",
        "    'distilbert-base-uncased', cache_dir=None, num_labels=3\n",
        ")\n",
        "\n",
        "config_amp = Config(\n",
        "    data_dir=cl_data_path,\n",
        "    bert_model=bertmodel_amp,\n",
        "    num_train_epochs=6,\n",
        "    model_dir=cl_path_amp,  # Changed from cl_path\n",
        "    max_seq_length=64,\n",
        "    train_batch_size=32,\n",
        "    learning_rate=0.00001420326287435756,\n",
        "    output_mode='classification',\n",
        "    warm_up_proportion=0.14386028719686458,\n",
        "    local_rank=-1,\n",
        "    discriminate=False,\n",
        "    gradual_unfreeze=False,\n",
        "    use_amp=True,  # Enable AMP\n",
        ")\n",
        "config_amp.profile_train_steps = 20\n",
        "\n",
        "# W&B\n",
        "wandb.init(\n",
        "    entity=\"si2449-columbia-university\",\n",
        "    project=\"Project-Runs\",\n",
        "    name=\"master-profile\",\n",
        "    group=\"master-profile\",\n",
        "    config=vars(config_amp)\n",
        ")\n",
        "\n",
        "finbert_amp = DistillFinBert(config_amp)\n",
        "finbert_amp.base_model = 'distilbert-base-uncased'\n",
        "finbert_amp.prepare_model(label_list=['positive', 'negative', 'neutral'])\n",
        "\n",
        "train_data_amp = finbert_amp.get_data('train')\n",
        "test_data_amp = finbert_amp.get_data('test')\n",
        "\n",
        "# train_data and test_data already loaded above\n",
        "model_amp = finbert_amp.create_the_model()\n",
        "    \n",
        "# Train AMP\n",
        "start = time.perf_counter()\n",
        "trained_model_amp = finbert_amp.train(train_examples=train_data_amp, model=model_amp)\n",
        "amp_train_wall_s = time.perf_counter() - start\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 00:59:52 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:59:52 - INFO - finbert.utils -   guid: test-1\n",
            "12/17/2025 00:59:52 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/17/2025 00:59:52 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:52 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:52 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:52 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/17/2025 00:59:53 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 00:59:53 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/17/2025 00:59:53 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 00:59:53 - INFO - finbert.finbert -     Num steps = 72\n",
            "12/17/2025 00:59:56 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:59:56 - INFO - finbert.utils -   guid: test-1\n",
            "12/17/2025 00:59:56 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/17/2025 00:59:56 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:56 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:56 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:56 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/17/2025 00:59:56 - INFO - finbert.distillFinBert -   ***** Loading data *****\n",
            "12/17/2025 00:59:56 - INFO - finbert.distillFinBert -     Num examples = 970\n",
            "12/17/2025 00:59:56 - INFO - finbert.distillFinBert -     Batch size = 32\n",
            "12/17/2025 00:59:56 - INFO - finbert.distillFinBert -     Num steps = 72\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline Model - Accuracy: 0.7495, F1: 0.7403\n",
            "Baseline Model - Throughput: 284.2 samples/sec\n",
            "Trained AMP Model - Accuracy: 0.7680, F1: 0.7566\n",
            "Trained AMP Model - Throughput: 2268.4 samples/sec\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "def timed_eval(*, finbert, model, examples, use_amp=False):\n",
        "    \"\"\"Evaluation with timing.\"\"\"\n",
        "    loader = finbert.get_loader(examples, phase=\"eval\")\n",
        "    device = finbert.device\n",
        "    model.eval()\n",
        "\n",
        "    preds, labels = [], []\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize(device)\n",
        "\n",
        "    start = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, attention_mask, token_type_ids, label_ids, _ = batch  # token_type_ids unused for DistilBERT\n",
        "\n",
        "            if use_amp and device.type == \"cuda\":\n",
        "                with torch.amp.autocast(device_type=\"cuda\"):\n",
        "                    out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            else:\n",
        "                out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            logits = out.logits if hasattr(out, \"logits\") else out[0]\n",
        "            preds.extend(logits.detach().cpu().numpy())\n",
        "            labels.extend(label_ids.detach().cpu().numpy().tolist())\n",
        "\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize(device)\n",
        "\n",
        "    wall_s = time.perf_counter() - start\n",
        "    n = len(labels)\n",
        "\n",
        "    return pd.DataFrame({\"predictions\": preds, \"labels\": labels}), {\n",
        "        \"eval_wall_s\": wall_s,\n",
        "        \"eval_samples_per_s\": n / wall_s if wall_s > 0 else float(\"inf\"),\n",
        "    }\n",
        "\n",
        "def get_metrics(df):\n",
        "    \"\"\"Extract accuracy and F1 from eval results.\"\"\"\n",
        "    preds = np.array([np.argmax(p) for p in df['predictions']])\n",
        "    labels = np.array(df['labels'])\n",
        "    acc = (preds == labels).mean()\n",
        "    from sklearn.metrics import f1_score\n",
        "    f1 = f1_score(labels, preds, average='macro')\n",
        "    return {\"accuracy\": acc, \"f1_macro\": f1}\n",
        "\n",
        "\n",
        "# Baseline eval (no AMP)\n",
        "baseline_eval_df, baseline_timing = timed_eval(\n",
        "    finbert=finbert_baseline, model=trained_model_baseline, examples=test_data_baseline, use_amp=False\n",
        ")\n",
        "baseline_metrics = get_metrics(baseline_eval_df)\n",
        "print(f\"Baseline Model - Accuracy: {baseline_metrics['accuracy']:.4f}, F1: {baseline_metrics['f1_macro']:.4f}\")\n",
        "print(f\"Baseline Model - Throughput: {baseline_timing['eval_samples_per_s']:.1f} samples/sec\")\n",
        "\n",
        "# AMP-trained eval (AMP enabled)\n",
        "amp_trained_eval_df, amp_trained_timing = timed_eval(\n",
        "    finbert=finbert_amp, model=trained_model_amp, examples=test_data_amp, use_amp=True\n",
        ")\n",
        "amp_trained_metrics = get_metrics(amp_trained_eval_df)\n",
        "print(f\"Trained AMP Model - Accuracy: {amp_trained_metrics['accuracy']:.4f}, F1: {amp_trained_metrics['f1_macro']:.4f}\")\n",
        "print(f\"Trained AMP Model - Throughput: {amp_trained_timing['eval_samples_per_s']:.1f} samples/sec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 00:59:57 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 00:59:57 - INFO - finbert.utils -   guid: test-1\n",
            "12/17/2025 00:59:57 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/17/2025 00:59:57 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:57 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:57 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 00:59:57 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/17/2025 00:59:57 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 00:59:57 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/17/2025 00:59:57 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 00:59:57 - INFO - finbert.finbert -     Num steps = 72\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline - Accuracy: 0.7495, F1: 0.7403\n",
            "Baseline - Throughput: 286.4 samples/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 01:00:01 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 01:00:01 - INFO - finbert.utils -   guid: test-1\n",
            "12/17/2025 01:00:01 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/17/2025 01:00:01 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 01:00:01 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 01:00:01 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 01:00:01 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/17/2025 01:00:01 - INFO - finbert.distillFinBert -   ***** Loading data *****\n",
            "12/17/2025 01:00:01 - INFO - finbert.distillFinBert -     Num examples = 970\n",
            "12/17/2025 01:00:01 - INFO - finbert.distillFinBert -     Batch size = 32\n",
            "12/17/2025 01:00:01 - INFO - finbert.distillFinBert -     Num steps = 72\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AMP+FP16 - Accuracy: 0.7680, F1: 0.7566\n",
            "AMP+FP16 - Throughput: 2445.8 samples/sec\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>variant</th>\n",
              "      <th>model_size_mb</th>\n",
              "      <th>eval_wall_s</th>\n",
              "      <th>eval_samples_per_s</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>baseline</td>\n",
              "      <td>417.658215</td>\n",
              "      <td>3.387386</td>\n",
              "      <td>286.356465</td>\n",
              "      <td>0.749485</td>\n",
              "      <td>0.740284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>amp_fp16_weights</td>\n",
              "      <td>127.711920</td>\n",
              "      <td>0.396606</td>\n",
              "      <td>2445.750838</td>\n",
              "      <td>0.768041</td>\n",
              "      <td>0.756607</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            variant  model_size_mb  eval_wall_s  eval_samples_per_s  accuracy  \\\n",
              "0          baseline     417.658215     3.387386          286.356465  0.749485   \n",
              "1  amp_fp16_weights     127.711920     0.396606         2445.750838  0.768041   \n",
              "\n",
              "   f1_macro  \n",
              "0  0.740284  \n",
              "1  0.756607  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = finbert_baseline.device\n",
        "\n",
        "# Evaluate baseline (no AMP/FP16)\n",
        "baseline_eval_df, baseline_timing = timed_eval(\n",
        "    finbert=finbert_baseline, model=model_baseline, examples=test_data_baseline, use_amp=False\n",
        ")\n",
        "baseline_metrics = get_metrics(baseline_eval_df)\n",
        "\n",
        "results_records = [{\n",
        "    \"variant\": \"baseline\",\n",
        "    \"model_size_mb\": get_model_size_mb(model_baseline),\n",
        "    **baseline_timing,\n",
        "    **baseline_metrics,\n",
        "}]\n",
        "print(f\"Baseline - Accuracy: {baseline_metrics['accuracy']:.4f}, F1: {baseline_metrics['f1_macro']:.4f}\")\n",
        "print(f\"Baseline - Throughput: {baseline_timing['eval_samples_per_s']:.1f} samples/sec\")\n",
        "\n",
        "device = finbert_amp.device\n",
        "if device.type == \"cuda\":\n",
        "    # Load model with FP16 weights\n",
        "    fp16_amp_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        cl_path_amp, num_labels=3, dtype=torch.float16\n",
        "    ).to(device)\n",
        "\n",
        "    # AMP autocast + FP16 weights\n",
        "    amp_fp16_eval_df, amp_fp16_timing = timed_eval(\n",
        "        finbert=finbert_amp, model=fp16_amp_model, examples=test_data_amp, use_amp=True\n",
        "    )\n",
        "    amp_fp16_metrics = get_metrics(amp_fp16_eval_df)\n",
        "\n",
        "    results_records.append({\n",
        "        \"variant\": \"amp_fp16_weights\",\n",
        "        \"model_size_mb\": get_model_size_mb(fp16_amp_model),\n",
        "        **amp_fp16_timing,\n",
        "        **amp_fp16_metrics,\n",
        "    })\n",
        "    print(f\"AMP+FP16 - Accuracy: {amp_fp16_metrics['accuracy']:.4f}, F1: {amp_fp16_metrics['f1_macro']:.4f}\")\n",
        "    print(f\"AMP+FP16 - Throughput: {amp_fp16_timing['eval_samples_per_s']:.1f} samples/sec\")\n",
        "else:\n",
        "    print(\"AMP+FP16 eval requires CUDA\")\n",
        "\n",
        "results_df = pd.DataFrame(results_records)\n",
        "\n",
        "# ---- Added statistics ----\n",
        "if len(results_df) > 1:\n",
        "    base = results_df.iloc[0]\n",
        "    amp = results_df.iloc[1]\n",
        "    # Relative speedup: how much faster is AMP+FP16 throughput\n",
        "    speedup = amp['eval_samples_per_s'] / base['eval_samples_per_s'] if base['eval_samples_per_s'] > 0 else float('nan')\n",
        "    # Compression: how much smaller is the model (MB)\n",
        "    compression = amp['model_size_mb'] / base['model_size_mb'] if base['model_size_mb'] > 0 else float('nan')\n",
        "    compression_str = f\"{(1/compression):.2f}x\" if compression > 0 else \"n/a\"\n",
        "    # Accuracy delta: amp - baseline\n",
        "    acc_delta = amp['accuracy'] - base['accuracy']\n",
        "    print(f\"\\n[STATS]\")\n",
        "    print(f\"Relative speedup (AMP+FP16 vs. baseline): {speedup:.2f}x\")\n",
        "    print(f\"Model size compression (AMP+FP16 vs. baseline): {compression_str} smaller \"\n",
        "          f\"({amp['model_size_mb']:.1f}MB vs {base['model_size_mb']:.1f}MB)\")\n",
        "    print(f\"Accuracy delta (AMP+FP16 minus baseline): {acc_delta:+.3f}\")\n",
        "\n",
        "    # Optionally also store in DataFrame\n",
        "    stats_row = {\n",
        "        \"variant\": \"amp_fp16_vs_baseline\",\n",
        "        \"speedup_x\": speedup,\n",
        "        \"compression_x\": (1/compression) if compression > 0 else float('nan'),\n",
        "        \"accuracy_delta\": acc_delta,\n",
        "        \"base_accuracy\": base['accuracy'],\n",
        "        \"amp_fp16_accuracy\": amp['accuracy']\n",
        "    }\n",
        "    # This row for stats, not normal metric row\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([stats_row])], ignore_index=True)\n",
        "\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>amp_fp16_trained_accuracy</td><td>▁</td></tr><tr><td>amp_fp16_trained_f1</td><td>▁</td></tr><tr><td>amp_fp16_trained_model_size</td><td>▁</td></tr><tr><td>amp_fp16_trained_throughput</td><td>▁</td></tr><tr><td>baseline_accuracy</td><td>▁</td></tr><tr><td>baseline_f1</td><td>▁</td></tr><tr><td>baseline_model_size</td><td>▁</td></tr><tr><td>baseline_throughput</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>amp_fp16_trained_accuracy</td><td>0.76804</td></tr><tr><td>amp_fp16_trained_f1</td><td>0.75661</td></tr><tr><td>amp_fp16_trained_model_size</td><td>127.71192</td></tr><tr><td>amp_fp16_trained_throughput</td><td>2445.75084</td></tr><tr><td>baseline_accuracy</td><td>0.74948</td></tr><tr><td>baseline_f1</td><td>0.74028</td></tr><tr><td>baseline_model_size</td><td>417.65821</td></tr><tr><td>baseline_throughput</td><td>286.35646</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">master-profile</strong> at: <a href='https://wandb.ai/si2449-columbia-university/Project-Runs/runs/88ij0tox' target=\"_blank\">https://wandb.ai/si2449-columbia-university/Project-Runs/runs/88ij0tox</a><br> View project at: <a href='https://wandb.ai/si2449-columbia-university/Project-Runs' target=\"_blank\">https://wandb.ai/si2449-columbia-university/Project-Runs</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251217_005838-88ij0tox/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Log summary to W&B with both baseline and AMP/FP16 metrics (if available)\n",
        "summary = {}\n",
        "\n",
        "# Always add baseline summary stats\n",
        "summary.update({\n",
        "    \"baseline_accuracy\": baseline_metrics[\"accuracy\"],\n",
        "    \"baseline_f1\": baseline_metrics[\"f1_macro\"],\n",
        "    \"baseline_throughput\": baseline_timing[\"eval_samples_per_s\"],\n",
        "    \"baseline_model_size\": get_model_size_mb(model_baseline),\n",
        "})\n",
        "\n",
        "# Add AMP/FP16 statistics if on CUDA and results available\n",
        "if device.type == \"cuda\":\n",
        "    summary.update({\n",
        "        \"amp_fp16_trained_accuracy\": amp_fp16_metrics[\"accuracy\"],\n",
        "        \"amp_fp16_trained_f1\": amp_fp16_metrics[\"f1_macro\"],\n",
        "        \"amp_fp16_trained_throughput\": amp_fp16_timing[\"eval_samples_per_s\"],\n",
        "        \"amp_fp16_trained_model_size\": get_model_size_mb(fp16_amp_model),\n",
        "    })\n",
        "\n",
        "wandb.log(summary)\n",
        "\n",
        "# We'll upload the results_df (or plot_df) as a W&B Table for interactive dashboards\n",
        "\n",
        "# Option 1: upload the underlying DataFrame as a W&B Table\n",
        "# (works best if your DataFrame columns cover all metrics you'd like to compare)\n",
        "table = wandb.Table(dataframe=results_df)\n",
        "\n",
        "wandb.log({\"variant_summary_table\": table})\n",
        "\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
