{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Memory Optimized FinBERT Profiling: FP16 and AMP\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: **AMP and FP16 are only enabled on CUDA by default** (to avoid MPS/CPU autocast edge cases).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports\n",
        "We import the necessary libraries and modules, including the custom `finbert` modules we have defined that allow for profiling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import time\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "from finbert.finbert import *\n",
        "from finbert.finbert_profile import *\n",
        "from finbert.profile_utils import get_model_size_mb, print_device_info, setup_nltk_data\n",
        "import finbert.utils as tools\n",
        "\n",
        "import wandb\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "project_dir = Path.cwd().parent\n",
        "pd.set_option('max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths\n",
        "cl_path = project_dir / 'models' / 'mem_opt_comparison'\n",
        "cl_data_path = project_dir / 'data' / 'sentiment_data'\n",
        "\n",
        "# Clean up previous run\n",
        "try:\n",
        "    shutil.rmtree(cl_path)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# W&B\n",
        "wandb.init(\n",
        "    entity=\"si2449-columbia-university\",\n",
        "    project=\"finbert-experiments\",\n",
        "    name=\"mem-opt-comparison\",\n",
        "    group=\"mem_optimization\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "USE_AMP = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bertmodel = AutoModelForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased', cache_dir=None, num_labels=3\n",
        ")\n",
        "\n",
        "config_baseline = Config(\n",
        "    data_dir=cl_data_path,\n",
        "    bert_model=bertmodel,\n",
        "    num_train_epochs=6,\n",
        "    model_dir=cl_path,\n",
        "    max_seq_length=64,\n",
        "    train_batch_size=32,\n",
        "    learning_rate=0.00001420326287435756,\n",
        "    output_mode='classification',\n",
        "    warm_up_proportion=0.14386028719686458,\n",
        "    local_rank=-1,\n",
        "    discriminate=False,\n",
        "    gradual_unfreeze=False,\n",
        "    use_amp=False,  # Baseline uses FP32\n",
        ")\n",
        "config_baseline.profile_train_steps = 20\n",
        "\n",
        "finbert = ProfiledFinBert(config_baseline)\n",
        "finbert.base_model = 'bert-base-uncased'\n",
        "finbert.prepare_model(label_list=['positive', 'negative', 'neutral'])\n",
        "\n",
        "train_data = finbert.get_data('train')\n",
        "test_data = finbert.get_data('test')\n",
        "\n",
        "model = finbert.create_the_model()\n",
        "\n",
        "# Train\n",
        "start = time.perf_counter()\n",
        "trained_model = finbert.train(train_examples=train_data, model=model)\n",
        "baseline_train_wall_s = time.perf_counter() - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def timed_eval(*, finbert, model, examples, use_amp=False):\n",
        "    \"\"\"Evaluation with timing.\"\"\"\n",
        "    loader = finbert.get_loader(examples, phase=\"eval\")\n",
        "    device = finbert.device\n",
        "    model.eval()\n",
        "    \n",
        "    preds, labels = [], []\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize(device)\n",
        "    \n",
        "    start = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, attention_mask, token_type_ids, label_ids, _ = batch\n",
        "            \n",
        "            if use_amp and device.type == \"cuda\":\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    logits = model(input_ids, attention_mask, token_type_ids)[0]\n",
        "            else:\n",
        "                logits = model(input_ids, attention_mask, token_type_ids)[0]\n",
        "            \n",
        "            preds.extend(logits.detach().cpu().numpy())\n",
        "            labels.extend(label_ids.detach().cpu().numpy().tolist())\n",
        "    \n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize(device)\n",
        "    \n",
        "    wall_s = time.perf_counter() - start\n",
        "    n = len(labels)\n",
        "    \n",
        "    return pd.DataFrame({\"predictions\": preds, \"labels\": labels}), {\n",
        "        \"eval_wall_s\": wall_s,\n",
        "        \"eval_samples_per_s\": n / wall_s if wall_s > 0 else float(\"inf\"),\n",
        "    }\n",
        "\n",
        "def get_metrics(df):\n",
        "    \"\"\"Extract accuracy and F1 from eval results.\"\"\"\n",
        "    preds = np.array([np.argmax(p) for p in df['predictions']])\n",
        "    labels = np.array(df['labels'])\n",
        "    acc = (preds == labels).mean()\n",
        "    from sklearn.metrics import f1_score\n",
        "    f1 = f1_score(labels, preds, average='macro')\n",
        "    return {\"accuracy\": acc, \"f1_macro\": f1}\n",
        "\n",
        "# Evaluate baseline\n",
        "baseline_eval_df, baseline_timing = timed_eval(finbert=finbert, model=trained_model, examples=test_data, use_amp=False)\n",
        "baseline_metrics = get_metrics(baseline_eval_df)\n",
        "\n",
        "print(f\"Baseline - Accuracy: {baseline_metrics['accuracy']:.4f}, F1: {baseline_metrics['f1_macro']:.4f}\")\n",
        "print(f\"Baseline - Throughput: {baseline_timing['eval_samples_per_s']:.1f} samples/sec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = finbert.device\n",
        "all_results = []\n",
        "\n",
        "# ===== BASELINE =====\n",
        "all_results.append({\n",
        "    \"variant\": \"baseline\",\n",
        "    \"model_size_mb\": get_model_size_mb(trained_model),\n",
        "    **baseline_timing,\n",
        "    **baseline_metrics,\n",
        "})\n",
        "\n",
        "# ===== FP16 WEIGHTS =====\n",
        "if device.type == \"cuda\":\n",
        "    # Load model with FP16 weights\n",
        "    fp16_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        cl_path, num_labels=3, torch_dtype=torch.float16\n",
        "    ).to(device)\n",
        "    \n",
        "    fp16_eval_df, fp16_timing = timed_eval(finbert=finbert, model=fp16_model, examples=test_data, use_amp=False)\n",
        "    fp16_metrics = get_metrics(fp16_eval_df)\n",
        "    \n",
        "    all_results.append({\n",
        "        \"variant\": \"fp16_weights\",\n",
        "        \"model_size_mb\": get_model_size_mb(fp16_model),\n",
        "        **fp16_timing,\n",
        "        **fp16_metrics,\n",
        "    })\n",
        "    print(f\"FP16 - Accuracy: {fp16_metrics['accuracy']:.4f}, F1: {fp16_metrics['f1_macro']:.4f}\")\n",
        "    print(f\"FP16 - Throughput: {fp16_timing['eval_samples_per_s']:.1f} samples/sec\")\n",
        "else:\n",
        "    print(\"Skipping FP16 (requires CUDA)\")\n",
        "\n",
        "# ===== AMP AUTOCAST =====\n",
        "if device.type == \"cuda\":\n",
        "    # Use baseline model with AMP autocast during inference\n",
        "    amp_eval_df, amp_timing = timed_eval(finbert=finbert, model=trained_model, examples=test_data, use_amp=True)\n",
        "    amp_metrics = get_metrics(amp_eval_df)\n",
        "    \n",
        "    all_results.append({\n",
        "        \"variant\": \"amp_autocast\",\n",
        "        \"model_size_mb\": get_model_size_mb(trained_model),\n",
        "        **amp_timing,\n",
        "        **amp_metrics,\n",
        "    })\n",
        "    print(f\"AMP - Accuracy: {amp_metrics['accuracy']:.4f}, F1: {amp_metrics['f1_macro']:.4f}\")\n",
        "    print(f\"AMP - Throughput: {amp_timing['eval_samples_per_s']:.1f} samples/sec\")\n",
        "else:\n",
        "    print(\"Skipping AMP (requires CUDA)\")\n",
        "\n",
        "results_df = pd.DataFrame(all_results)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
        "\n",
        "# Throughput\n",
        "ax = axes[0]\n",
        "results_df.set_index(\"variant\")[\"eval_samples_per_s\"].plot(kind=\"bar\", ax=ax, color=['#2ecc71', '#3498db', '#e74c3c'])\n",
        "ax.set_title(\"Inference Throughput\")\n",
        "ax.set_ylabel(\"samples/sec\")\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
        "\n",
        "# Accuracy\n",
        "ax = axes[1]\n",
        "results_df.set_index(\"variant\")[\"accuracy\"].plot(kind=\"bar\", ax=ax, color=['#2ecc71', '#3498db', '#e74c3c'])\n",
        "ax.set_title(\"Accuracy\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_ylim(0.7, 1.0)\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
        "\n",
        "# Model Size\n",
        "ax = axes[2]\n",
        "results_df.set_index(\"variant\")[\"model_size_mb\"].plot(kind=\"bar\", ax=ax, color=['#2ecc71', '#3498db', '#e74c3c'])\n",
        "ax.set_title(\"Model Size\")\n",
        "ax.set_ylabel(\"MB\")\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Speedup summary\n",
        "if len(results_df) > 1:\n",
        "    base = results_df[results_df[\"variant\"] == \"baseline\"].iloc[0]\n",
        "    print(\"\\n=== Speedup vs Baseline ===\")\n",
        "    for _, row in results_df.iterrows():\n",
        "        if row[\"variant\"] != \"baseline\":\n",
        "            speedup = row[\"eval_samples_per_s\"] / base[\"eval_samples_per_s\"]\n",
        "            delta_acc = row[\"accuracy\"] - base[\"accuracy\"]\n",
        "            print(f\"{row['variant']}: {speedup:.2f}x speedup, Δaccuracy={delta_acc:+.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Log summary to W&B\n",
        "summary = {\n",
        "    \"baseline_train_wall_s\": baseline_train_wall_s,\n",
        "    \"baseline_accuracy\": baseline_metrics[\"accuracy\"],\n",
        "    \"baseline_f1\": baseline_metrics[\"f1_macro\"],\n",
        "    \"baseline_throughput\": baseline_timing[\"eval_samples_per_s\"],\n",
        "}\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    summary.update({\n",
        "        \"fp16_accuracy\": fp16_metrics[\"accuracy\"],\n",
        "        \"fp16_throughput\": fp16_timing[\"eval_samples_per_s\"],\n",
        "        \"amp_accuracy\": amp_metrics[\"accuracy\"],\n",
        "        \"amp_throughput\": amp_timing[\"eval_samples_per_s\"],\n",
        "    })\n",
        "\n",
        "wandb.log(summary)\n",
        "wandb.finish()\n",
        "\n",
        "print(\"✓ Done!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
