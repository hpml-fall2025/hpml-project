{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Memory Optimized FinBERT Profiling: FP16 and AMP\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: **AMP and FP16 are only enabled on CUDA by default** (to avoid MPS/CPU autocast edge cases).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports\n",
        "We import the necessary libraries and modules, including the custom `finbert` modules we have defined that allow for profiling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Helper utilities loaded\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import time\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "from finbert.finbert import *\n",
        "from finbert.finbert_profile import *\n",
        "from finbert.profile_utils import get_model_size_mb, print_device_info, setup_nltk_data\n",
        "import finbert.utils as tools\n",
        "\n",
        "import wandb\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "project_dir = Path.cwd().parent\n",
        "pd.set_option('max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msi2449\u001b[0m (\u001b[33msi2449-columbia-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "setting up run lnygxq0l (0.2s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/si2449/hpml-project/pipelines/finBERT/notebooks/wandb/run-20251220_021748-lnygxq0l</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/si2449-columbia-university/Project-Runs/runs/lnygxq0l' target=\"_blank\">mem-opt-comparison</a></strong> to <a href='https://wandb.ai/si2449-columbia-university/Project-Runs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/si2449-columbia-university/Project-Runs' target=\"_blank\">https://wandb.ai/si2449-columbia-university/Project-Runs</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/si2449-columbia-university/Project-Runs/runs/lnygxq0l' target=\"_blank\">https://wandb.ai/si2449-columbia-university/Project-Runs/runs/lnygxq0l</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/si2449-columbia-university/Project-Runs/runs/lnygxq0l?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f8bb09c73d0>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Paths\n",
        "cl_path = project_dir / 'models' / 'mem_opt_comparison'\n",
        "cl_path_baseline = project_dir / 'models' / 'mem_opt_comparison' / 'baseline'\n",
        "cl_path_amp = project_dir / 'models' / 'mem_opt_comparison' / 'amp'\n",
        "cl_data_path = project_dir / 'data' / 'sentiment_data'\n",
        "\n",
        "# Clean up previous run\n",
        "try:\n",
        "    shutil.rmtree(cl_path)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# # W&B\n",
        "wandb.init(\n",
        "    entity=\"si2449-columbia-university\",\n",
        "    project=\"Project-Runs\",\n",
        "    name=\"mem-opt-comparison\",\n",
        "    group=\"mem_optimization\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "12/20/2025 02:17:50 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,194,243 || all params: 110,678,790 || trainable%: 1.0790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/20/2025 02:17:52 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:17:52 - INFO - finbert.utils -   guid: train-1\n",
            "12/20/2025 02:17:52 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/20/2025 02:17:52 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:17:52 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:17:52 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:17:52 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/20/2025 02:17:52 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:17:52 - INFO - finbert.finbert -     Num examples = 3488\n",
            "12/20/2025 02:17:52 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:17:52 - INFO - finbert.finbert -     Num steps = 120\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Starting Profiled Training\n",
            "Device: cuda\n",
            "Profiling activities: [<ProfilerActivity.CPU: 0>, <ProfilerActivity.CUDA: 2>]\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration:  17%|█▋        | 19/109 [00:04<00:21,  4.25it/s]\n",
            "Epoch:   0%|          | 0/10 [00:04<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Profiling complete for first epoch (20 steps)\n",
            "Continuing full training without profiling...\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "PROFILING RESULTS - Training\n",
            "================================================================================\n",
            "\n",
            "\n",
            "By CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                  cudaStreamSynchronize        29.99%        1.611s        29.99%        1.611s      10.072ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           160  \n",
            "                                          backward_pass        21.36%        1.148s        22.06%        1.186s      59.280ms       0.000us         0.00%      46.717us       2.336us     -13.28 KB     -13.28 KB     -22.12 GB     -22.12 GB            20  \n",
            "                                           forward_pass         5.65%     303.715ms        21.70%        1.166s      58.303ms       0.000us         0.00%        1.746s      87.285ms      13.28 KB       9.45 KB      22.22 GB     -36.39 GB            20  \n",
            "                                             aten::item         0.19%       9.990ms        16.32%     877.055ms     175.341us       0.000us         0.00%      65.722us       0.013us           0 B           0 B           0 B           0 B          5002  \n",
            "                              aten::_local_scalar_dense         0.11%       5.803ms        16.14%     867.065ms     173.344us      65.722us         0.00%      65.722us       0.013us           0 B           0 B           0 B           0 B          5002  \n",
            "                                       loss_calculation         0.32%      17.114ms        14.86%     798.471ms      39.924ms       0.000us         0.00%     166.781us       8.339us           0 B           0 B      21.00 KB     -19.00 KB            20  \n",
            "                                               aten::to         0.10%       5.530ms        14.38%     772.803ms     133.150us       0.000us         0.00%     449.749us       0.077us           0 B           0 B       7.76 MB           0 B          5804  \n",
            "                                            aten::copy_         0.08%       4.469ms        14.33%     769.935ms       1.750ms       1.384ms         0.04%       1.421ms       3.230us           0 B           0 B           0 B           0 B           440  \n",
            "                                         aten::_to_copy         0.02%       1.329ms        14.28%     767.273ms       4.795ms       0.000us         0.00%     449.749us       2.811us           0 B           0 B       7.76 MB           0 B           160  \n",
            "                                       cudaLaunchKernel         5.03%     270.420ms        10.81%     581.105ms      20.341us       0.000us         0.00%       4.322ms       0.151us           0 B           0 B           0 B           0 B         28568  \n",
            "                                           aten::linear         0.51%      27.255ms         7.38%     396.650ms     101.186us       0.000us         0.00%        1.284s     327.644us           0 B           0 B      18.03 GB           0 B          3920  \n",
            "                                               aten::mm         4.55%     244.443ms         7.31%     392.869ms      45.054us        1.445s        39.09%        1.445s     165.706us           0 B           0 B      26.18 GB      26.18 GB          8720  \n",
            "                                         optimizer_step         1.30%      69.599ms         6.40%     343.838ms      17.192ms       0.000us         0.00%      13.925ms     696.267us         496 B           0 B     -82.01 MB      -1.27 MB            20  \n",
            "                       Runtime Triggered Module Loading         6.29%     337.872ms         6.29%     337.872ms       4.969ms       5.405ms         0.15%       5.405ms      79.483us           0 B           0 B           0 B           0 B            68  \n",
            "       autograd::engine::evaluate_function: MmBackward0         0.71%      37.953ms         5.93%     318.487ms     130.528us       0.000us         0.00%     246.244ms     100.920us           0 B           0 B      -8.60 GB     -17.00 GB          2440  \n",
            "                                            MmBackward0         0.54%      29.226ms         5.22%     280.534ms     114.973us       0.000us         0.00%     246.244ms     100.920us           0 B           0 B       8.41 GB           0 B          2440  \n",
            "                                           aten::matmul         0.44%      23.759ms         3.40%     182.662ms      74.861us       0.000us         0.00%     141.566ms      58.019us           0 B           0 B       8.53 GB           0 B          2440  \n",
            "                              Optimizer.step#AdamW.step         1.01%      54.296ms         3.37%     180.902ms       9.045ms       0.000us         0.00%      11.733ms     586.641us         496 B        -160 B       9.11 MB     -91.12 MB            20  \n",
            "                                                aten::t         1.03%      55.470ms         2.47%     132.775ms       8.781us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B         15120  \n",
            "     autograd::engine::evaluate_function: ViewBackward0         0.84%      45.140ms         2.38%     127.690ms      21.002us       0.000us         0.00%     124.077ms      20.407us           0 B           0 B      -9.23 GB      -9.23 GB          6080  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 5.374s\n",
            "Self CUDA time total: 3.696s\n",
            "\n",
            "\n",
            "By CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us        1.908s        51.64%        1.908s      95.422ms           0 B           0 B           0 B           0 B            20  \n",
            "                                           forward_pass         5.65%     303.715ms        21.70%        1.166s      58.303ms       0.000us         0.00%        1.746s      87.285ms      13.28 KB       9.45 KB      22.22 GB     -36.39 GB            20  \n",
            "                                               aten::mm         4.55%     244.443ms         7.31%     392.869ms      45.054us        1.445s        39.09%        1.445s     165.706us           0 B           0 B      26.18 GB      26.18 GB          8720  \n",
            "                                           aten::linear         0.51%      27.255ms         7.38%     396.650ms     101.186us       0.000us         0.00%        1.284s     327.644us           0 B           0 B      18.03 GB           0 B          3920  \n",
            "                                            aten::addmm         1.41%      75.599ms         2.28%     122.765ms      82.949us        1.139s        30.82%        1.143s     772.161us           0 B           0 B       9.50 GB       9.50 GB          1480  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.25%      13.617ms         2.18%     117.068ms      82.442us       0.000us         0.00%        1.057s     744.613us           0 B           0 B       1.18 MB      -9.24 GB          1420  \n",
            "                                         AddmmBackward0         0.20%      10.642ms         1.68%      90.327ms      63.610us       0.000us         0.00%        1.057s     744.469us           0 B           0 B       9.24 GB           0 B          1420  \n",
            "                                  volta_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us        1.054s        28.53%        1.054s     764.098us           0 B           0 B           0 B           0 B          1380  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     770.542ms        20.85%     770.542ms     535.099us           0 B           0 B           0 B           0 B          1440  \n",
            "                                 volta_sgemm_128x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     412.046ms        11.15%     412.046ms     343.372us           0 B           0 B           0 B           0 B          1200  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     309.310ms         8.37%     309.310ms      81.397us           0 B           0 B           0 B           0 B          3800  \n",
            "       autograd::engine::evaluate_function: MmBackward0         0.71%      37.953ms         5.93%     318.487ms     130.528us       0.000us         0.00%     246.244ms     100.920us           0 B           0 B      -8.60 GB     -17.00 GB          2440  \n",
            "                                            MmBackward0         0.54%      29.226ms         5.22%     280.534ms     114.973us       0.000us         0.00%     246.244ms     100.920us           0 B           0 B       8.41 GB           0 B          2440  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.12%       6.514ms         1.31%      70.574ms     294.060us       0.000us         0.00%     204.191ms     850.796us      -3.75 KB      -3.75 KB      -2.25 GB      -5.34 GB           240  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.06%       3.129ms         1.19%      64.060ms     266.918us       0.000us         0.00%     204.191ms     850.796us           0 B           0 B       3.08 GB     -90.00 MB           240  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.11%       5.688ms         1.13%      60.931ms     253.880us       0.000us         0.00%     204.191ms     850.796us           0 B           0 B       3.17 GB           0 B           240  \n",
            "                    aten::_efficient_attention_backward         0.18%       9.456ms         0.86%      46.481ms     193.672us     178.631ms         4.83%     204.191ms     850.796us           0 B           0 B       3.17 GB      -2.50 GB           240  \n",
            "fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm75(PyT...         0.00%       0.000us         0.00%       0.000us       0.000us     178.631ms         4.83%     178.631ms     744.296us           0 B           0 B           0 B           0 B           240  \n",
            "                                              aten::mul         0.94%      50.467ms         1.63%      87.427ms      32.380us     166.714ms         4.51%     166.834ms      61.790us           0 B           0 B      17.95 GB      17.95 GB          2700  \n",
            "                                             aten::add_         0.47%      25.274ms         0.78%      41.924ms       9.154us     165.773ms         4.49%     165.820ms      36.205us           0 B           0 B           0 B           0 B          4580  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 5.374s\n",
            "Self CUDA time total: 3.696s\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "⚠ Failed to log profiler table: 'FunctionEventAvg' object has no attribute 'cuda_time_total'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.93it/s]\n",
            "12/20/2025 02:19:18 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:19:18 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:19:18 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:19:18 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:19:18 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:19:18 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:19:18 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:19:18 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:19:18 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:19:18 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:19:18 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47418922873643726]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.81it/s]\n",
            "12/20/2025 02:19:42 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:19:42 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:19:42 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:19:42 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:19:42 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:19:42 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:19:42 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:19:42 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:19:42 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:19:42 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:19:42 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 10.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47418922873643726, 0.30263933539390564]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:23<00:00,  4.74it/s]\n",
            "12/20/2025 02:20:07 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:20:07 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:20:07 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:20:07 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:20:07 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:20:07 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:20:07 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:20:07 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:20:07 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:20:07 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:20:07 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47418922873643726, 0.30263933539390564, 0.27598179418307084]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.83it/s]\n",
            "12/20/2025 02:20:32 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:20:32 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:20:32 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:20:32 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:20:32 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:20:32 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:20:32 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:20:32 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:20:32 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:20:32 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:20:32 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47418922873643726, 0.30263933539390564, 0.27598179418307084, 0.27598179418307084]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.84it/s]\n",
            "12/20/2025 02:20:56 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:20:56 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:20:56 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:20:56 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:20:56 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:20:56 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:20:56 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:20:56 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:20:56 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:20:56 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:20:56 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47418922873643726, 0.30263933539390564, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.80it/s]\n",
            "12/20/2025 02:21:21 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:21:21 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:21:21 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:21:21 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:21:21 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:21:21 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:21:21 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:21:21 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:21:21 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:21:21 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:21:21 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47418922873643726, 0.30263933539390564, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.81it/s]\n",
            "12/20/2025 02:21:46 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:21:46 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:21:46 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:21:46 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:21:46 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:21:46 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:21:46 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:21:46 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:21:46 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:21:46 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:21:46 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47418922873643726, 0.30263933539390564, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.80it/s]\n",
            "12/20/2025 02:22:10 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:22:10 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:22:10 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:22:10 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:22:10 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:22:10 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:22:10 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:22:11 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:22:11 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:22:11 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:22:11 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47418922873643726, 0.30263933539390564, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.81it/s]\n",
            "12/20/2025 02:22:35 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:22:35 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:22:35 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:22:35 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:22:35 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:22:35 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:22:35 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:22:35 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:22:35 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:22:35 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:22:35 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47418922873643726, 0.30263933539390564, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.82it/s]\n",
            "12/20/2025 02:23:00 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:23:00 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:23:00 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:23:00 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:23:00 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:23:00 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:23:00 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:23:00 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:23:00 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:23:00 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:23:00 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47418922873643726, 0.30263933539390564, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084, 0.27598179418307084]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 10/10 [04:06<00:00, 24.60s/it]\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "12/20/2025 02:23:03 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "12/20/2025 02:23:05 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:23:05 - INFO - finbert.utils -   guid: train-1\n",
            "12/20/2025 02:23:05 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/20/2025 02:23:05 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:23:05 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:23:05 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:23:05 - INFO - finbert.utils -   label: positive (id = 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,194,243 || all params: 110,678,790 || trainable%: 1.0790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/20/2025 02:23:05 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:23:05 - INFO - finbert.finbert -     Num examples = 3488\n",
            "12/20/2025 02:23:05 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:23:05 - INFO - finbert.finbert -     Num steps = 120\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Starting Profiled Training\n",
            "Device: cuda\n",
            "Profiling activities: [<ProfilerActivity.CPU: 0>, <ProfilerActivity.CUDA: 2>]\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration:  17%|█▋        | 19/109 [00:03<00:14,  6.17it/s]\n",
            "Epoch:   0%|          | 0/10 [00:03<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Profiling complete for first epoch (20 steps)\n",
            "Continuing full training without profiling...\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "PROFILING RESULTS - Training\n",
            "================================================================================\n",
            "\n",
            "\n",
            "By CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          backward_pass        33.30%        1.396s        33.79%        1.416s      70.810ms       0.000us         0.00%      72.466us       3.623us     -13.28 KB     -13.28 KB     -16.85 GB     -16.88 GB            20  \n",
            "                                           forward_pass         7.73%     323.957ms        31.02%        1.300s      64.989ms       0.000us         0.00%     668.199ms      33.410ms      13.28 KB       9.45 KB      16.94 GB     -33.16 GB            20  \n",
            "                                           aten::linear         1.36%      57.165ms        25.79%        1.081s     137.846us       0.000us         0.00%     539.753ms      68.846us           0 B           0 B      25.58 GB      -2.23 GB          7840  \n",
            "                                               aten::to         0.80%      33.646ms        11.20%     469.505ms      24.889us       0.000us         0.00%     328.502ms      17.414us           0 B           0 B      31.14 GB           0 B         18864  \n",
            "                                         aten::_to_copy         2.27%      95.013ms        10.40%     435.859ms      30.825us       0.000us         0.00%     328.502ms      23.232us           0 B           0 B      31.14 GB           0 B         14140  \n",
            "                                               aten::mm         7.08%     296.841ms         9.53%     399.545ms      45.819us     293.191ms        20.33%     293.227ms      33.627us           0 B           0 B      13.07 GB      13.07 GB          8720  \n",
            "       autograd::engine::evaluate_function: MmBackward0         0.87%      36.302ms         8.25%     345.587ms     141.634us       0.000us         0.00%     104.937ms      43.007us           0 B           0 B      -4.35 GB      -8.56 GB          2440  \n",
            "                                       cudaLaunchKernel         7.21%     302.179ms         7.54%     316.019ms       9.094us       0.000us         0.00%     969.423us       0.028us           0 B           0 B           0 B           0 B         34750  \n",
            "                                            MmBackward0         0.71%      29.898ms         7.38%     309.285ms     126.756us       0.000us         0.00%     104.937ms      43.007us           0 B           0 B       4.20 GB           0 B          2440  \n",
            "                                            aten::copy_         2.86%     119.666ms         5.89%     246.749ms      17.401us     328.555ms        22.78%     328.616ms      23.175us           0 B           0 B           0 B           0 B         14180  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.97%      40.816ms         5.69%     238.651ms      46.978us       0.000us         0.00%     189.616ms      37.326us           0 B           0 B    -450.32 MB     -15.39 GB          5080  \n",
            "                                         optimizer_step         1.75%      73.385ms         5.62%     235.623ms      11.781ms       0.000us         0.00%      13.560ms     678.021us         496 B           0 B     -82.01 MB      -1.33 MB            20  \n",
            "                                        ToCopyBackward0         0.33%      13.956ms         4.38%     183.541ms      36.130us       0.000us         0.00%     134.845ms      26.544us           0 B           0 B      14.95 GB           0 B          5080  \n",
            "                                           aten::matmul         0.48%      20.312ms         3.90%     163.432ms      66.980us       0.000us         0.00%      45.186ms      18.519us           0 B           0 B       4.25 GB           0 B          2440  \n",
            "                                            aten::addmm         2.80%     117.331ms         3.79%     159.017ms     107.444us     154.719ms        10.73%     155.213ms     104.874us           0 B           0 B       4.75 GB       4.75 GB          1480  \n",
            "                                    aten::empty_strided         3.02%     126.652ms         3.06%     128.226ms       6.295us       0.000us         0.00%       0.000us       0.000us           0 B           0 B      43.87 GB      43.87 GB         20368  \n",
            "                                                aten::t         1.24%      52.157ms         2.99%     125.485ms       8.299us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B         15120  \n",
            "                              Optimizer.step#AdamW.step         1.13%      47.513ms         2.84%     119.070ms       5.953ms       0.000us         0.00%      10.426ms     521.309us         496 B        -160 B       9.11 MB     -91.12 MB            20  \n",
            "     autograd::engine::evaluate_function: ViewBackward0         0.94%      39.547ms         2.50%     104.927ms      17.258us       0.000us         0.00%      33.924ms       5.580us           0 B           0 B      -2.64 GB      -2.64 GB          6080  \n",
            "                                        aten::transpose         1.58%      66.172ms         2.35%      98.375ms       4.943us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B         19900  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 4.191s\n",
            "Self CUDA time total: 1.442s\n",
            "\n",
            "\n",
            "By CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us        1.201s        83.31%        1.201s      60.064ms           0 B           0 B           0 B           0 B            20  \n",
            "                                           forward_pass         7.73%     323.957ms        31.02%        1.300s      64.989ms       0.000us         0.00%     668.199ms      33.410ms      13.28 KB       9.45 KB      16.94 GB     -33.16 GB            20  \n",
            "                                           aten::linear         1.36%      57.165ms        25.79%        1.081s     137.846us       0.000us         0.00%     539.753ms      68.846us           0 B           0 B      25.58 GB      -2.23 GB          7840  \n",
            "                                            aten::copy_         2.86%     119.666ms         5.89%     246.749ms      17.401us     328.555ms        22.78%     328.616ms      23.175us           0 B           0 B           0 B           0 B         14180  \n",
            "                                               aten::to         0.80%      33.646ms        11.20%     469.505ms      24.889us       0.000us         0.00%     328.502ms      17.414us           0 B           0 B      31.14 GB           0 B         18864  \n",
            "                                         aten::_to_copy         2.27%      95.013ms        10.40%     435.859ms      30.825us       0.000us         0.00%     328.502ms      23.232us           0 B           0 B      31.14 GB           0 B         14140  \n",
            "                                               aten::mm         7.08%     296.841ms         9.53%     399.545ms      45.819us     293.191ms        20.33%     293.227ms      33.627us           0 B           0 B      13.07 GB      13.07 GB          8720  \n",
            "                                         optimizer_step         0.00%       0.000us         0.00%       0.000us       0.000us     225.368ms        15.63%     225.368ms      11.268ms           0 B           0 B           0 B           0 B            20  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.97%      40.816ms         5.69%     238.651ms      46.978us       0.000us         0.00%     189.616ms      37.326us           0 B           0 B    -450.32 MB     -15.39 GB          5080  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     186.621ms        12.94%     186.621ms      21.219us           0 B           0 B           0 B           0 B          8795  \n",
            "                                            aten::addmm         2.80%     117.331ms         3.79%     159.017ms     107.444us     154.719ms        10.73%     155.213ms     104.874us           0 B           0 B       4.75 GB       4.75 GB          1480  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.33%      13.937ms         2.28%      95.396ms      67.180us       0.000us         0.00%     143.207ms     100.850us           0 B           0 B      -3.31 GB      -7.93 GB          1420  \n",
            "                                         AddmmBackward0         0.24%       9.921ms         1.92%      80.551ms      56.726us       0.000us         0.00%     143.104ms     100.777us           0 B           0 B       4.62 GB           0 B          1420  \n",
            "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us     141.295ms         9.80%     141.295ms      27.705us           0 B           0 B           0 B           0 B          5100  \n",
            "                                        ToCopyBackward0         0.33%      13.956ms         4.38%     183.541ms      36.130us       0.000us         0.00%     134.845ms      26.544us           0 B           0 B      14.95 GB           0 B          5080  \n",
            "autograd::engine::evaluate_function: NativeDropoutBa...         0.42%      17.679ms         2.01%      84.254ms      50.151us       0.000us         0.00%     134.252ms      79.912us           0 B           0 B      -5.93 GB     -15.24 GB          1680  \n",
            "                                             aten::add_         0.61%      25.593ms         0.98%      41.075ms       8.968us     130.615ms         9.06%     130.615ms      28.519us           0 B           0 B           0 B           0 B          4580  \n",
            "                                          aten::dropout         0.16%       6.861ms         2.28%      95.427ms      54.843us       0.000us         0.00%     105.565ms      60.669us           0 B           0 B      12.52 GB    -120.00 MB          1740  \n",
            "                                   aten::native_dropout         0.86%      35.993ms         2.11%      88.565ms      50.900us     105.538ms         7.32%     105.565ms      60.669us           0 B           0 B      12.64 GB           0 B          1740  \n",
            "       autograd::engine::evaluate_function: MmBackward0         0.87%      36.302ms         8.25%     345.587ms     141.634us       0.000us         0.00%     104.937ms      43.007us           0 B           0 B      -4.35 GB      -8.56 GB          2440  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 4.191s\n",
            "Self CUDA time total: 1.442s\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "⚠ Failed to log profiler table: 'FunctionEventAvg' object has no attribute 'cuda_time_total'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:10<00:00, 10.84it/s]\n",
            "12/20/2025 02:24:38 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:24:38 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:24:38 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:24:38 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:24:38 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:24:38 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:24:38 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:24:38 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:24:38 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:24:38 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:24:38 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 10.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.45803888600606185]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:10<00:00, 10.85it/s]\n",
            "12/20/2025 02:24:50 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:24:50 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:24:50 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:24:50 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:24:50 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:24:50 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:24:50 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:24:50 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:24:50 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:24:50 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:24:50 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 10.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.45803888600606185, 0.3298683235278496]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:10<00:00, 10.88it/s]\n",
            "12/20/2025 02:25:02 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:25:02 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:25:02 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:25:02 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:25:02 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:25:02 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:25:02 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:25:02 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:25:02 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:25:02 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:25:02 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 10.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.45803888600606185, 0.3298683235278496, 0.28941168922644395]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:10<00:00, 10.89it/s]\n",
            "12/20/2025 02:25:14 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:25:14 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:25:14 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:25:14 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:25:14 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:25:14 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:25:14 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:25:14 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:25:14 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:25:14 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:25:14 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.45803888600606185, 0.3298683235278496, 0.28941168922644395, 0.28941168922644395]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:09<00:00, 10.97it/s]\n",
            "12/20/2025 02:25:26 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:25:26 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:25:26 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:25:26 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:25:26 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:25:26 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:25:26 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:25:26 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:25:26 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:25:26 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:25:26 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.45803888600606185, 0.3298683235278496, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:10<00:00, 10.87it/s]\n",
            "12/20/2025 02:25:38 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:25:38 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:25:38 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:25:38 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:25:38 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:25:38 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:25:38 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:25:38 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:25:38 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:25:38 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:25:38 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.45803888600606185, 0.3298683235278496, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:09<00:00, 10.97it/s]\n",
            "12/20/2025 02:25:50 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:25:50 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:25:50 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:25:50 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:25:50 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:25:50 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:25:50 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:25:50 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:25:50 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:25:50 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:25:50 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.45803888600606185, 0.3298683235278496, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:09<00:00, 10.93it/s]\n",
            "12/20/2025 02:26:02 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:26:02 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:26:02 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:26:02 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:26:02 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:26:02 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:26:02 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:26:02 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:26:02 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:26:02 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:26:02 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.45803888600606185, 0.3298683235278496, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:09<00:00, 11.05it/s]\n",
            "12/20/2025 02:26:14 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:26:14 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:26:14 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:26:14 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:26:14 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:26:14 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:26:14 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:26:14 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:26:14 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:26:14 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:26:14 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.45803888600606185, 0.3298683235278496, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:09<00:00, 11.02it/s]\n",
            "12/20/2025 02:26:26 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:26:26 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 02:26:26 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 02:26:26 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:26:26 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:26:26 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:26:26 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 02:26:26 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:26:26 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 02:26:26 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:26:26 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.45803888600606185, 0.3298683235278496, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395, 0.28941168922644395]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 10/10 [02:00<00:00, 12.01s/it]\n"
          ]
        }
      ],
      "source": [
        "# Baseline (FP32) model and training\n",
        "bertmodel_fp32 = AutoModelForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased', cache_dir=None, num_labels=3\n",
        ")\n",
        "\n",
        "config_baseline = Config(\n",
        "    data_dir=cl_data_path,\n",
        "    bert_model=bertmodel_fp32,\n",
        "\n",
        "    # updated to optimal (vague-sweep-12)\n",
        "    num_train_epochs=10,\n",
        "    max_seq_length=48,\n",
        "    train_batch_size=32,\n",
        "    learning_rate=0.000964072700118,\n",
        "    warm_up_proportion=0.265341258915704,\n",
        "\n",
        "    # enable LoRA so this run is \"all optimizations\" (except AMP here, still FP32)\n",
        "    use_lora=True,\n",
        "    lora_r=8,\n",
        "    lora_alpha=8,\n",
        "    lora_dropout=0.0238539130648572,\n",
        "    lora_target_modules=[\"query\", \"value\", \"dense\"],\n",
        "\n",
        "    # unchanged\n",
        "    model_dir=cl_path_baseline,  # Changed from cl_path\n",
        "    output_mode='classification',\n",
        "    local_rank=-1,\n",
        "    discriminate=False,\n",
        "    gradual_unfreeze=False,\n",
        "    use_amp=False,  # Baseline uses FP32\n",
        ")\n",
        "config_baseline.profile_train_steps = 20\n",
        "\n",
        "finbert_fp32 = ProfiledFinBert(config_baseline)\n",
        "finbert_fp32.base_model = 'bert-base-uncased'\n",
        "finbert_fp32.prepare_model(label_list=['positive', 'negative', 'neutral'])\n",
        "\n",
        "train_data = finbert_fp32.get_data('train')\n",
        "test_data = finbert_fp32.get_data('test')\n",
        "\n",
        "model_fp32 = finbert_fp32.create_the_model()\n",
        "\n",
        "# Train FP32\n",
        "start = time.perf_counter()\n",
        "trained_model_fp32 = finbert_fp32.train(train_examples=train_data, model=model_fp32)\n",
        "baseline_train_wall_s = time.perf_counter() - start\n",
        "\n",
        "# AMP model and training\n",
        "bertmodel_amp = AutoModelForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased', cache_dir=None, num_labels=3\n",
        ")\n",
        "\n",
        "config_amp = Config(\n",
        "    data_dir=cl_data_path,\n",
        "    bert_model=bertmodel_amp,\n",
        "\n",
        "    # updated to optimal (vague-sweep-12)\n",
        "    num_train_epochs=10,\n",
        "    max_seq_length=48,\n",
        "    train_batch_size=32,\n",
        "    learning_rate=0.000964072700118,\n",
        "    warm_up_proportion=0.265341258915704,\n",
        "\n",
        "    # enable LoRA here too (AMP + LoRA together)\n",
        "    use_lora=True,\n",
        "    lora_r=8,\n",
        "    lora_alpha=8,\n",
        "    lora_dropout=0.0238539130648572,\n",
        "    lora_target_modules=[\"query\", \"value\", \"dense\"],\n",
        "\n",
        "    # unchanged\n",
        "    model_dir=cl_path_amp,  # Changed from cl_path\n",
        "    output_mode='classification',\n",
        "    local_rank=-1,\n",
        "    discriminate=False,\n",
        "    gradual_unfreeze=False,\n",
        "    use_amp=True,  # Enable AMP\n",
        ")\n",
        "config_amp.profile_train_steps = 20\n",
        "\n",
        "finbert_amp = ProfiledFinBert(config_amp)\n",
        "finbert_amp.base_model = 'bert-base-uncased'\n",
        "finbert_amp.prepare_model(label_list=['positive', 'negative', 'neutral'])\n",
        "\n",
        "train_data = finbert_amp.get_data('train')\n",
        "test_data = finbert_amp.get_data('test')\n",
        "\n",
        "# train_data and test_data already loaded above\n",
        "model_amp = finbert_amp.create_the_model()\n",
        "    \n",
        "# Train AMP\n",
        "start = time.perf_counter()\n",
        "trained_model_amp = finbert_amp.train(train_examples=train_data, model=model_amp)\n",
        "amp_train_wall_s = time.perf_counter() - start\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/20/2025 02:27:50 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:27:50 - INFO - finbert.utils -   guid: test-1\n",
            "12/20/2025 02:27:50 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/20/2025 02:27:50 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:27:50 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:27:50 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:27:50 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/20/2025 02:27:50 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:27:50 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/20/2025 02:27:50 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:27:50 - INFO - finbert.finbert -     Num steps = 120\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/20/2025 02:27:53 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:27:53 - INFO - finbert.utils -   guid: test-1\n",
            "12/20/2025 02:27:53 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/20/2025 02:27:53 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:27:53 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:27:53 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:27:53 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/20/2025 02:27:53 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:27:53 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/20/2025 02:27:53 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:27:53 - INFO - finbert.finbert -     Num steps = 120\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline - Accuracy: 0.8330, F1: 0.8235\n",
            "Baseline - Throughput: 337.5 samples/sec\n",
            "Trained AMP Model - Accuracy: 0.8237, F1: 0.8152\n",
            "Trained AMP Model - Throughput: 927.4 samples/sec\n"
          ]
        }
      ],
      "source": [
        "def timed_eval(*, finbert, model, examples, use_amp=False):\n",
        "    \"\"\"Evaluation with timing.\"\"\"\n",
        "    loader = finbert.get_loader(examples, phase=\"eval\")\n",
        "    device = finbert.device\n",
        "    model.eval()\n",
        "    \n",
        "    preds, labels = [], []\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize(device)\n",
        "    \n",
        "    start = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, attention_mask, token_type_ids, label_ids, _ = batch\n",
        "            \n",
        "            if use_amp and device.type == \"cuda\":\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    outputs = model(\n",
        "                        input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        token_type_ids=token_type_ids\n",
        "                        )\n",
        "                    logits = outputs.logits\n",
        "            else:\n",
        "                outputs = model(\n",
        "                        input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        token_type_ids=token_type_ids\n",
        "                        )\n",
        "                logits = outputs.logits\n",
        "            \n",
        "            preds.extend(logits.detach().cpu().numpy())\n",
        "            labels.extend(label_ids.detach().cpu().numpy().tolist())\n",
        "    \n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize(device)\n",
        "    \n",
        "    wall_s = time.perf_counter() - start\n",
        "    n = len(labels)\n",
        "    \n",
        "    return pd.DataFrame({\"predictions\": preds, \"labels\": labels}), {\n",
        "        \"eval_wall_s\": wall_s,\n",
        "        \"eval_samples_per_s\": n / wall_s if wall_s > 0 else float(\"inf\"),\n",
        "    }\n",
        "\n",
        "def get_metrics(df):\n",
        "    \"\"\"Extract accuracy and F1 from eval results.\"\"\"\n",
        "    preds = np.array([np.argmax(p) for p in df['predictions']])\n",
        "    labels = np.array(df['labels'])\n",
        "    acc = (preds == labels).mean()\n",
        "    from sklearn.metrics import f1_score\n",
        "    f1 = f1_score(labels, preds, average='macro')\n",
        "    return {\"accuracy\": acc, \"f1_macro\": f1}\n",
        "\n",
        "# Evaluate baseline\n",
        "baseline_eval_df, baseline_timing = timed_eval(finbert=finbert_fp32, model=trained_model_fp32, examples=test_data, use_amp=False)\n",
        "baseline_metrics = get_metrics(baseline_eval_df)\n",
        "\n",
        "print(f\"Baseline - Accuracy: {baseline_metrics['accuracy']:.4f}, F1: {baseline_metrics['f1_macro']:.4f}\")\n",
        "print(f\"Baseline - Throughput: {baseline_timing['eval_samples_per_s']:.1f} samples/sec\")\n",
        "\n",
        "\n",
        "amp_trained_eval_df, amp_trained_timing = timed_eval(\n",
        "    finbert=finbert_amp, model=trained_model_amp, examples=test_data, use_amp=True\n",
        ")\n",
        "amp_trained_metrics = get_metrics(amp_trained_eval_df)\n",
        "print(f\"Trained AMP Model - Accuracy: {amp_trained_metrics['accuracy']:.4f}, F1: {amp_trained_metrics['f1_macro']:.4f}\")\n",
        "print(f\"Trained AMP Model - Throughput: {amp_trained_timing['eval_samples_per_s']:.1f} samples/sec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/si2449/hpml-project/pipelines/finBERT/models/mem_opt_comparison/baseline and are newly initialized: ['bert.embeddings.LayerNorm.bias', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "12/20/2025 02:28:02 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:28:02 - INFO - finbert.utils -   guid: test-1\n",
            "12/20/2025 02:28:02 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/20/2025 02:28:02 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:28:02 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:28:02 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:28:02 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/20/2025 02:28:02 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:28:02 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/20/2025 02:28:02 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:28:02 - INFO - finbert.finbert -     Num steps = 120\n",
            "12/20/2025 02:28:03 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 02:28:03 - INFO - finbert.utils -   guid: test-1\n",
            "12/20/2025 02:28:03 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/20/2025 02:28:03 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:28:03 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:28:03 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 02:28:03 - INFO - finbert.utils -   label: positive (id = 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FP16 - Accuracy: 0.1330, F1: 0.0789\n",
            "FP16 - Throughput: 1840.6 samples/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/20/2025 02:28:03 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 02:28:03 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/20/2025 02:28:03 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 02:28:03 - INFO - finbert.finbert -     Num steps = 120\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AMP - Accuracy: 0.8237, F1: 0.8152\n",
            "AMP - Throughput: 890.4 samples/sec\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>variant</th>\n",
              "      <th>model_size_mb</th>\n",
              "      <th>eval_wall_s</th>\n",
              "      <th>eval_samples_per_s</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>baseline</td>\n",
              "      <td>422.213890</td>\n",
              "      <td>2.873704</td>\n",
              "      <td>337.543477</td>\n",
              "      <td>0.832990</td>\n",
              "      <td>0.823511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fp16_weights</td>\n",
              "      <td>208.833014</td>\n",
              "      <td>0.526991</td>\n",
              "      <td>1840.638564</td>\n",
              "      <td>0.132990</td>\n",
              "      <td>0.078945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amp_autocast</td>\n",
              "      <td>422.213890</td>\n",
              "      <td>1.089339</td>\n",
              "      <td>890.447952</td>\n",
              "      <td>0.823711</td>\n",
              "      <td>0.815241</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        variant  model_size_mb  eval_wall_s  eval_samples_per_s  accuracy  \\\n",
              "0      baseline     422.213890     2.873704          337.543477  0.832990   \n",
              "1  fp16_weights     208.833014     0.526991         1840.638564  0.132990   \n",
              "2  amp_autocast     422.213890     1.089339          890.447952  0.823711   \n",
              "\n",
              "   f1_macro  \n",
              "0  0.823511  \n",
              "1  0.078945  \n",
              "2  0.815241  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = finbert_fp32.device\n",
        "all_results = []\n",
        "\n",
        "# ===== BASELINE =====\n",
        "all_results.append({\n",
        "    \"variant\": \"baseline\",\n",
        "    \"model_size_mb\": get_model_size_mb(trained_model_fp32),\n",
        "    **baseline_timing,\n",
        "    **baseline_metrics,\n",
        "})\n",
        "\n",
        "# ===== FP16 WEIGHTS =====\n",
        "if device.type == \"cuda\":\n",
        "    # Load model with FP16 weights\n",
        "    fp16_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        cl_path_baseline, num_labels=3, dtype=torch.float16  # Changed from cl_path\n",
        "    ).to(device)\n",
        "    \n",
        "    fp16_eval_df, fp16_timing = timed_eval(finbert=finbert_fp32, model=fp16_model, examples=test_data, use_amp=False)\n",
        "    fp16_metrics = get_metrics(fp16_eval_df)\n",
        "    \n",
        "    all_results.append({\n",
        "        \"variant\": \"fp16_weights\",\n",
        "        \"model_size_mb\": get_model_size_mb(fp16_model),\n",
        "        **fp16_timing,\n",
        "        **fp16_metrics,\n",
        "    })\n",
        "    print(f\"FP16 - Accuracy: {fp16_metrics['accuracy']:.4f}, F1: {fp16_metrics['f1_macro']:.4f}\")\n",
        "    print(f\"FP16 - Throughput: {fp16_timing['eval_samples_per_s']:.1f} samples/sec\")\n",
        "else:\n",
        "    print(\"Skipping FP16 (requires CUDA)\")\n",
        "\n",
        "# ===== AMP AUTOCAST =====\n",
        "if device.type == \"cuda\":\n",
        "    # Use baseline model with AMP autocast during inference\n",
        "    amp_eval_df, amp_timing = timed_eval(finbert=finbert_amp, model=trained_model_amp, examples=test_data, use_amp=True)\n",
        "    amp_metrics = get_metrics(amp_eval_df)\n",
        "    \n",
        "    all_results.append({\n",
        "        \"variant\": \"amp_autocast\",\n",
        "        \"model_size_mb\": get_model_size_mb(trained_model_amp),\n",
        "        **amp_timing,\n",
        "        **amp_metrics,\n",
        "    })\n",
        "    print(f\"AMP - Accuracy: {amp_metrics['accuracy']:.4f}, F1: {amp_metrics['f1_macro']:.4f}\")\n",
        "    print(f\"AMP - Throughput: {amp_timing['eval_samples_per_s']:.1f} samples/sec\")\n",
        "else:\n",
        "    print(\"Skipping AMP (requires CUDA)\")\n",
        "\n",
        "results_df = pd.DataFrame(all_results)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/20/2025 02:28:16 - INFO - matplotlib.font_manager -   generated new fontManager\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x400 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Speedup vs Baseline ===\n",
            "FP16 weights: 5.45x speedup, Δaccuracy=-0.7000\n",
            "Trained AMP (use_amp=True): 2.64x speedup, Δaccuracy=-0.0093\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Stable ordering + nicer display names\n",
        "preferred_order = [\"baseline\", \"fp16_weights\", \"trained_amp\", \"amp_trained\", \"amp_autocast\"]\n",
        "present = results_df[\"variant\"].tolist()\n",
        "order = [v for v in preferred_order if v in present] + [v for v in present if v not in preferred_order]\n",
        "\n",
        "display_name = {\n",
        "    \"baseline\": \"Baseline (FP32)\",\n",
        "    \"fp16_weights\": \"FP16 weights\",\n",
        "    \"trained_amp\": \"Trained AMP (use_amp=True)\",\n",
        "    \"amp_trained\": \"Trained AMP (use_amp=True)\",\n",
        "    \"amp_autocast\": \"Trained AMP (use_amp=True)\",\n",
        "}\n",
        "\n",
        "variant_color = {\n",
        "    \"baseline\": \"#2ecc71\",\n",
        "    \"fp16_weights\": \"#3498db\",\n",
        "    \"trained_amp\": \"#e74c3c\",\n",
        "    \"amp_trained\": \"#e74c3c\",\n",
        "    \"amp_autocast\": \"#e74c3c\",\n",
        "}\n",
        "\n",
        "plot_df = results_df.set_index(\"variant\").loc[order]\n",
        "colors = [variant_color.get(v, \"#95a5a6\") for v in plot_df.index]\n",
        "xticklabels = [display_name.get(v, v) for v in plot_df.index]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
        "\n",
        "# Throughput\n",
        "ax = axes[0]\n",
        "plot_df[\"eval_samples_per_s\"].plot(kind=\"bar\", ax=ax, color=colors)\n",
        "ax.set_title(\"Inference Throughput\")\n",
        "ax.set_ylabel(\"samples/sec\")\n",
        "ax.set_xticklabels(xticklabels, rotation=0)\n",
        "\n",
        "# Accuracy\n",
        "ax = axes[1]\n",
        "plot_df[\"accuracy\"].plot(kind=\"bar\", ax=ax, color=colors)\n",
        "ax.set_title(\"Accuracy\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_ylim(0.7, 1.0)\n",
        "ax.set_xticklabels(xticklabels, rotation=0)\n",
        "\n",
        "# Model Size\n",
        "ax = axes[2]\n",
        "plot_df[\"model_size_mb\"].plot(kind=\"bar\", ax=ax, color=colors)\n",
        "ax.set_title(\"Model Size\")\n",
        "ax.set_ylabel(\"MB\")\n",
        "ax.set_xticklabels(xticklabels, rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Speedup summary\n",
        "if len(plot_df) > 1 and \"baseline\" in plot_df.index:\n",
        "    base = plot_df.loc[\"baseline\"]\n",
        "    print(\"\\n=== Speedup vs Baseline ===\")\n",
        "    for variant, row in plot_df.iterrows():\n",
        "        if variant == \"baseline\":\n",
        "            continue\n",
        "        speedup = row[\"eval_samples_per_s\"] / base[\"eval_samples_per_s\"]\n",
        "        delta_acc = row[\"accuracy\"] - base[\"accuracy\"]\n",
        "        print(f\"{display_name.get(variant, variant)}: {speedup:.2f}x speedup, Δaccuracy={delta_acc:+.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>variant</th>\n",
              "      <th>model_size_mb</th>\n",
              "      <th>eval_wall_s</th>\n",
              "      <th>eval_samples_per_s</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>baseline</td>\n",
              "      <td>422.213890</td>\n",
              "      <td>2.873704</td>\n",
              "      <td>337.543477</td>\n",
              "      <td>0.832990</td>\n",
              "      <td>0.823511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fp16_weights</td>\n",
              "      <td>208.833014</td>\n",
              "      <td>0.526991</td>\n",
              "      <td>1840.638564</td>\n",
              "      <td>0.132990</td>\n",
              "      <td>0.078945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amp_autocast</td>\n",
              "      <td>422.213890</td>\n",
              "      <td>1.089339</td>\n",
              "      <td>890.447952</td>\n",
              "      <td>0.823711</td>\n",
              "      <td>0.815241</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        variant  model_size_mb  eval_wall_s  eval_samples_per_s  accuracy  \\\n",
              "0      baseline     422.213890     2.873704          337.543477  0.832990   \n",
              "1  fp16_weights     208.833014     0.526991         1840.638564  0.132990   \n",
              "2  amp_autocast     422.213890     1.089339          890.447952  0.823711   \n",
              "\n",
              "   f1_macro  \n",
              "0  0.823511  \n",
              "1  0.078945  \n",
              "2  0.815241  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>amp_accuracy</td><td>▁</td></tr><tr><td>amp_f1</td><td>▁</td></tr><tr><td>amp_model_size</td><td>▁</td></tr><tr><td>amp_throughput</td><td>▁</td></tr><tr><td>amp_train_wall_s</td><td>▁</td></tr><tr><td>baseline_accuracy</td><td>▁</td></tr><tr><td>baseline_f1</td><td>▁</td></tr><tr><td>baseline_model_size</td><td>▁</td></tr><tr><td>baseline_throughput</td><td>▁</td></tr><tr><td>baseline_train_wall_s</td><td>▁</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>amp_accuracy</td><td>0.82371</td></tr><tr><td>amp_f1</td><td>0.81524</td></tr><tr><td>amp_model_size</td><td>422.21389</td></tr><tr><td>amp_throughput</td><td>890.44795</td></tr><tr><td>amp_train_wall_s</td><td>204.09771</td></tr><tr><td>baseline_accuracy</td><td>0.83299</td></tr><tr><td>baseline_f1</td><td>0.82351</td></tr><tr><td>baseline_model_size</td><td>422.21389</td></tr><tr><td>baseline_throughput</td><td>337.54348</td></tr><tr><td>baseline_train_wall_s</td><td>310.93659</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">mem-opt-comparison</strong> at: <a href='https://wandb.ai/si2449-columbia-university/Project-Runs/runs/lnygxq0l' target=\"_blank\">https://wandb.ai/si2449-columbia-university/Project-Runs/runs/lnygxq0l</a><br> View project at: <a href='https://wandb.ai/si2449-columbia-university/Project-Runs' target=\"_blank\">https://wandb.ai/si2449-columbia-university/Project-Runs</a><br>Synced 4 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251220_021748-lnygxq0l/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Log summary to W&B\n",
        "summary = {\n",
        "    \"baseline_train_wall_s\": baseline_train_wall_s,\n",
        "    \"baseline_accuracy\": baseline_metrics[\"accuracy\"],\n",
        "    \"baseline_f1\": baseline_metrics[\"f1_macro\"],\n",
        "    \"baseline_throughput\": baseline_timing[\"eval_samples_per_s\"],\n",
        "    \"baseline_model_size\": get_model_size_mb(trained_model_fp32),\n",
        "}\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    summary.update({\n",
        "        \"fp16_accuracy\": fp16_metrics[\"accuracy\"],\n",
        "        \"fp16_throughput\": fp16_timing[\"eval_samples_per_s\"],\n",
        "        \"fp16_model_size\": get_model_size_mb(fp16_model),\n",
        "        \"amp_train_wall_s\": amp_train_wall_s,\n",
        "        \"amp_accuracy\": amp_metrics[\"accuracy\"],\n",
        "        \"amp_f1\": amp_metrics[\"f1_macro\"],\n",
        "        \"amp_throughput\": amp_timing[\"eval_samples_per_s\"],\n",
        "        \"amp_model_size\": get_model_size_mb(trained_model_amp),\n",
        "    })\n",
        "\n",
        "wandb.log(summary)\n",
        "\n",
        "# We'll upload the results_df (or plot_df) as a W&B Table for interactive dashboards\n",
        "\n",
        "# Option 1: upload the underlying DataFrame as a W&B Table\n",
        "# (works best if your DataFrame columns cover all metrics you'd like to compare)\n",
        "table = wandb.Table(dataframe=results_df)\n",
        "\n",
        "wandb.log({\"variant_summary_table\": table})\n",
        "\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
