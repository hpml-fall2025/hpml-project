{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FinBERT Profiling: Baseline vs FP16 vs AMP\n",
        "\n",
        "This notebook is intentionally **thin**: it reuses the profiling utilities in `pipelines/finBERT/finbert/` (especially `finbert/finbert_profile.py` and `finbert/profile_utils.py`) instead of copying large code blocks.\n",
        "\n",
        "### What this notebook compares\n",
        "- **Training**: Baseline (FP32) vs **AMP** (autocast + GradScaler) — wall time + profiler breakdown + accuracy\n",
        "- **Inference** (from the **baseline checkpoint**): FP32 vs **FP16-weights** vs **AMP-autocast** — throughput/latency + accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick start\n",
        "\n",
        "1. Run **Setup + Config + Helpers** (cells 2–4).\n",
        "2. Run **Training** (cell 5) to train/eval **baseline** and **AMP**.\n",
        "3. Run **Inference benchmarking** (cell 6) to benchmark **baseline / FP16-weights / AMP-autocast** off the baseline checkpoint.\n",
        "4. Run **Results** (cell 7) to see comparison tables and plots.\n",
        "\n",
        "### Notes\n",
        "- **AMP and FP16 are only enabled on CUDA by default** (to avoid MPS/CPU autocast edge cases).\n",
        "- If you already have a trained checkpoint you want to use, set `BASELINE_CKPT_DIR` in the config cell and set `RUN_TRAIN_BASELINE = False`.\n",
        "- This notebook follows the same “thin notebook, modules do the work” style as `finbert_sweep.ipynb`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Helper utilities loaded\n",
            "✓ FINBERT_ROOT: /home/srm2245/hpml-project/pipelines/finBERT\n",
            "✓ PROJECT_ROOT: /home/srm2245/hpml-project\n",
            "✓ torch: 2.9.1+cu128\n",
            "✓ cuda available: True\n",
            "✓ mps available: False\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Silence noisy deprecations (we still keep runtime-correct code)\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=FutureWarning,\n",
        "    message=\"`torch\\\\.cuda\\\\.amp\\\\.autocast\\\\(args\\\\.\\\\.\\\\.\\\\)` is deprecated\",\n",
        ")\n",
        "\n",
        "\n",
        "def _find_finbert_root(start: Path) -> Path:\n",
        "    \"\"\"Return the directory that contains the `finbert/` package.\"\"\"\n",
        "    start = start.resolve()\n",
        "    for p in [start, *start.parents]:\n",
        "        if (p / \"finbert\").is_dir() and (p / \"finbert\" / \"finbert.py\").exists():\n",
        "            return p\n",
        "        if (p / \"pipelines\" / \"finBERT\" / \"finbert\").is_dir():\n",
        "            return p / \"pipelines\" / \"finBERT\"\n",
        "    raise FileNotFoundError(\n",
        "        \"Could not locate finBERT root. Expected a folder containing finbert/finbert.py\"\n",
        "    )\n",
        "\n",
        "\n",
        "FINBERT_ROOT = _find_finbert_root(Path.cwd())\n",
        "if str(FINBERT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(FINBERT_ROOT))\n",
        "\n",
        "PROJECT_ROOT = FINBERT_ROOT.parents[1] if FINBERT_ROOT.name == \"finBERT\" else FINBERT_ROOT.parent\n",
        "\n",
        "from finbert.finbert import Config, FinBert\n",
        "from finbert.finbert_profile import ProfiledFinBert, profile_inference\n",
        "from finbert.profile_utils import get_model_size_mb, print_device_info, setup_nltk_data\n",
        "from finbert.utils import get_device\n",
        "\n",
        "LABEL_LIST = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 120)\n",
        "\n",
        "print(\"✓ FINBERT_ROOT:\", FINBERT_ROOT)\n",
        "print(\"✓ PROJECT_ROOT:\", PROJECT_ROOT)\n",
        "print(\"✓ torch:\", torch.__version__)\n",
        "print(\"✓ cuda available:\", torch.cuda.is_available())\n",
        "print(\"✓ mps available:\", hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ DATA_DIR: /home/srm2245/hpml-project/pipelines/finBERT/data/sentiment_data\n",
            "✓ RUNS_DIR: /home/srm2245/hpml-project/pipelines/finBERT/models/profiling_runs\n",
            "✓ BASELINE_CKPT_DIR: /home/srm2245/hpml-project/pipelines/finBERT/models/sentiment\n",
            "✓ INFERENCE_VARIANTS: ['baseline', 'fp16_weights', 'amp_autocast']\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Experiment configuration\n",
        "# =========================\n",
        "\n",
        "BASE_MODEL_NAME = \"bert-base-uncased\"\n",
        "\n",
        "DATA_DIR = FINBERT_ROOT / \"data\" / \"sentiment_data\"\n",
        "\n",
        "# Where to write new trained models (kept separate from the shipped `models/sentiment` checkpoint)\n",
        "RUNS_DIR = FINBERT_ROOT / \"models\" / \"profiling_runs\"\n",
        "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# If you want to skip training, point this at an existing checkpoint directory\n",
        "BASELINE_CKPT_DIR = FINBERT_ROOT / \"models\" / \"sentiment\"\n",
        "\n",
        "# Training params (using optimal hyperparameters from W&B sweep: solar-sweep-21)\n",
        "TRAINING = dict(\n",
        "    num_train_epochs=6,\n",
        "    train_batch_size=32,\n",
        "    eval_batch_size=32,\n",
        "    learning_rate=1.4e-5,\n",
        "    warm_up_proportion=0.144,\n",
        "    max_seq_length=64,\n",
        "    discriminate=False,\n",
        "    gradual_unfreeze=False,\n",
        ")\n",
        "\n",
        "# Profiling params\n",
        "PROFILE_TRAIN_STEPS = 20  # first N optimizer steps to profile during training\n",
        "\n",
        "INFER_TEXT_BATCH_SIZE = 5\n",
        "INFER_TEST_TEXT = \"\"\"Later that day Apple said it was revising down its earnings expectations in \\\n",
        "The fourth quarter of 2018, largely because of lower sales and signs of economic weakness in China. \\\n",
        "The news rapidly infected financial markets. Apple's share price fell by around 7% in after-hours \\\n",
        "Trading and the decline was extended to more than 10% when the market opened. The dollar fell \\\n",
        "By 3.7% against the yen in a matter of minutes after the announcement, before rapidly recovering \\\n",
        "Some ground. Asian stockmarkets closed down on January 3rd and European ones opened lower. \\\n",
        "Yields on government bonds fell as investors fled to the traditional haven in a market storm.\"\"\"\n",
        "\n",
        "# Device settings\n",
        "PREFER_GPU = True\n",
        "GPU_NAME = \"cuda:0\"  # only used when CUDA is present\n",
        "\n",
        "# Optional W&B logging (same idea as `finbert_sweep.ipynb`)\n",
        "USE_WANDB = False\n",
        "WANDB_ENTITY = \"si2449-columbia-university\"\n",
        "WANDB_PROJECT = \"finbert-profiling\"\n",
        "WANDB_GROUP = \"profiling\"\n",
        "\n",
        "# Which runs to execute\n",
        "RUN_TRAIN_BASELINE = True\n",
        "RUN_TRAIN_AMP = True\n",
        "RUN_INFER_BENCHMARKS = True\n",
        "\n",
        "# Safety\n",
        "OVERWRITE_EXISTING_RUN_DIRS = True\n",
        "\n",
        "# Variants (edit here to add/remove)\n",
        "INFERENCE_VARIANTS = {\n",
        "    \"baseline\": {\"torch_dtype\": None, \"use_amp\": False, \"requires_cuda\": False},\n",
        "    \"fp16_weights\": {\"torch_dtype\": torch.float16, \"use_amp\": False, \"requires_cuda\": True},\n",
        "    \"amp_autocast\": {\"torch_dtype\": None, \"use_amp\": True, \"requires_cuda\": True},\n",
        "}\n",
        "\n",
        "print(\"✓ DATA_DIR:\", DATA_DIR)\n",
        "print(\"✓ RUNS_DIR:\", RUNS_DIR)\n",
        "print(\"✓ BASELINE_CKPT_DIR:\", BASELINE_CKPT_DIR)\n",
        "print(\"✓ INFERENCE_VARIANTS:\", list(INFERENCE_VARIANTS.keys()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Helper functions loaded\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from contextlib import nullcontext\n",
        "from typing import Any\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "def resolve_device(prefer_gpu: bool = True, gpu_name: str = \"cuda:0\") -> torch.device:\n",
        "    if not prefer_gpu:\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "    device = get_device(no_cuda=False)\n",
        "    if device.type == \"cuda\" and gpu_name.startswith(\"cuda:\"):\n",
        "        return torch.device(gpu_name)\n",
        "    return device\n",
        "\n",
        "\n",
        "def autocast_ctx(device: torch.device, enabled: bool):\n",
        "    if not enabled:\n",
        "        return nullcontext()\n",
        "    if device.type != \"cuda\":\n",
        "        # Keep this conservative: AMP is only enabled on CUDA in this notebook.\n",
        "        return nullcontext()\n",
        "    try:\n",
        "        return torch.amp.autocast(device_type=\"cuda\", enabled=True)\n",
        "    except Exception:\n",
        "        # Older torch fallback\n",
        "        return torch.cuda.amp.autocast(enabled=True)\n",
        "\n",
        "\n",
        "def make_run_dir(prefix: str) -> Path:\n",
        "    ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    run_dir = RUNS_DIR / f\"{prefix}_{ts}\"\n",
        "\n",
        "    if run_dir.exists() and OVERWRITE_EXISTING_RUN_DIRS:\n",
        "        import shutil\n",
        "\n",
        "        shutil.rmtree(run_dir)\n",
        "\n",
        "    if run_dir.exists() and any(run_dir.iterdir()):\n",
        "        raise ValueError(f\"Run dir exists and is not empty: {run_dir}\")\n",
        "\n",
        "    return run_dir\n",
        "\n",
        "\n",
        "def make_finbert_config(*, model_dir: Path, use_amp: bool) -> Config:\n",
        "    # Guard AMP to CUDA only (FinBERT training uses torch.cuda.amp.*)\n",
        "    use_amp = bool(use_amp and torch.cuda.is_available())\n",
        "\n",
        "    bertmodel = AutoModelForSequenceClassification.from_pretrained(\n",
        "        BASE_MODEL_NAME, cache_dir=None, num_labels=3\n",
        "    )\n",
        "\n",
        "    cfg = Config(\n",
        "        data_dir=DATA_DIR,\n",
        "        bert_model=bertmodel,\n",
        "        model_dir=model_dir,\n",
        "        max_seq_length=TRAINING[\"max_seq_length\"],\n",
        "        train_batch_size=TRAINING[\"train_batch_size\"],\n",
        "        eval_batch_size=TRAINING[\"eval_batch_size\"],\n",
        "        learning_rate=TRAINING[\"learning_rate\"],\n",
        "        num_train_epochs=TRAINING[\"num_train_epochs\"],\n",
        "        warm_up_proportion=TRAINING[\"warm_up_proportion\"],\n",
        "        local_rank=-1,\n",
        "        output_mode=\"classification\",\n",
        "        discriminate=TRAINING[\"discriminate\"],\n",
        "        gradual_unfreeze=TRAINING[\"gradual_unfreeze\"],\n",
        "        fp16=False,\n",
        "        use_amp=use_amp,\n",
        "    )\n",
        "\n",
        "    # Read by `ProfiledFinBert.train()` via `getattr(self.config, 'profile_train_steps', 20)`\n",
        "    cfg.profile_train_steps = PROFILE_TRAIN_STEPS\n",
        "\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def calculate_metrics(results_df: pd.DataFrame) -> dict[str, float]:\n",
        "    \"\"\"Sweep-style metrics: CE loss + accuracy + macro/per-class F1.\"\"\"\n",
        "    y_true = np.asarray(results_df[\"labels\"], dtype=np.int64)\n",
        "    logits = np.stack(results_df[\"predictions\"].to_numpy())\n",
        "    y_pred = logits.argmax(axis=1)\n",
        "\n",
        "    loss = F.cross_entropy(torch.tensor(logits, dtype=torch.float32), torch.tensor(y_true)).item()\n",
        "    acc = float((y_true == y_pred).mean())\n",
        "\n",
        "    f1_per = f1_score(y_true, y_pred, average=None, labels=[0, 1, 2])\n",
        "    f1_macro = float(f1_score(y_true, y_pred, average=\"macro\"))\n",
        "\n",
        "    return {\n",
        "        \"loss\": float(loss),\n",
        "        \"accuracy\": acc,\n",
        "        \"f1_positive\": float(f1_per[0]),\n",
        "        \"f1_negative\": float(f1_per[1]),\n",
        "        \"f1_neutral\": float(f1_per[2]),\n",
        "        \"f1_macro\": f1_macro,\n",
        "    }\n",
        "\n",
        "\n",
        "def timed_eval(\n",
        "    *, finbert: FinBert, model: torch.nn.Module, examples, use_amp: bool\n",
        ") -> tuple[pd.DataFrame, dict[str, Any]]:\n",
        "    \"\"\"Evaluation loop with optional CUDA autocast + timing (kept small for notebook use).\"\"\"\n",
        "    loader = finbert.get_loader(examples, phase=\"eval\")\n",
        "    device = finbert.device\n",
        "\n",
        "    model.eval()\n",
        "    preds: list[np.ndarray] = []\n",
        "    labels: list[int] = []\n",
        "\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize(device)\n",
        "\n",
        "    start = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, attention_mask, token_type_ids, label_ids, _agree_ids = batch\n",
        "\n",
        "            with autocast_ctx(device, enabled=bool(use_amp)):\n",
        "                logits = model(input_ids, attention_mask, token_type_ids)[0]\n",
        "\n",
        "            preds.extend(logits.detach().cpu().numpy())\n",
        "            labels.extend(label_ids.detach().cpu().numpy().tolist())\n",
        "\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize(device)\n",
        "\n",
        "    wall_s = time.perf_counter() - start\n",
        "    n = len(labels)\n",
        "\n",
        "    results_df = pd.DataFrame({\"predictions\": preds, \"labels\": labels})\n",
        "\n",
        "    timing = {\n",
        "        \"eval_wall_s\": float(wall_s),\n",
        "        \"eval_num_samples\": int(n),\n",
        "        \"eval_samples_per_s\": float(n / wall_s) if wall_s > 0 else float(\"inf\"),\n",
        "    }\n",
        "    return results_df, timing\n",
        "\n",
        "\n",
        "def maybe_wandb_init(run_name: str, config: dict[str, Any]):\n",
        "    if not USE_WANDB:\n",
        "        return None\n",
        "    try:\n",
        "        import wandb\n",
        "\n",
        "        return wandb.init(\n",
        "            entity=WANDB_ENTITY,\n",
        "            project=WANDB_PROJECT,\n",
        "            group=WANDB_GROUP,\n",
        "            name=run_name,\n",
        "            config=config,\n",
        "        )\n",
        "    except ImportError:\n",
        "        print(\"⚠ wandb is not installed; set USE_WANDB=False or install wandb\")\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"✓ Helper functions loaded\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Device: cuda:0\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 14.6 GB\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "12/14/2025 19:35:46 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "12/14/2025 19:35:48 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:35:48 - INFO - finbert.utils -   guid: train-1\n",
            "12/14/2025 19:35:48 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/14/2025 19:35:48 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:35:48 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:35:48 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:35:48 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/14/2025 19:35:48 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:35:48 - INFO - finbert.finbert -     Num examples = 3488\n",
            "12/14/2025 19:35:48 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:35:48 - INFO - finbert.finbert -     Num steps = 72\n",
            "/home/srm2245/hpml-project/pipelines/finBERT/finbert/finbert_profile.py:99: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=self.config.use_amp)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n================================================================================\n",
            "Starting Profiled Training\n",
            "Device: cuda\n",
            "Profiling activities: [<ProfilerActivity.CPU: 0>, <ProfilerActivity.CUDA: 2>]\n",
            "================================================================================\\n\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration:  17%|█▋        | 19/109 [00:06<00:30,  2.97it/s]\n",
            "Epoch:   0%|          | 0/6 [00:06<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n================================================================================\n",
            "Profiling complete for first epoch (20 steps)\n",
            "Continuing full training without profiling...\n",
            "================================================================================\\n\n",
            "\\n================================================================================\n",
            "PROFILING RESULTS - Training\n",
            "================================================================================\\n\n",
            "\\nBy CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                  cudaStreamSynchronize        61.30%        4.388s        61.30%        4.388s      27.426ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           160  \n",
            "                                             aten::item         0.17%      12.124ms        36.21%        2.592s     320.705us       0.000us         0.00%      64.223us       0.008us           0 B           0 B           0 B           0 B          8082  \n",
            "                              aten::_local_scalar_dense         0.08%       5.663ms        36.04%        2.580s     319.205us      64.223us         0.00%      64.223us       0.008us           0 B           0 B           0 B           0 B          8082  \n",
            "                                               aten::to         0.05%       3.362ms        25.63%        1.835s     368.371us       0.000us         0.00%     452.568us       0.091us           0 B           0 B      13.47 MB           0 B          4981  \n",
            "                                            aten::copy_         0.06%       4.268ms        25.62%        1.834s       4.168ms       1.539ms         0.03%       1.577ms       3.585us           0 B           0 B           0 B           0 B           440  \n",
            "                                         aten::_to_copy         0.02%       1.338ms        25.58%        1.831s      11.447ms       0.000us         0.00%     452.568us       2.829us           0 B           0 B      13.47 MB           0 B           160  \n",
            "                                       loss_calculation         0.13%       9.538ms        18.97%        1.358s      67.908ms       0.000us         0.00%     179.358us       8.968us           0 B           0 B      21.00 KB     -19.00 KB            20  \n",
            "                                          backward_pass         9.85%     704.974ms        12.55%     898.592ms      44.930ms       0.000us         0.00%      49.790us       2.490us      -3.75 KB      -3.75 KB     -15.27 GB     -15.27 GB            20  \n",
            "                                       cudaLaunchKernel         4.21%     301.111ms         8.87%     634.858ms      44.389us       0.000us         0.00%      98.983ms       6.921us           0 B           0 B           0 B           0 B         14302  \n",
            "                                           forward_pass         1.56%     111.606ms         8.62%     617.280ms      30.864ms       0.000us         0.00%        1.798s      89.905ms       3.75 KB         -80 B      23.61 GB      -6.00 GB            20  \n",
            "                       Runtime Triggered Module Loading         7.28%     520.969ms         7.28%     520.969ms       7.893ms      61.245ms         1.02%      61.245ms     927.952us           0 B           0 B           0 B           0 B            66  \n",
            "                                          data_transfer         0.03%       1.906ms         7.00%     501.200ms      25.060ms       0.000us         0.00%     191.552us       9.578us           0 B           0 B      49.00 KB    -931.00 KB            20  \n",
            "                                         optimizer_step         0.57%      40.514ms         5.23%     374.358ms      18.718ms       0.000us         0.00%     943.021ms      47.151ms         804 B           0 B      -7.51 GB      -2.03 MB            20  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.44%      31.737ms         3.83%     274.513ms     185.482us       0.000us         0.00%        2.897s       1.957ms           0 B           0 B      -2.01 GB     -21.22 GB          1480  \n",
            "                                           aten::linear         0.21%      15.134ms         3.77%     269.706ms     182.234us       0.000us         0.00%        1.573s       1.063ms           0 B           0 B      12.67 GB           0 B          1480  \n",
            "                              Optimizer.step#AdamW.step         0.96%      68.449ms         3.24%     231.916ms      11.596ms       0.000us         0.00%     817.404ms      40.870ms         804 B        -160 B     836.46 MB      -8.22 GB            20  \n",
            "                                            aten::addmm         0.94%      67.030ms         3.12%     223.247ms     150.842us        1.564s        25.94%        1.573s       1.063ms           0 B           0 B      12.67 GB      12.67 GB          1480  \n",
            "                                         AddmmBackward0         0.28%      20.316ms         2.43%     173.615ms     117.307us       0.000us         0.00%        2.812s       1.900ms           0 B           0 B      19.20 GB           0 B          1480  \n",
            "autograd::engine::evaluate_function: EmbeddingBackwa...         0.01%     490.165us         2.15%     153.863ms       2.564ms       0.000us         0.00%      14.613ms     243.544us           0 B           0 B       1.67 GB    -123.75 MB            60  \n",
            "                                     EmbeddingBackward0         0.00%     253.737us         2.14%     153.373ms       2.556ms       0.000us         0.00%      14.613ms     243.544us           0 B           0 B       1.79 GB           0 B            60  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 7.159s\n",
            "Self CUDA time total: 6.030s\n",
            "\n",
            "\\nBy CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.44%      31.737ms         3.83%     274.513ms     185.482us       0.000us         0.00%        2.897s       1.957ms           0 B           0 B      -2.01 GB     -21.22 GB          1480  \n",
            "                                         AddmmBackward0         0.28%      20.316ms         2.43%     173.615ms     117.307us       0.000us         0.00%        2.812s       1.900ms           0 B           0 B      19.20 GB           0 B          1480  \n",
            "                                               aten::mm         1.08%      77.151ms         1.62%     115.693ms      39.085us        2.812s        46.63%        2.812s     949.916us           0 B           0 B      19.20 GB      19.20 GB          2960  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us        1.931s        32.03%        1.931s      96.575ms           0 B           0 B           0 B           0 B            20  \n",
            "                                           forward_pass         1.56%     111.606ms         8.62%     617.280ms      30.864ms       0.000us         0.00%        1.798s      89.905ms       3.75 KB         -80 B      23.61 GB      -6.00 GB            20  \n",
            "                                           aten::linear         0.21%      15.134ms         3.77%     269.706ms     182.234us       0.000us         0.00%        1.573s       1.063ms           0 B           0 B      12.67 GB           0 B          1480  \n",
            "                                            aten::addmm         0.94%      67.030ms         3.12%     223.247ms     150.842us        1.564s        25.94%        1.573s       1.063ms           0 B           0 B      12.67 GB      12.67 GB          1480  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us        1.057s        17.52%        1.057s     880.492us           0 B           0 B           0 B           0 B          1200  \n",
            "                                  volta_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us     949.512ms        15.75%     949.512ms     791.260us           0 B           0 B           0 B           0 B          1200  \n",
            "                                         optimizer_step         0.57%      40.514ms         5.23%     374.358ms      18.718ms       0.000us         0.00%     943.021ms      47.151ms         804 B           0 B      -7.51 GB      -2.03 MB            20  \n",
            "                                  volta_sgemm_128x64_nt         0.00%       0.000us         0.00%       0.000us       0.000us     931.576ms        15.45%     931.576ms     763.587us           0 B           0 B           0 B           0 B          1220  \n",
            "                              Optimizer.step#AdamW.step         0.96%      68.449ms         3.24%     231.916ms      11.596ms       0.000us         0.00%     817.404ms      40.870ms         804 B        -160 B     836.46 MB      -8.22 GB            20  \n",
            "                              Optimizer.step#AdamW.step         0.00%       0.000us         0.00%       0.000us       0.000us     768.321ms        12.74%     768.321ms      38.416ms           0 B           0 B           0 B           0 B            20  \n",
            "                                 volta_sgemm_128x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     506.317ms         8.40%     506.317ms       2.110ms           0 B           0 B           0 B           0 B           240  \n",
            "                                 volta_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     466.288ms         7.73%     466.288ms       1.943ms           0 B           0 B           0 B           0 B           240  \n",
            "                                 volta_sgemm_128x128_nt         0.00%       0.000us         0.00%       0.000us       0.000us     460.955ms         7.64%     460.955ms       1.921ms           0 B           0 B           0 B           0 B           240  \n",
            "                                    aten::_foreach_mul_         0.13%       8.987ms         0.32%      23.225ms     290.309us     224.955ms         3.73%     247.555ms       3.094ms           0 B           0 B           0 B           0 B            80  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.08%       5.412ms         1.09%      78.016ms     325.066us       0.000us         0.00%     241.969ms       1.008ms      -3.75 KB      -3.75 KB      -2.84 GB      -7.06 GB           240  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.04%       2.536ms         1.01%      72.604ms     302.518us       0.000us         0.00%     241.969ms       1.008ms           0 B           0 B       4.22 GB           0 B           240  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.08%       5.676ms         0.98%      70.068ms     291.950us       0.000us         0.00%     241.969ms       1.008ms           0 B           0 B       4.22 GB           0 B           240  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 7.159s\n",
            "Self CUDA time total: 6.030s\n",
            "\n",
            "\\n================================================================================\\n\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:34<00:00,  3.14it/s]\n",
            "12/14/2025 19:37:06 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:37:06 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 19:37:06 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 19:37:06 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:37:06 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:37:06 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:37:06 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 19:37:06 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:37:06 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 19:37:06 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:37:06 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47961220145225525]\n",
            "No best model found\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:37<00:00,  2.93it/s]\n",
            "12/14/2025 19:37:46 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:37:46 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 19:37:46 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 19:37:46 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:37:46 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:37:46 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:37:46 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 19:37:46 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:37:46 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 19:37:46 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:37:46 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  8.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47961220145225525, 0.45011044236329883]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:37<00:00,  2.92it/s]\n",
            "12/14/2025 19:38:25 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:38:25 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 19:38:25 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 19:38:25 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:38:25 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:38:25 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:38:25 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 19:38:25 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:38:25 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 19:38:25 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:38:25 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47961220145225525, 0.45011044236329883, 0.45011044236329883]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:37<00:00,  2.94it/s]\n",
            "12/14/2025 19:39:04 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:39:04 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 19:39:04 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 19:39:04 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:39:04 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:39:04 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:39:04 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 19:39:04 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:39:04 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 19:39:04 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:39:04 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47961220145225525, 0.45011044236329883, 0.45011044236329883, 0.45011044236329883]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:37<00:00,  2.92it/s]\n",
            "12/14/2025 19:39:44 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:39:44 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 19:39:44 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 19:39:44 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:39:44 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:39:44 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:39:44 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 19:39:44 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:39:44 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 19:39:44 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:39:44 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47961220145225525, 0.45011044236329883, 0.45011044236329883, 0.45011044236329883, 0.45011044236329883]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:37<00:00,  2.93it/s]\n",
            "12/14/2025 19:40:23 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:40:23 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 19:40:23 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 19:40:23 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:40:23 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:40:23 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:40:23 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 19:40:23 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:40:23 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 19:40:23 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:40:23 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.47961220145225525, 0.45011044236329883, 0.45011044236329883, 0.45011044236329883, 0.45011044236329883, 0.45011044236329883]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 6/6 [03:53<00:00, 38.97s/it]\n",
            "12/14/2025 19:40:26 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:40:26 - INFO - finbert.utils -   guid: test-1\n",
            "12/14/2025 19:40:26 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/14/2025 19:40:26 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:40:26 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:40:26 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:40:26 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/14/2025 19:40:27 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:40:27 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/14/2025 19:40:27 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:40:27 - INFO - finbert.finbert -     Num steps = 72\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ BASELINE_CKPT_DIR set to: /home/srm2245/hpml-project/pipelines/finBERT/models/profiling_runs/baseline_20251214_193546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "12/14/2025 19:40:30 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "12/14/2025 19:40:31 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:40:31 - INFO - finbert.utils -   guid: train-1\n",
            "12/14/2025 19:40:31 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/14/2025 19:40:31 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:40:31 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:40:31 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:40:31 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/14/2025 19:40:32 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:40:32 - INFO - finbert.finbert -     Num examples = 3488\n",
            "12/14/2025 19:40:32 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:40:32 - INFO - finbert.finbert -     Num steps = 72\n",
            "/home/srm2245/hpml-project/pipelines/finBERT/finbert/finbert_profile.py:99: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=self.config.use_amp)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n================================================================================\n",
            "Starting Profiled Training\n",
            "Device: cuda\n",
            "Profiling activities: [<ProfilerActivity.CPU: 0>, <ProfilerActivity.CUDA: 2>]\n",
            "================================================================================\\n\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration:  17%|█▋        | 19/109 [00:02<00:12,  7.25it/s]\n",
            "Epoch:   0%|          | 0/6 [00:02<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n================================================================================\n",
            "Profiling complete for first epoch (20 steps)\n",
            "Continuing full training without profiling...\n",
            "================================================================================\\n\n",
            "\\n================================================================================\n",
            "PROFILING RESULTS - Training\n",
            "================================================================================\\n\n",
            "\\nBy CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          backward_pass        25.66%     847.582ms        25.88%     855.037ms      42.752ms       0.000us         0.00%      82.595us       4.130us      -3.75 KB      -3.75 KB     -10.45 GB     -10.45 GB            20  \n",
            "                                  cudaStreamSynchronize        23.59%     779.431ms        23.59%     779.431ms       4.330ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           180  \n",
            "                                               aten::to         0.65%      21.500ms        22.42%     740.821ms      55.865us       0.000us         0.00%     206.630ms      15.582us           0 B           0 B      20.84 GB           0 B         13261  \n",
            "                                         aten::_to_copy         1.91%      63.111ms        21.77%     719.322ms      81.005us       0.000us         0.00%     206.630ms      23.269us           0 B           0 B      20.84 GB           0 B          8880  \n",
            "                                            aten::copy_         1.97%      65.041ms        18.16%     599.962ms      67.260us     206.704ms         8.55%     206.786ms      23.182us           0 B           0 B           0 B           0 B          8920  \n",
            "                                           forward_pass         3.67%     121.077ms        17.85%     589.593ms      29.480ms       0.000us         0.00%     521.303ms      26.065ms       3.75 KB         -80 B      19.17 GB      -6.16 GB            20  \n",
            "                                           aten::linear         0.87%      28.873ms        15.69%     518.445ms     175.151us       0.000us         0.00%     663.848ms     224.273us           0 B           0 B      19.53 GB      -3.00 MB          2960  \n",
            "                                          data_transfer         0.06%       2.119ms        13.98%     461.911ms      23.096ms       0.000us         0.00%     200.096us      10.005us           0 B           0 B      49.00 KB    -931.00 KB            20  \n",
            "                                         optimizer_step         1.54%      50.788ms        12.03%     397.396ms      19.870ms       0.000us         0.00%     931.930ms      46.596ms         804 B           0 B      -7.89 GB      -2.09 MB            20  \n",
            "                                             aten::item         0.37%      12.385ms        10.20%     337.014ms      41.596us       0.000us         0.00%      95.036us       0.012us           0 B           0 B           0 B           0 B          8102  \n",
            "                              aten::_local_scalar_dense         0.18%       5.995ms         9.83%     324.629ms      40.068us      95.036us         0.00%      95.036us       0.012us           0 B           0 B           0 B           0 B          8102  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.93%      30.789ms         7.56%     249.904ms     168.854us       0.000us         0.00%     598.993ms     404.725us           0 B           0 B      -6.02 GB     -15.93 GB          1480  \n",
            "                              Optimizer.step#AdamW.step         2.07%      68.285ms         5.57%     184.076ms       9.204ms       0.000us         0.00%     736.924ms      36.846ms         804 B        -160 B     839.21 MB      -8.25 GB            20  \n",
            "                                       cudaLaunchKernel         5.28%     174.336ms         5.38%     177.708ms       7.939us       0.000us         0.00%      12.204ms       0.545us           0 B           0 B           0 B           0 B         22384  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         1.03%      33.873ms         5.34%     176.518ms      44.575us       0.000us         0.00%     179.883ms      45.425us           0 B           0 B     545.09 MB     -12.02 GB          3960  \n",
            "                                         AddmmBackward0         0.58%      19.135ms         4.86%     160.711ms     108.588us       0.000us         0.00%     544.841ms     368.136us           0 B           0 B       9.91 GB           0 B          1480  \n",
            "                                            aten::addmm         3.38%     111.755ms         4.31%     142.464ms      96.260us     261.342ms        10.81%     288.500ms     194.932us           0 B           0 B       6.37 GB       6.37 GB          1480  \n",
            "                                        ToCopyBackward0         0.31%      10.093ms         3.88%     128.058ms      32.338us       0.000us         0.00%     103.803ms      26.213us           0 B           0 B      12.55 GB           0 B          3960  \n",
            "                                               aten::mm         2.35%      77.532ms         3.23%     106.749ms      36.064us     544.841ms        22.55%     544.841ms     184.068us           0 B           0 B       9.91 GB       9.91 GB          2960  \n",
            "                                    aten::empty_strided         2.54%      83.963ms         2.54%      83.963ms       5.846us       0.000us         0.00%       0.000us       0.000us           0 B           0 B      32.33 GB      32.33 GB         14362  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 3.304s\n",
            "Self CUDA time total: 2.417s\n",
            "\n",
            "\\nBy CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                         optimizer_step         0.00%       0.000us         0.00%       0.000us       0.000us     960.757ms        39.76%     960.757ms      48.038ms           0 B           0 B           0 B           0 B            20  \n",
            "                                         optimizer_step         1.54%      50.788ms        12.03%     397.396ms      19.870ms       0.000us         0.00%     931.930ms      46.596ms         804 B           0 B      -7.89 GB      -2.09 MB            20  \n",
            "                              Optimizer.step#AdamW.step         0.00%       0.000us         0.00%       0.000us       0.000us     741.769ms        30.69%     741.769ms      37.088ms           0 B           0 B           0 B           0 B            20  \n",
            "                              Optimizer.step#AdamW.step         2.07%      68.285ms         5.57%     184.076ms       9.204ms       0.000us         0.00%     736.924ms      36.846ms         804 B        -160 B     839.21 MB      -8.25 GB            20  \n",
            "                                           aten::linear         0.87%      28.873ms        15.69%     518.445ms     175.151us       0.000us         0.00%     663.848ms     224.273us           0 B           0 B      19.53 GB      -3.00 MB          2960  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.93%      30.789ms         7.56%     249.904ms     168.854us       0.000us         0.00%     598.993ms     404.725us           0 B           0 B      -6.02 GB     -15.93 GB          1480  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us     588.376ms        24.35%     588.376ms      29.419ms           0 B           0 B           0 B           0 B            20  \n",
            "                                         AddmmBackward0         0.58%      19.135ms         4.86%     160.711ms     108.588us       0.000us         0.00%     544.841ms     368.136us           0 B           0 B       9.91 GB           0 B          1480  \n",
            "                                               aten::mm         2.35%      77.532ms         3.23%     106.749ms      36.064us     544.841ms        22.55%     544.841ms     184.068us           0 B           0 B       9.91 GB       9.91 GB          2960  \n",
            "                                           forward_pass         3.67%     121.077ms        17.85%     589.593ms      29.480ms       0.000us         0.00%     521.303ms      26.065ms       3.75 KB         -80 B      19.17 GB      -6.16 GB            20  \n",
            "                                            aten::addmm         3.38%     111.755ms         4.31%     142.464ms      96.260us     261.342ms        10.81%     288.500ms     194.932us           0 B           0 B       6.37 GB       6.37 GB          1480  \n",
            "turing_fp16_s1688gemm_fp16_128x256_ldg8_f2f_stages_3...         0.00%       0.000us         0.00%       0.000us       0.000us     274.777ms        11.37%     274.777ms     190.817us           0 B           0 B           0 B           0 B          1440  \n",
            "                                    aten::_foreach_mul_         0.26%       8.696ms         0.42%      13.795ms     172.442us     224.094ms         9.27%     224.094ms       2.801ms           0 B           0 B           0 B           0 B            80  \n",
            "                                            aten::copy_         1.97%      65.041ms        18.16%     599.962ms      67.260us     206.704ms         8.55%     206.786ms      23.182us           0 B           0 B           0 B           0 B          8920  \n",
            "                                               aten::to         0.65%      21.500ms        22.42%     740.821ms      55.865us       0.000us         0.00%     206.630ms      15.582us           0 B           0 B      20.84 GB           0 B         13261  \n",
            "                                         aten::_to_copy         1.91%      63.111ms        21.77%     719.322ms      81.005us       0.000us         0.00%     206.630ms      23.269us           0 B           0 B      20.84 GB           0 B          8880  \n",
            "turing_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_3...         0.00%       0.000us         0.00%       0.000us       0.000us     194.215ms         8.04%     194.215ms     161.846us           0 B           0 B           0 B           0 B          1200  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         1.03%      33.873ms         5.34%     176.518ms      44.575us       0.000us         0.00%     179.883ms      45.425us           0 B           0 B     545.09 MB     -12.02 GB          3960  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     149.465ms         6.18%     149.465ms     533.802us           0 B           0 B           0 B           0 B           280  \n",
            "                                aten::_foreach_addcdiv_         0.18%       6.084ms         0.27%       8.980ms     224.497us     140.396ms         5.81%     140.396ms       3.510ms           0 B           0 B           0 B           0 B            40  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 3.304s\n",
            "Self CUDA time total: 2.417s\n",
            "\n",
            "\\n================================================================================\\n\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:13<00:00,  8.06it/s]\n",
            "12/14/2025 19:41:37 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:41:37 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 19:41:37 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 19:41:37 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:41:37 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:41:37 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:41:37 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 19:41:37 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:41:37 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 19:41:37 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:41:37 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  8.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6536286519123957]\n",
            "No best model found\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:13<00:00,  7.94it/s]\n",
            "12/14/2025 19:41:53 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:41:53 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 19:41:53 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 19:41:53 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:41:53 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:41:53 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:41:53 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 19:41:53 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:41:53 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 19:41:53 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:41:53 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  8.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6536286519123957, 0.5867621027506315]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:13<00:00,  8.04it/s]\n",
            "12/14/2025 19:42:09 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:42:09 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 19:42:09 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 19:42:09 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:42:09 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:42:09 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:42:09 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 19:42:09 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:42:09 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 19:42:09 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:42:09 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6536286519123957, 0.5867621027506315, 0.5867621027506315]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:13<00:00,  8.09it/s]\n",
            "12/14/2025 19:42:25 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:42:25 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 19:42:25 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 19:42:25 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:42:25 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:42:25 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:42:25 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 19:42:25 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:42:25 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 19:42:25 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:42:25 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6536286519123957, 0.5867621027506315, 0.5867621027506315, 0.5867621027506315]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:13<00:00,  8.11it/s]\n",
            "12/14/2025 19:42:40 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:42:40 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 19:42:40 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 19:42:40 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:42:40 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:42:40 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:42:40 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 19:42:40 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:42:40 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 19:42:40 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:42:40 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6536286519123957, 0.5867621027506315, 0.5867621027506315, 0.5867621027506315, 0.5867621027506315]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:13<00:00,  8.07it/s]\n",
            "12/14/2025 19:42:56 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:42:56 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 19:42:56 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 19:42:56 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:42:56 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:42:56 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:42:56 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 19:42:56 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:42:56 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 19:42:56 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:42:56 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6536286519123957, 0.5867621027506315, 0.5867621027506315, 0.5867621027506315, 0.5867621027506315, 0.5867621027506315]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 6/6 [01:34<00:00, 15.71s/it]\n",
            "12/14/2025 19:42:59 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:42:59 - INFO - finbert.utils -   guid: test-1\n",
            "12/14/2025 19:42:59 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/14/2025 19:42:59 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:42:59 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:42:59 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:42:59 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/14/2025 19:42:59 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:42:59 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/14/2025 19:42:59 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:42:59 - INFO - finbert.finbert -     Num steps = 72\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run</th>\n",
              "      <th>use_amp</th>\n",
              "      <th>device</th>\n",
              "      <th>model_dir</th>\n",
              "      <th>train_wall_s</th>\n",
              "      <th>train_examples</th>\n",
              "      <th>train_examples_per_s</th>\n",
              "      <th>model_size_mb</th>\n",
              "      <th>profile_train_steps</th>\n",
              "      <th>train_data_transfer_ms</th>\n",
              "      <th>...</th>\n",
              "      <th>train_optimizer_step_ms</th>\n",
              "      <th>eval_wall_s</th>\n",
              "      <th>eval_num_samples</th>\n",
              "      <th>eval_samples_per_s</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_positive</th>\n",
              "      <th>f1_negative</th>\n",
              "      <th>f1_neutral</th>\n",
              "      <th>f1_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>baseline</td>\n",
              "      <td>False</td>\n",
              "      <td>cuda</td>\n",
              "      <td>/home/srm2245/hpml-project/pipelines/finBERT/models/profiling_runs/baseline_20251214_193546</td>\n",
              "      <td>278.746592</td>\n",
              "      <td>3488</td>\n",
              "      <td>75.078945</td>\n",
              "      <td>417.658215</td>\n",
              "      <td>20</td>\n",
              "      <td>501.199707</td>\n",
              "      <td>...</td>\n",
              "      <td>374.357624</td>\n",
              "      <td>3.479373</td>\n",
              "      <td>970</td>\n",
              "      <td>278.785828</td>\n",
              "      <td>0.549870</td>\n",
              "      <td>0.787629</td>\n",
              "      <td>0.733447</td>\n",
              "      <td>0.779221</td>\n",
              "      <td>0.820709</td>\n",
              "      <td>0.777792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>amp</td>\n",
              "      <td>True</td>\n",
              "      <td>cuda</td>\n",
              "      <td>/home/srm2245/hpml-project/pipelines/finBERT/models/profiling_runs/amp_20251214_194030</td>\n",
              "      <td>147.662289</td>\n",
              "      <td>3488</td>\n",
              "      <td>141.728807</td>\n",
              "      <td>417.658215</td>\n",
              "      <td>20</td>\n",
              "      <td>461.910767</td>\n",
              "      <td>...</td>\n",
              "      <td>397.395732</td>\n",
              "      <td>0.822835</td>\n",
              "      <td>970</td>\n",
              "      <td>1178.851776</td>\n",
              "      <td>0.638034</td>\n",
              "      <td>0.780412</td>\n",
              "      <td>0.698413</td>\n",
              "      <td>0.767742</td>\n",
              "      <td>0.827846</td>\n",
              "      <td>0.764667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        run  use_amp device  \\\n",
              "0  baseline    False   cuda   \n",
              "1       amp     True   cuda   \n",
              "\n",
              "                                                                                     model_dir  \\\n",
              "0  /home/srm2245/hpml-project/pipelines/finBERT/models/profiling_runs/baseline_20251214_193546   \n",
              "1       /home/srm2245/hpml-project/pipelines/finBERT/models/profiling_runs/amp_20251214_194030   \n",
              "\n",
              "   train_wall_s  train_examples  train_examples_per_s  model_size_mb  \\\n",
              "0    278.746592            3488             75.078945     417.658215   \n",
              "1    147.662289            3488            141.728807     417.658215   \n",
              "\n",
              "   profile_train_steps  train_data_transfer_ms  ...  train_optimizer_step_ms  \\\n",
              "0                   20              501.199707  ...               374.357624   \n",
              "1                   20              461.910767  ...               397.395732   \n",
              "\n",
              "   eval_wall_s  eval_num_samples  eval_samples_per_s      loss  accuracy  \\\n",
              "0     3.479373               970          278.785828  0.549870  0.787629   \n",
              "1     0.822835               970         1178.851776  0.638034  0.780412   \n",
              "\n",
              "   f1_positive  f1_negative  f1_neutral  f1_macro  \n",
              "0     0.733447     0.779221    0.820709  0.777792  \n",
              "1     0.698413     0.767742    0.827846  0.764667  \n",
              "\n",
              "[2 rows x 23 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# =========================\n",
        "# Training: baseline vs AMP\n",
        "# =========================\n",
        "\n",
        "if not DATA_DIR.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"DATA_DIR not found: {DATA_DIR}\\n\"\n",
        "        \"Create train/validation/test TSVs under data/sentiment_data (see pipelines/finBERT/README.md).\"\n",
        "    )\n",
        "\n",
        "device = resolve_device(PREFER_GPU, GPU_NAME)\n",
        "print_device_info(device)\n",
        "\n",
        "training_summaries: list[dict[str, Any]] = []\n",
        "trained_ckpts: dict[str, Path] = {}\n",
        "\n",
        "\n",
        "def run_train(tag: str, *, use_amp: bool) -> tuple[dict[str, Any], Path]:\n",
        "    run_dir = make_run_dir(tag)\n",
        "\n",
        "    cfg = make_finbert_config(model_dir=run_dir, use_amp=use_amp)\n",
        "\n",
        "    finbert = ProfiledFinBert(cfg)\n",
        "    finbert.base_model = BASE_MODEL_NAME\n",
        "    finbert.prepare_model(label_list=LABEL_LIST)\n",
        "\n",
        "    train_data = finbert.get_data(\"train\")\n",
        "    test_data = finbert.get_data(\"test\")\n",
        "\n",
        "    model = finbert.create_the_model()\n",
        "\n",
        "    wb = maybe_wandb_init(\n",
        "        run_name=f\"train-{tag}\",\n",
        "        config={\"tag\": tag, \"use_amp\": bool(use_amp), **TRAINING},\n",
        "    )\n",
        "\n",
        "    start = time.perf_counter()\n",
        "    trained_model = finbert.train(train_examples=train_data, model=model)\n",
        "    train_wall_s = time.perf_counter() - start\n",
        "\n",
        "    eval_df, eval_timing = timed_eval(\n",
        "        finbert=finbert, model=trained_model, examples=test_data, use_amp=bool(use_amp)\n",
        "    )\n",
        "    metrics = calculate_metrics(eval_df)\n",
        "\n",
        "    summary = {\n",
        "        \"run\": tag,\n",
        "        \"use_amp\": bool(use_amp and torch.cuda.is_available()),\n",
        "        \"device\": str(finbert.device),\n",
        "        \"model_dir\": str(run_dir),\n",
        "        \"train_wall_s\": float(train_wall_s),\n",
        "        \"train_examples\": int(len(train_data)),\n",
        "        \"train_examples_per_s\": float((len(train_data) * TRAINING[\"num_train_epochs\"]) / train_wall_s)\n",
        "        if train_wall_s > 0\n",
        "        else float(\"inf\"),\n",
        "        \"model_size_mb\": float(get_model_size_mb(trained_model)),\n",
        "        \"profile_train_steps\": int(getattr(cfg, \"profile_train_steps\", PROFILE_TRAIN_STEPS)),\n",
        "        **(finbert.profile_results.get(\"training_summary\", {}) or {}),\n",
        "        **eval_timing,\n",
        "        **metrics,\n",
        "    }\n",
        "\n",
        "    if wb is not None:\n",
        "        import wandb\n",
        "\n",
        "        wandb.log(summary)\n",
        "        wb.finish()\n",
        "\n",
        "    return summary, run_dir\n",
        "\n",
        "\n",
        "if RUN_TRAIN_BASELINE:\n",
        "    baseline_summary, baseline_dir = run_train(\"baseline\", use_amp=False)\n",
        "    training_summaries.append(baseline_summary)\n",
        "    trained_ckpts[\"baseline\"] = baseline_dir\n",
        "\n",
        "    # Use the freshly trained baseline checkpoint for inference benchmarking\n",
        "    BASELINE_CKPT_DIR = baseline_dir\n",
        "    print(\"✓ BASELINE_CKPT_DIR set to:\", BASELINE_CKPT_DIR)\n",
        "else:\n",
        "    print(\"Skipping baseline training. Using BASELINE_CKPT_DIR =\", BASELINE_CKPT_DIR)\n",
        "\n",
        "if RUN_TRAIN_AMP:\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"⚠ RUN_TRAIN_AMP=True but CUDA is not available — skipping AMP training.\")\n",
        "    else:\n",
        "        amp_summary, amp_dir = run_train(\"amp\", use_amp=True)\n",
        "        training_summaries.append(amp_summary)\n",
        "        trained_ckpts[\"amp\"] = amp_dir\n",
        "else:\n",
        "    print(\"Skipping AMP training.\")\n",
        "\n",
        "train_summary_df = pd.DataFrame(training_summaries)\n",
        "train_summary_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Device: cuda:0\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 14.6 GB\n",
            "================================================================================\n",
            "\n",
            "✓ Using baseline checkpoint: /home/srm2245/hpml-project/pipelines/finBERT/models/profiling_runs/baseline_20251214_193546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/14/2025 19:43:00 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/14/2025 19:43:02 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:43:02 - INFO - finbert.utils -   guid: test-1\n",
            "12/14/2025 19:43:02 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/14/2025 19:43:02 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:02 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:02 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:02 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/14/2025 19:43:02 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:43:02 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/14/2025 19:43:02 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:43:02 - INFO - finbert.finbert -     Num steps = 30\n",
            "12/14/2025 19:43:06 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:43:06 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 19:43:06 - INFO - finbert.utils -   tokens: [CLS] later that day apple said it was rev ##ising down its earnings expectations in the fourth quarter of 2018 , largely because of lower sales and signs of economic weakness in china . [SEP]\n",
            "12/14/2025 19:43:06 - INFO - finbert.utils -   input_ids: 101 2101 2008 2154 6207 2056 2009 2001 7065 9355 2091 2049 16565 10908 1999 1996 2959 4284 1997 2760 1010 4321 2138 1997 2896 4341 1998 5751 1997 3171 11251 1999 2859 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:06 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:06 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:06 - INFO - finbert.utils -   label: None (id = 9090)\n",
            "/home/srm2245/hpml-project/pipelines/finBERT/finbert/finbert_profile.py:474: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat([result, batch_result], ignore_index=True)\n",
            "12/14/2025 19:43:06 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:43:06 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 19:43:06 - INFO - finbert.utils -   tokens: [CLS] yields on government bonds fell as investors fled to the traditional haven in a market storm . [SEP]\n",
            "12/14/2025 19:43:06 - INFO - finbert.utils -   input_ids: 101 16189 2006 2231 9547 3062 2004 9387 6783 2000 1996 3151 4033 1999 1037 3006 4040 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:06 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:06 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:06 - INFO - finbert.utils -   label: None (id = 9090)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Device: cuda:0\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 14.6 GB\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Inference Profiling - baseline\n",
            "================================================================================\n",
            "\n",
            "By CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                  sentence_tokenization        38.96%      36.482ms        38.96%      36.482ms      36.482ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             1  \n",
            "                                      inference_forward        11.30%      10.585ms        34.95%      32.720ms      16.360ms       0.000us         0.00%      16.753ms       8.376ms           0 B          -8 B       1.00 KB    -248.22 MB             2  \n",
            "                                    convert_to_features        14.49%      13.570ms        14.49%      13.570ms       6.785ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             2  \n",
            "                                           aten::linear         1.57%       1.471ms        14.03%      13.135ms      88.747us       0.000us         0.00%      15.149ms     102.361us           0 B           0 B     121.52 MB           0 B           148  \n",
            "                                            aten::addmm         5.38%       5.040ms        10.04%       9.397ms      63.493us      15.076ms        90.36%      15.149ms     102.361us           0 B           0 B     121.52 MB     121.52 MB           148  \n",
            "                                        model_to_device         6.38%       5.974ms         7.05%       6.600ms       3.300ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             2  \n",
            "                                       cudaLaunchKernel         3.45%       3.234ms         3.47%       3.249ms       8.854us       0.000us         0.00%       4.543us       0.012us           0 B           0 B           0 B           0 B           367  \n",
            "                                       aten::layer_norm         0.34%     320.208us         2.84%       2.655ms      53.099us       0.000us         0.00%     350.810us       7.016us           0 B           0 B      28.13 MB     -99.50 KB            50  \n",
            "                                    postprocess_results         2.55%       2.390ms         2.71%       2.534ms       1.267ms       0.000us         0.00%       3.680us       1.840us           0 B         -72 B      -1.00 KB      -1.00 KB             2  \n",
            "                                aten::native_layer_norm         1.09%       1.017ms         2.49%       2.335ms      46.695us     350.810us         2.10%     350.810us       7.016us           0 B           0 B      28.22 MB           0 B            50  \n",
            "                     aten::scaled_dot_product_attention         0.36%     340.470us         2.43%       2.273ms      94.718us       0.000us         0.00%     639.508us      26.646us           0 B        -384 B      13.50 MB           0 B            24  \n",
            "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.04%      35.972us         1.92%       1.796ms     449.084us       0.000us         0.00%      68.377us      17.094us           0 B           0 B           0 B           0 B             4  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.31%     288.872us         1.90%       1.778ms      74.104us       0.000us         0.00%     639.508us      26.646us         384 B           0 B      13.50 MB           0 B            24  \n",
            "                                        aten::transpose         1.19%       1.112ms         1.73%       1.617ms       4.757us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           340  \n",
            "                                        prepare_tensors         0.48%     448.663us         1.72%       1.615ms     807.253us       0.000us         0.00%       1.439us       0.719us           0 B      -9.00 KB       1.50 KB      -7.50 KB             2  \n",
            "                                               aten::to         0.29%     271.093us         1.71%       1.601ms       3.741us       0.000us         0.00%      14.335us       0.033us          72 B           0 B     129.00 KB           0 B           428  \n",
            "                       Runtime Triggered Module Loading         1.71%       1.600ms         1.71%       1.600ms     399.926us      32.444us         0.19%      32.444us       8.111us           0 B           0 B           0 B           0 B             4  \n",
            "                                         aten::_to_copy         0.10%      96.735us         1.42%       1.330ms     110.848us       0.000us         0.00%      14.335us       1.195us          72 B           0 B     129.00 KB           0 B            12  \n",
            "                                            aten::empty         1.40%       1.310ms         1.40%       1.310ms       5.000us       0.000us         0.00%       0.000us       0.000us       9.38 KB       9.38 KB      41.82 MB      41.82 MB           262  \n",
            "                                              aten::add         0.87%     813.438us         1.32%       1.236ms      24.718us     218.681us         1.31%     218.681us       4.374us           0 B           0 B      28.12 MB      28.12 MB            50  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 93.631ms\n",
            "Self CUDA time total: 16.685ms\n",
            "\n",
            "\n",
            "By CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                      inference_forward         0.00%       0.000us         0.00%       0.000us       0.000us      28.782ms       172.50%      28.782ms      14.391ms           0 B           0 B           0 B           0 B             2  \n",
            "                                      inference_forward        11.30%      10.585ms        34.95%      32.720ms      16.360ms       0.000us         0.00%      16.753ms       8.376ms           0 B          -8 B       1.00 KB    -248.22 MB             2  \n",
            "                                           aten::linear         1.57%       1.471ms        14.03%      13.135ms      88.747us       0.000us         0.00%      15.149ms     102.361us           0 B           0 B     121.52 MB           0 B           148  \n",
            "                                            aten::addmm         5.38%       5.040ms        10.04%       9.397ms      63.493us      15.076ms        90.36%      15.149ms     102.361us           0 B           0 B     121.52 MB     121.52 MB           148  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      14.790ms        88.65%      14.790ms     109.559us           0 B           0 B           0 B           0 B           135  \n",
            "                     aten::scaled_dot_product_attention         0.36%     340.470us         2.43%       2.273ms      94.718us       0.000us         0.00%     639.508us      26.646us           0 B        -384 B      13.50 MB           0 B            24  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.31%     288.872us         1.90%       1.778ms      74.104us       0.000us         0.00%     639.508us      26.646us         384 B           0 B      13.50 MB           0 B            24  \n",
            "                     aten::_efficient_attention_forward         0.45%     420.925us         1.20%       1.120ms      46.647us     639.508us         3.83%     639.508us      26.646us         384 B           0 B      13.50 MB           0 B            24  \n",
            "fmha_cutlassF_f32_aligned_64x64_rf_sm75(PyTorchMemEf...         0.00%       0.000us         0.00%       0.000us       0.000us     639.508us         3.83%     639.508us      29.069us           0 B           0 B           0 B           0 B            22  \n",
            "                                             aten::gelu         0.40%     374.033us         0.62%     583.605us      24.317us     355.508us         2.13%     355.508us      14.813us           0 B           0 B      54.00 MB      54.00 MB            24  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     355.508us         2.13%     355.508us      15.457us           0 B           0 B           0 B           0 B            23  \n",
            "                                       aten::layer_norm         0.34%     320.208us         2.84%       2.655ms      53.099us       0.000us         0.00%     350.810us       7.016us           0 B           0 B      28.13 MB     -99.50 KB            50  \n",
            "                                aten::native_layer_norm         1.09%       1.017ms         2.49%       2.335ms      46.695us     350.810us         2.10%     350.810us       7.016us           0 B           0 B      28.22 MB           0 B            50  \n",
            "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us     350.810us         2.10%     350.810us       7.464us           0 B           0 B           0 B           0 B            47  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     220.793us         1.32%     220.793us       4.600us           0 B           0 B           0 B           0 B            48  \n",
            "                                              aten::add         0.87%     813.438us         1.32%       1.236ms      24.718us     218.681us         1.31%     218.681us       4.374us           0 B           0 B      28.12 MB      28.12 MB            50  \n",
            "void cublasLt::splitKreduce_kernel<32, 16, int, floa...         0.00%       0.000us         0.00%       0.000us       0.000us     206.712us         1.24%     206.712us       4.307us           0 B           0 B           0 B           0 B            48  \n",
            "                                        prepare_tensors         0.00%       0.000us         0.00%       0.000us       0.000us     153.788us         0.92%     153.788us     153.788us           0 B           0 B           0 B           0 B             1  \n",
            "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.04%      35.972us         1.92%       1.796ms     449.084us       0.000us         0.00%      68.377us      17.094us           0 B           0 B           0 B           0 B             4  \n",
            "                                  Lazy Function Loading         0.19%     175.604us         0.19%     175.604us      43.901us      40.476us         0.24%      40.476us      10.119us           0 B           0 B           0 B           0 B             4  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 93.631ms\n",
            "Self CUDA time total: 16.685ms\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference Summary:\n",
            "  Total sentences: 6\n",
            "  Total inference time: 32.62 ms\n",
            "  Time per sentence: 5.44 ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/14/2025 19:43:07 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:43:07 - INFO - finbert.utils -   guid: test-1\n",
            "12/14/2025 19:43:07 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/14/2025 19:43:07 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:07 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:07 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:07 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/14/2025 19:43:08 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:43:08 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/14/2025 19:43:08 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:43:08 - INFO - finbert.finbert -     Num steps = 30\n",
            "12/14/2025 19:43:10 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:43:10 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 19:43:10 - INFO - finbert.utils -   tokens: [CLS] later that day apple said it was rev ##ising down its earnings expectations in the fourth quarter of 2018 , largely because of lower sales and signs of economic weakness in china . [SEP]\n",
            "12/14/2025 19:43:10 - INFO - finbert.utils -   input_ids: 101 2101 2008 2154 6207 2056 2009 2001 7065 9355 2091 2049 16565 10908 1999 1996 2959 4284 1997 2760 1010 4321 2138 1997 2896 4341 1998 5751 1997 3171 11251 1999 2859 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:10 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:10 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:10 - INFO - finbert.utils -   label: None (id = 9090)\n",
            "/home/srm2245/hpml-project/pipelines/finBERT/finbert/finbert_profile.py:474: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat([result, batch_result], ignore_index=True)\n",
            "12/14/2025 19:43:10 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:43:10 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 19:43:10 - INFO - finbert.utils -   tokens: [CLS] yields on government bonds fell as investors fled to the traditional haven in a market storm . [SEP]\n",
            "12/14/2025 19:43:10 - INFO - finbert.utils -   input_ids: 101 16189 2006 2231 9547 3062 2004 9387 6783 2000 1996 3151 4033 1999 1037 3006 4040 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:10 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:10 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:10 - INFO - finbert.utils -   label: None (id = 9090)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Device: cuda:0\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 14.6 GB\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Inference Profiling - fp16_weights\n",
            "================================================================================\n",
            "\n",
            "By CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                      inference_forward        16.87%      10.388ms        59.03%      36.347ms      18.174ms       0.000us         0.00%       5.500ms       2.750ms           0 B          -4 B       1.00 KB    -130.13 MB             2  \n",
            "                                           aten::linear         2.40%       1.479ms        27.67%      17.037ms     115.116us       0.000us         0.00%       4.530ms      30.608us           0 B           0 B      62.26 MB           0 B           148  \n",
            "                                            aten::addmm         8.27%       5.090ms        21.63%      13.318ms      89.986us       4.428ms        81.94%       4.530ms      30.608us           0 B           0 B      62.26 MB      62.26 MB           148  \n",
            "                                    convert_to_features        19.26%      11.860ms        19.26%      11.860ms       5.930ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             2  \n",
            "                                        model_to_device        10.46%       6.438ms        11.57%       7.124ms       3.562ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             2  \n",
            "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.05%      33.225us         9.72%       5.984ms       1.995ms       0.000us         0.00%      55.549us      18.516us           0 B           0 B           0 B           0 B             3  \n",
            "                       Runtime Triggered Module Loading         9.45%       5.816ms         9.45%       5.816ms       1.454ms      30.718us         0.57%      30.718us       7.679us           0 B           0 B           0 B           0 B             4  \n",
            "                                       cudaLaunchKernel         5.41%       3.333ms         5.44%       3.348ms       8.858us       0.000us         0.00%       4.511us       0.012us           0 B           0 B           0 B           0 B           378  \n",
            "                                        prepare_tensors         2.47%       1.519ms         5.41%       3.331ms       1.665ms       0.000us         0.00%       3.680us       1.840us           0 B      -9.00 KB       1.50 KB      -7.50 KB             2  \n",
            "                                       aten::layer_norm         0.48%     292.661us         4.14%       2.549ms      50.980us       0.000us         0.00%     294.105us       5.882us           0 B           0 B      14.07 MB     -95.50 KB            50  \n",
            "                                    postprocess_results         3.89%       2.398ms         4.14%       2.549ms       1.274ms       0.000us         0.00%       3.296us       1.648us           0 B         -36 B      -1.00 KB      -1.00 KB             2  \n",
            "                                               aten::to         0.52%     322.865us         3.74%       2.300ms       5.374us       0.000us         0.00%      25.792us       0.060us          36 B           0 B      81.00 KB           0 B           428  \n",
            "                     aten::scaled_dot_product_attention         0.53%     327.337us         3.68%       2.267ms      94.446us       0.000us         0.00%     309.401us      12.892us           0 B        -384 B       6.75 MB           0 B            24  \n",
            "                                aten::native_layer_norm         1.61%     989.106us         3.66%       2.256ms      45.127us     294.105us         5.44%     294.105us       5.882us           0 B           0 B      14.16 MB           0 B            50  \n",
            "                                         aten::_to_copy         0.17%     102.642us         3.21%       1.977ms     164.766us       0.000us         0.00%      25.792us       2.149us          36 B           0 B      81.00 KB           0 B            12  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.48%     297.759us         2.91%       1.792ms      74.683us       0.000us         0.00%     309.401us      12.892us         384 B           0 B       6.75 MB           0 B            24  \n",
            "                                            aten::copy_         0.28%     173.681us         2.88%       1.775ms     126.792us      28.096us         0.52%      28.672us       2.048us           0 B           0 B           0 B           0 B            14  \n",
            "                                        aten::transpose         1.85%       1.140ms         2.63%       1.620ms       4.764us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           340  \n",
            "                                              aten::add         1.39%     853.614us         2.09%       1.286ms      25.719us     143.455us         2.65%     143.455us       2.869us           0 B           0 B      14.06 MB      14.06 MB            50  \n",
            "                                            aten::empty         2.06%       1.267ms         2.06%       1.267ms       4.836us       0.000us         0.00%       0.000us       0.000us       9.38 KB       9.38 KB      20.96 MB      20.96 MB           262  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 61.577ms\n",
            "Self CUDA time total: 5.404ms\n",
            "\n",
            "\n",
            "By CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                      inference_forward         0.00%       0.000us         0.00%       0.000us       0.000us      35.508ms       657.04%      35.508ms      17.754ms           0 B           0 B           0 B           0 B             2  \n",
            "                                      inference_forward        16.87%      10.388ms        59.03%      36.347ms      18.174ms       0.000us         0.00%       5.500ms       2.750ms           0 B          -4 B       1.00 KB    -130.13 MB             2  \n",
            "                                           aten::linear         2.40%       1.479ms        27.67%      17.037ms     115.116us       0.000us         0.00%       4.530ms      30.608us           0 B           0 B      62.26 MB           0 B           148  \n",
            "                                            aten::addmm         8.27%       5.090ms        21.63%      13.318ms      89.986us       4.428ms        81.94%       4.530ms      30.608us           0 B           0 B      62.26 MB      62.26 MB           148  \n",
            "turing_fp16_s1688gemm_fp16_128x64_sliced1x2_ldg8_rel...         0.00%       0.000us         0.00%       0.000us       0.000us       1.569ms        29.04%       1.569ms      26.156us           0 B           0 B           0 B           0 B            60  \n",
            "                                        prepare_tensors         0.00%       0.000us         0.00%       0.000us       0.000us       1.462ms        27.06%       1.462ms     731.101us           0 B           0 B           0 B           0 B             2  \n",
            "turing_fp16_s1688gemm_fp16_128x64_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us       1.053ms        19.49%       1.053ms      17.556us           0 B           0 B           0 B           0 B            60  \n",
            "turing_fp16_s1688gemm_fp16_256x64_sliced1x2_ldg8_rel...         0.00%       0.000us         0.00%       0.000us       0.000us     826.827us        15.30%     826.827us      68.902us           0 B           0 B           0 B           0 B            12  \n",
            "    turing_fp16_s1688gemm_fp16_256x128_ldg8_relu_f2f_tn         0.00%       0.000us         0.00%       0.000us       0.000us     689.266us        12.75%     689.266us      57.439us           0 B           0 B           0 B           0 B            12  \n",
            "                     aten::scaled_dot_product_attention         0.53%     327.337us         3.68%       2.267ms      94.446us       0.000us         0.00%     309.401us      12.892us           0 B        -384 B       6.75 MB           0 B            24  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.48%     297.759us         2.91%       1.792ms      74.683us       0.000us         0.00%     309.401us      12.892us         384 B           0 B       6.75 MB           0 B            24  \n",
            "                     aten::_efficient_attention_forward         0.71%     435.877us         1.79%       1.101ms      45.874us     309.401us         5.73%     309.401us      12.892us         384 B           0 B       6.75 MB           0 B            24  \n",
            "fmha_cutlassF_f16_aligned_64x64_rf_sm75(PyTorchMemEf...         0.00%       0.000us         0.00%       0.000us       0.000us     309.401us         5.73%     309.401us      12.892us           0 B           0 B           0 B           0 B            24  \n",
            "                                       aten::layer_norm         0.48%     292.661us         4.14%       2.549ms      50.980us       0.000us         0.00%     294.105us       5.882us           0 B           0 B      14.07 MB     -95.50 KB            50  \n",
            "                                aten::native_layer_norm         1.61%     989.106us         3.66%       2.256ms      45.127us     294.105us         5.44%     294.105us       5.882us           0 B           0 B      14.16 MB           0 B            50  \n",
            "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us     294.105us         5.44%     294.105us       5.882us           0 B           0 B           0 B           0 B            50  \n",
            "void cublasLt::splitKreduce_kernel<32, 16, int, __ha...         0.00%       0.000us         0.00%       0.000us       0.000us     249.979us         4.63%     249.979us       4.166us           0 B           0 B           0 B           0 B            60  \n",
            "                                             aten::gelu         0.61%     375.626us         0.97%     595.999us      24.833us     149.658us         2.77%     149.658us       6.236us           0 B           0 B      31.50 MB      31.50 MB            24  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     149.658us         2.77%     149.658us       6.236us           0 B           0 B           0 B           0 B            24  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     145.215us         2.69%     145.215us       2.847us           0 B           0 B           0 B           0 B            51  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 61.577ms\n",
            "Self CUDA time total: 5.404ms\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Inference Summary:\n",
            "  Total sentences: 6\n",
            "  Total inference time: 36.24 ms\n",
            "  Time per sentence: 6.04 ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/14/2025 19:43:11 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:43:11 - INFO - finbert.utils -   guid: test-1\n",
            "12/14/2025 19:43:11 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/14/2025 19:43:11 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:11 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:11 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:11 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/14/2025 19:43:11 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 19:43:11 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/14/2025 19:43:11 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 19:43:11 - INFO - finbert.finbert -     Num steps = 30\n",
            "12/14/2025 19:43:13 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:43:13 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 19:43:13 - INFO - finbert.utils -   tokens: [CLS] later that day apple said it was rev ##ising down its earnings expectations in the fourth quarter of 2018 , largely because of lower sales and signs of economic weakness in china . [SEP]\n",
            "12/14/2025 19:43:13 - INFO - finbert.utils -   input_ids: 101 2101 2008 2154 6207 2056 2009 2001 7065 9355 2091 2049 16565 10908 1999 1996 2959 4284 1997 2760 1010 4321 2138 1997 2896 4341 1998 5751 1997 3171 11251 1999 2859 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:13 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:13 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:13 - INFO - finbert.utils -   label: None (id = 9090)\n",
            "/home/srm2245/hpml-project/pipelines/finBERT/finbert/finbert_profile.py:474: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat([result, batch_result], ignore_index=True)\n",
            "12/14/2025 19:43:13 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 19:43:13 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 19:43:13 - INFO - finbert.utils -   tokens: [CLS] yields on government bonds fell as investors fled to the traditional haven in a market storm . [SEP]\n",
            "12/14/2025 19:43:13 - INFO - finbert.utils -   input_ids: 101 16189 2006 2231 9547 3062 2004 9387 6783 2000 1996 3151 4033 1999 1037 3006 4040 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:13 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:13 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 19:43:13 - INFO - finbert.utils -   label: None (id = 9090)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Device: cuda:0\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 14.6 GB\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Inference Profiling - amp_autocast\n",
            "================================================================================\n",
            "\n",
            "By CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                      inference_forward        17.72%      13.741ms        65.54%      50.826ms      25.413ms       0.000us         0.00%       9.724ms       4.862ms           0 B          -8 B       1.00 KB    -551.65 MB             2  \n",
            "                                           aten::linear         4.20%       3.256ms        48.57%      37.667ms     127.254us       0.000us         0.00%      12.025ms      40.624us           0 B           0 B     519.48 MB     -27.01 MB           296  \n",
            "                                               aten::to         1.54%       1.192ms        20.07%      15.563ms      18.396us       0.000us         0.00%       5.001ms       5.912us          36 B           0 B     423.40 MB           0 B           846  \n",
            "                                         aten::_to_copy         3.49%       2.708ms        18.53%      14.370ms      33.419us       0.000us         0.00%       5.001ms      11.631us          36 B           0 B     423.40 MB           0 B           430  \n",
            "                                    convert_to_features        14.68%      11.384ms        14.68%      11.384ms       5.692ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             2  \n",
            "                                        model_to_device        10.74%       8.328ms        11.83%       9.172ms       4.586ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             2  \n",
            "                                            aten::copy_         4.51%       3.497ms        10.97%       8.510ms      19.700us       5.003ms        51.43%       5.003ms      11.580us           0 B           0 B           0 B           0 B           432  \n",
            "                                            aten::addmm         7.28%       5.645ms         9.81%       7.612ms      51.430us       3.538ms        36.37%       3.538ms      23.903us           0 B           0 B      61.88 MB      61.88 MB           148  \n",
            "                                       cudaLaunchKernel         8.84%       6.853ms         8.84%       6.853ms       8.609us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           796  \n",
            "                     aten::scaled_dot_product_attention         0.64%     495.979us         7.09%       5.500ms     114.586us       0.000us         0.00%     663.696us      13.827us           0 B        -384 B      13.50 MB    -576.00 KB            48  \n",
            "                                       aten::layer_norm         0.72%     555.679us         4.41%       3.418ms      68.363us       0.000us         0.00%     307.225us       6.144us           0 B           0 B      28.12 MB    -100.00 KB            50  \n",
            "                                    aten::empty_strided         4.14%       3.208ms         4.14%       3.208ms       7.460us       0.000us         0.00%       0.000us       0.000us          36 B          36 B     423.40 MB     423.40 MB           430  \n",
            "                                        prepare_tensors         1.79%       1.392ms         4.13%       3.206ms       1.603ms       0.000us         0.00%       1.152us       0.576us           0 B      -9.00 KB       1.50 KB      -7.50 KB             2  \n",
            "                                aten::native_layer_norm         1.72%       1.333ms         3.69%       2.862ms      57.249us     307.225us         3.16%     307.225us       6.144us           0 B           0 B      28.22 MB           0 B            50  \n",
            "                                    postprocess_results         3.15%       2.446ms         3.35%       2.595ms       1.297ms       0.000us         0.00%       2.432us       1.216us           0 B         -36 B      -1.00 KB      -1.00 KB             2  \n",
            "                                        aten::transpose         1.62%       1.253ms         2.31%       1.792ms       5.269us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           340  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.37%     286.374us         2.25%       1.749ms      72.865us       0.000us         0.00%     311.481us      12.978us         384 B           0 B       6.75 MB           0 B            24  \n",
            "                                              aten::add         1.21%     935.015us         1.89%       1.462ms      29.244us     407.347us         4.19%     407.347us       8.147us           0 B           0 B      28.12 MB      28.12 MB            50  \n",
            "                                            aten::empty         1.88%       1.458ms         1.88%       1.458ms       5.566us       0.000us         0.00%       0.000us       0.000us       9.38 KB       9.38 KB      35.07 MB      35.07 MB           262  \n",
            "                                             aten::view         1.75%       1.361ms         1.75%       1.361ms       2.711us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           502  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 77.552ms\n",
            "Self CUDA time total: 9.727ms\n",
            "\n",
            "\n",
            "By CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                      inference_forward         0.00%       0.000us         0.00%       0.000us       0.000us      47.654ms       489.90%      47.654ms      23.827ms           0 B           0 B           0 B           0 B             2  \n",
            "                                           aten::linear         4.20%       3.256ms        48.57%      37.667ms     127.254us       0.000us         0.00%      12.025ms      40.624us           0 B           0 B     519.48 MB     -27.01 MB           296  \n",
            "                                      inference_forward        17.72%      13.741ms        65.54%      50.826ms      25.413ms       0.000us         0.00%       9.724ms       4.862ms           0 B          -8 B       1.00 KB    -551.65 MB             2  \n",
            "                                            aten::copy_         4.51%       3.497ms        10.97%       8.510ms      19.700us       5.003ms        51.43%       5.003ms      11.580us           0 B           0 B           0 B           0 B           432  \n",
            "                                               aten::to         1.54%       1.192ms        20.07%      15.563ms      18.396us       0.000us         0.00%       5.001ms       5.912us          36 B           0 B     423.40 MB           0 B           846  \n",
            "                                         aten::_to_copy         3.49%       2.708ms        18.53%      14.370ms      33.419us       0.000us         0.00%       5.001ms      11.631us          36 B           0 B     423.40 MB           0 B           430  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.987ms        51.27%       4.987ms      12.047us           0 B           0 B           0 B           0 B           414  \n",
            "                                            aten::addmm         7.28%       5.645ms         9.81%       7.612ms      51.430us       3.538ms        36.37%       3.538ms      23.903us           0 B           0 B      61.88 MB      61.88 MB           148  \n",
            "turing_fp16_s1688gemm_fp16_128x64_sliced1x2_ldg8_rel...         0.00%       0.000us         0.00%       0.000us       0.000us       1.181ms        12.14%       1.181ms      20.013us           0 B           0 B           0 B           0 B            59  \n",
            "turing_fp16_s1688gemm_fp16_128x64_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us     792.810us         8.15%     792.810us      13.213us           0 B           0 B           0 B           0 B            60  \n",
            "turing_fp16_s1688gemm_fp16_256x64_sliced1x2_ldg8_rel...         0.00%       0.000us         0.00%       0.000us       0.000us     735.532us         7.56%     735.532us      61.294us           0 B           0 B           0 B           0 B            12  \n",
            "                     aten::scaled_dot_product_attention         0.64%     495.979us         7.09%       5.500ms     114.586us       0.000us         0.00%     663.696us      13.827us           0 B        -384 B      13.50 MB    -576.00 KB            48  \n",
            "    turing_fp16_s1688gemm_fp16_256x128_ldg8_relu_f2f_tn         0.00%       0.000us         0.00%       0.000us       0.000us     584.562us         6.01%     584.562us      48.714us           0 B           0 B           0 B           0 B            12  \n",
            "                                              aten::add         1.21%     935.015us         1.89%       1.462ms      29.244us     407.347us         4.19%     407.347us       8.147us           0 B           0 B      28.12 MB      28.12 MB            50  \n",
            "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us     405.556us         4.17%     405.556us       8.449us           0 B           0 B           0 B           0 B            48  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.37%     286.374us         2.25%       1.749ms      72.865us       0.000us         0.00%     311.481us      12.978us         384 B           0 B       6.75 MB           0 B            24  \n",
            "                     aten::_efficient_attention_forward         0.55%     427.045us         1.41%       1.090ms      45.409us     311.481us         3.20%     311.481us      12.978us         384 B           0 B       6.75 MB           0 B            24  \n",
            "fmha_cutlassF_f16_aligned_64x64_rf_sm75(PyTorchMemEf...         0.00%       0.000us         0.00%       0.000us       0.000us     311.481us         3.20%     311.481us      12.978us           0 B           0 B           0 B           0 B            24  \n",
            "                                       aten::layer_norm         0.72%     555.679us         4.41%       3.418ms      68.363us       0.000us         0.00%     307.225us       6.144us           0 B           0 B      28.12 MB    -100.00 KB            50  \n",
            "                                aten::native_layer_norm         1.72%       1.333ms         3.69%       2.862ms      57.249us     307.225us         3.16%     307.225us       6.144us           0 B           0 B      28.22 MB           0 B            50  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 77.552ms\n",
            "Self CUDA time total: 9.727ms\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Inference Summary:\n",
            "  Total sentences: 6\n",
            "  Total inference time: 50.72 ms\n",
            "  Time per sentence: 8.45 ms\n"
          ]
        }
      ],
      "source": [
        "# ================================================\n",
        "# Inference benchmarking: baseline ckpt variations\n",
        "# ================================================\n",
        "\n",
        "if RUN_INFER_BENCHMARKS:\n",
        "    device = resolve_device(PREFER_GPU, GPU_NAME)\n",
        "    use_gpu = device.type != \"cpu\"\n",
        "\n",
        "    print_device_info(device)\n",
        "    print(\"✓ Using baseline checkpoint:\", BASELINE_CKPT_DIR)\n",
        "\n",
        "    # Ensure sentence tokenizer is available\n",
        "    setup_nltk_data()\n",
        "\n",
        "    # FinBERT instance for data loading + batching (model_dir must be empty)\n",
        "    eval_dir = make_run_dir(\"_eval\")\n",
        "    eval_cfg = Config(\n",
        "        data_dir=DATA_DIR,\n",
        "        bert_model=None,\n",
        "        model_dir=eval_dir,\n",
        "        max_seq_length=TRAINING[\"max_seq_length\"],\n",
        "        train_batch_size=TRAINING[\"eval_batch_size\"],\n",
        "        eval_batch_size=TRAINING[\"eval_batch_size\"],\n",
        "        learning_rate=TRAINING[\"learning_rate\"],\n",
        "        num_train_epochs=1,\n",
        "        warm_up_proportion=TRAINING[\"warm_up_proportion\"],\n",
        "        local_rank=-1,\n",
        "        output_mode=\"classification\",\n",
        "        discriminate=False,\n",
        "        gradual_unfreeze=False,\n",
        "        fp16=False,\n",
        "        use_amp=False,\n",
        "    )\n",
        "\n",
        "    finbert_eval = FinBert(eval_cfg)\n",
        "    finbert_eval.base_model = BASE_MODEL_NAME\n",
        "    finbert_eval.prepare_model(label_list=LABEL_LIST)\n",
        "    test_data = finbert_eval.get_data(\"test\")\n",
        "\n",
        "    def load_model_from_ckpt(*, ckpt_dir: Path, torch_dtype=None) -> torch.nn.Module:\n",
        "        if torch_dtype is None:\n",
        "            model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                ckpt_dir, cache_dir=None, num_labels=3\n",
        "            )\n",
        "        else:\n",
        "            model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                ckpt_dir, cache_dir=None, num_labels=3, torch_dtype=torch_dtype\n",
        "            )\n",
        "        return model.to(device)\n",
        "\n",
        "    variants = list(INFERENCE_VARIANTS.items())\n",
        "\n",
        "    inference_rows: list[dict[str, Any]] = []\n",
        "\n",
        "    # Optional: log all inference variants to a single W&B run\n",
        "    wb = maybe_wandb_init(\n",
        "        run_name=\"inference-benchmark\",\n",
        "        config={\"baseline_ckpt\": str(BASELINE_CKPT_DIR), **TRAINING},\n",
        "    )\n",
        "\n",
        "    for variant_name, spec in variants:\n",
        "        if spec[\"requires_cuda\"] and device.type != \"cuda\":\n",
        "            print(f\"Skipping {variant_name} (requires CUDA; current device={device})\")\n",
        "            continue\n",
        "\n",
        "        use_amp = bool(spec[\"use_amp\"])\n",
        "        model = load_model_from_ckpt(ckpt_dir=BASELINE_CKPT_DIR, torch_dtype=spec[\"torch_dtype\"])\n",
        "\n",
        "        # Dataset eval: throughput + accuracy\n",
        "        eval_df, eval_timing = timed_eval(\n",
        "            finbert=finbert_eval, model=model, examples=test_data, use_amp=use_amp\n",
        "        )\n",
        "        metrics = calculate_metrics(eval_df)\n",
        "\n",
        "        # Text inference profiling (torch.profiler + forward timing)\n",
        "        _pred_df, prof_metrics = profile_inference(\n",
        "            INFER_TEST_TEXT,\n",
        "            model,\n",
        "            variant_name=variant_name,\n",
        "            use_gpu=use_gpu,\n",
        "            gpu_name=GPU_NAME,\n",
        "            batch_size=INFER_TEXT_BATCH_SIZE,\n",
        "            use_amp=use_amp,\n",
        "        )\n",
        "\n",
        "        # Prefix the text-inference metrics to avoid collisions\n",
        "        text_metrics = {f\"text_{k}\": v for k, v in prof_metrics.items() if k != \"variant\"}\n",
        "\n",
        "        row = {\n",
        "            \"variant\": variant_name,\n",
        "            \"device\": str(device),\n",
        "            \"use_amp\": use_amp,\n",
        "            \"model_size_mb\": float(get_model_size_mb(model)),\n",
        "            **eval_timing,\n",
        "            **metrics,\n",
        "            **text_metrics,\n",
        "        }\n",
        "        inference_rows.append(row)\n",
        "\n",
        "        if wb is not None:\n",
        "            import wandb\n",
        "\n",
        "            wandb.log({f\"{variant_name}/{k}\": v for k, v in row.items() if k != \"variant\"})\n",
        "\n",
        "    if wb is not None:\n",
        "        wb.finish()\n",
        "\n",
        "    inference_summary_df = pd.DataFrame(inference_rows)\n",
        "    inference_summary_df\n",
        "else:\n",
        "    inference_summary_df = pd.DataFrame()\n",
        "    print(\"Skipping inference benchmarking\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/14/2025 19:43:18 - INFO - matplotlib.font_manager -   generated new fontManager\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Training summary ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run</th>\n",
              "      <th>use_amp</th>\n",
              "      <th>device</th>\n",
              "      <th>train_wall_s</th>\n",
              "      <th>train_examples_per_s</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>train_forward_pass_ms</th>\n",
              "      <th>train_backward_pass_ms</th>\n",
              "      <th>train_optimizer_step_ms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>amp</td>\n",
              "      <td>True</td>\n",
              "      <td>cuda</td>\n",
              "      <td>147.662289</td>\n",
              "      <td>141.728807</td>\n",
              "      <td>0.780412</td>\n",
              "      <td>0.764667</td>\n",
              "      <td>589.593108</td>\n",
              "      <td>855.037493</td>\n",
              "      <td>397.395732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>baseline</td>\n",
              "      <td>False</td>\n",
              "      <td>cuda</td>\n",
              "      <td>278.746592</td>\n",
              "      <td>75.078945</td>\n",
              "      <td>0.787629</td>\n",
              "      <td>0.777792</td>\n",
              "      <td>617.279628</td>\n",
              "      <td>898.592052</td>\n",
              "      <td>374.357624</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        run  use_amp device  train_wall_s  train_examples_per_s  accuracy  \\\n",
              "1       amp     True   cuda    147.662289            141.728807  0.780412   \n",
              "0  baseline    False   cuda    278.746592             75.078945  0.787629   \n",
              "\n",
              "   f1_macro  train_forward_pass_ms  train_backward_pass_ms  \\\n",
              "1  0.764667             589.593108              855.037493   \n",
              "0  0.777792             617.279628              898.592052   \n",
              "\n",
              "   train_optimizer_step_ms  \n",
              "1               397.395732  \n",
              "0               374.357624  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training speedup (baseline/amp): 1.89x | Δaccuracy (amp-baseline): -0.0072 | Δf1_macro (amp-baseline): -0.0131\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Inference summary ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>variant</th>\n",
              "      <th>device</th>\n",
              "      <th>model_size_mb</th>\n",
              "      <th>eval_samples_per_s</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>text_time_per_sentence_ms</th>\n",
              "      <th>eval_speedup_vs_baseline</th>\n",
              "      <th>compression_vs_baseline</th>\n",
              "      <th>text_latency_speedup_vs_baseline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>amp_autocast</td>\n",
              "      <td>cuda:0</td>\n",
              "      <td>417.658215</td>\n",
              "      <td>1136.501850</td>\n",
              "      <td>0.787629</td>\n",
              "      <td>0.777792</td>\n",
              "      <td>8.452535</td>\n",
              "      <td>4.116758</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.643269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>baseline</td>\n",
              "      <td>cuda:0</td>\n",
              "      <td>417.658215</td>\n",
              "      <td>276.067228</td>\n",
              "      <td>0.787629</td>\n",
              "      <td>0.777792</td>\n",
              "      <td>5.437255</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fp16_weights</td>\n",
              "      <td>cuda:0</td>\n",
              "      <td>208.833014</td>\n",
              "      <td>572.834257</td>\n",
              "      <td>0.787629</td>\n",
              "      <td>0.777792</td>\n",
              "      <td>6.039699</td>\n",
              "      <td>2.074981</td>\n",
              "      <td>1.999963</td>\n",
              "      <td>0.900253</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        variant  device  model_size_mb  eval_samples_per_s  accuracy  \\\n",
              "0  amp_autocast  cuda:0     417.658215         1136.501850  0.787629   \n",
              "1      baseline  cuda:0     417.658215          276.067228  0.787629   \n",
              "2  fp16_weights  cuda:0     208.833014          572.834257  0.787629   \n",
              "\n",
              "   f1_macro  text_time_per_sentence_ms  eval_speedup_vs_baseline  \\\n",
              "0  0.777792                   8.452535                  4.116758   \n",
              "1  0.777792                   5.437255                  1.000000   \n",
              "2  0.777792                   6.039699                  2.074981   \n",
              "\n",
              "   compression_vs_baseline  text_latency_speedup_vs_baseline  \n",
              "0                 1.000000                          0.643269  \n",
              "1                 1.000000                          1.000000  \n",
              "2                 1.999963                          0.900253  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fp16_weights: Δaccuracy=+0.0000, Δf1_macro=+0.0000, eval_speedup=2.07x, compression=2.00x\n",
            "amp_autocast: Δaccuracy=+0.0000, Δf1_macro=+0.0000, eval_speedup=4.12x, compression=1.00x\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =========================\n",
        "# Results: tables + plots\n",
        "# =========================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "\n",
        "print(\"\\n=== Training summary ===\")\n",
        "if \"train_summary_df\" in globals() and not train_summary_df.empty:\n",
        "    cols = [\n",
        "        \"run\",\n",
        "        \"use_amp\",\n",
        "        \"device\",\n",
        "        \"train_wall_s\",\n",
        "        \"train_examples_per_s\",\n",
        "        \"accuracy\",\n",
        "        \"f1_macro\",\n",
        "        \"train_forward_pass_ms\",\n",
        "        \"train_backward_pass_ms\",\n",
        "        \"train_optimizer_step_ms\",\n",
        "    ]\n",
        "    cols = [c for c in cols if c in train_summary_df.columns]\n",
        "    display(train_summary_df[cols].sort_values(\"run\"))\n",
        "\n",
        "    if {\"baseline\", \"amp\"}.issubset(set(train_summary_df[\"run\"])):\n",
        "        base = train_summary_df[train_summary_df[\"run\"] == \"baseline\"].iloc[0]\n",
        "        amp = train_summary_df[train_summary_df[\"run\"] == \"amp\"].iloc[0]\n",
        "        print(\n",
        "            f\"Training speedup (baseline/amp): {base['train_wall_s'] / amp['train_wall_s']:.2f}x | \"\n",
        "            f\"Δaccuracy (amp-baseline): {amp['accuracy'] - base['accuracy']:+.4f} | \"\n",
        "            f\"Δf1_macro (amp-baseline): {amp['f1_macro'] - base['f1_macro']:+.4f}\"\n",
        "        )\n",
        "\n",
        "    ax = train_summary_df.set_index(\"run\")[\"train_wall_s\"].plot(\n",
        "        kind=\"bar\", title=\"Training wall time (s)\", rot=0\n",
        "    )\n",
        "    ax.set_ylabel(\"seconds\")\n",
        "    plt.show()\n",
        "\n",
        "    ax = train_summary_df.set_index(\"run\")[\"train_examples_per_s\"].plot(\n",
        "        kind=\"bar\", title=\"Training throughput (examples/sec)\", rot=0\n",
        "    )\n",
        "    ax.set_ylabel(\"examples/sec\")\n",
        "    plt.show()\n",
        "\n",
        "    ax = train_summary_df.set_index(\"run\")[[\"accuracy\", \"f1_macro\"]].plot(\n",
        "        kind=\"bar\", title=\"Test metrics\", rot=0\n",
        "    )\n",
        "    ax.set_ylabel(\"score\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"(no training runs executed)\")\n",
        "\n",
        "\n",
        "print(\"\\n=== Inference summary ===\")\n",
        "if \"inference_summary_df\" in globals() and not inference_summary_df.empty:\n",
        "    df = inference_summary_df.copy()\n",
        "\n",
        "    if \"baseline\" in set(df[\"variant\"]):\n",
        "        base = df[df[\"variant\"] == \"baseline\"].iloc[0]\n",
        "        df[\"eval_speedup_vs_baseline\"] = df[\"eval_samples_per_s\"] / base[\"eval_samples_per_s\"]\n",
        "        df[\"compression_vs_baseline\"] = base[\"model_size_mb\"] / df[\"model_size_mb\"]\n",
        "        if \"text_time_per_sentence_ms\" in df.columns and base.get(\"text_time_per_sentence_ms\"):\n",
        "            df[\"text_latency_speedup_vs_baseline\"] = (\n",
        "                base[\"text_time_per_sentence_ms\"] / df[\"text_time_per_sentence_ms\"]\n",
        "            )\n",
        "\n",
        "    display(\n",
        "        df[[\n",
        "            \"variant\",\n",
        "            \"device\",\n",
        "            \"model_size_mb\",\n",
        "            \"eval_samples_per_s\",\n",
        "            \"accuracy\",\n",
        "            \"f1_macro\",\n",
        "            \"text_time_per_sentence_ms\",\n",
        "            \"eval_speedup_vs_baseline\",\n",
        "            \"compression_vs_baseline\",\n",
        "            \"text_latency_speedup_vs_baseline\",\n",
        "        ]]\n",
        "        .sort_values(\"variant\")\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    if \"baseline\" in set(df[\"variant\"]):\n",
        "        base = df[df[\"variant\"] == \"baseline\"].iloc[0]\n",
        "        for _, row in df.iterrows():\n",
        "            if row[\"variant\"] == \"baseline\":\n",
        "                continue\n",
        "            print(\n",
        "                f\"{row['variant']}: Δaccuracy={row['accuracy'] - base['accuracy']:+.4f}, \"\n",
        "                f\"Δf1_macro={row['f1_macro'] - base['f1_macro']:+.4f}, \"\n",
        "                f\"eval_speedup={row.get('eval_speedup_vs_baseline', float('nan')):.2f}x, \"\n",
        "                f\"compression={row.get('compression_vs_baseline', float('nan')):.2f}x\"\n",
        "            )\n",
        "\n",
        "    ax = df.set_index(\"variant\")[\"eval_samples_per_s\"].plot(\n",
        "        kind=\"bar\", title=\"Test-set throughput (samples/sec)\", rot=0\n",
        "    )\n",
        "    ax.set_ylabel(\"samples/sec\")\n",
        "    plt.show()\n",
        "\n",
        "    if \"text_time_per_sentence_ms\" in df.columns:\n",
        "        ax = df.set_index(\"variant\")[\"text_time_per_sentence_ms\"].plot(\n",
        "            kind=\"bar\", title=\"Text inference latency (ms/sentence)\", rot=0\n",
        "        )\n",
        "        ax.set_ylabel(\"ms/sentence\")\n",
        "        plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"(no inference benchmarks executed)\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
