{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FinBERT Profiling: Baseline vs FP16 vs AMP\n",
        "\n",
        "This notebook is intentionally **thin**: it reuses the profiling utilities in `pipelines/finBERT/finbert/` (especially `finbert/finbert_profile.py` and `finbert/profile_utils.py`) instead of copying large code blocks.\n",
        "\n",
        "### What this notebook compares\n",
        "- **Training**: Baseline (FP32) vs **AMP** (autocast + GradScaler) — wall time + profiler breakdown + accuracy\n",
        "- **Inference** (from the **baseline checkpoint**): FP32 vs **FP16-weights** vs **AMP-autocast** — throughput/latency + accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick start\n",
        "\n",
        "1. Run **Setup + Config + Helpers** (cells 2–4).\n",
        "2. Run **Training** (cell 5) to train/eval **baseline** and **AMP**.\n",
        "3. Run **Inference benchmarking** (cell 6) to benchmark **baseline / FP16-weights / AMP-autocast** off the baseline checkpoint.\n",
        "4. Run **Results** (cell 7) to see comparison tables and plots.\n",
        "\n",
        "### Notes\n",
        "- **AMP and FP16 are only enabled on CUDA by default** (to avoid MPS/CPU autocast edge cases).\n",
        "- If you already have a trained checkpoint you want to use, set `BASELINE_CKPT_DIR` in the config cell and set `RUN_TRAIN_BASELINE = False`.\n",
        "- This notebook follows the same “thin notebook, modules do the work” style as `finbert_sweep.ipynb`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Helper utilities loaded\n",
            "✓ FINBERT_ROOT: /home/tfs2123/hpml-project/pipelines/finBERT\n",
            "✓ PROJECT_ROOT: /home/tfs2123/hpml-project\n",
            "✓ torch: 2.9.1+cu128\n",
            "✓ cuda available: True\n",
            "✓ mps available: False\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Silence noisy deprecations (we still keep runtime-correct code)\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=FutureWarning,\n",
        "    message=\"`torch\\\\.cuda\\\\.amp\\\\.autocast\\\\(args\\\\.\\\\.\\\\.\\\\)` is deprecated\",\n",
        ")\n",
        "\n",
        "\n",
        "def _find_finbert_root(start: Path) -> Path:\n",
        "    \"\"\"Return the directory that contains the `finbert/` package.\"\"\"\n",
        "    start = start.resolve()\n",
        "    for p in [start, *start.parents]:\n",
        "        if (p / \"finbert\").is_dir() and (p / \"finbert\" / \"finbert.py\").exists():\n",
        "            return p\n",
        "        if (p / \"pipelines\" / \"finBERT\" / \"finbert\").is_dir():\n",
        "            return p / \"pipelines\" / \"finBERT\"\n",
        "    raise FileNotFoundError(\n",
        "        \"Could not locate finBERT root. Expected a folder containing finbert/finbert.py\"\n",
        "    )\n",
        "\n",
        "\n",
        "FINBERT_ROOT = _find_finbert_root(Path.cwd())\n",
        "if str(FINBERT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(FINBERT_ROOT))\n",
        "\n",
        "PROJECT_ROOT = FINBERT_ROOT.parents[1] if FINBERT_ROOT.name == \"finBERT\" else FINBERT_ROOT.parent\n",
        "\n",
        "from finbert.finbert import Config, FinBert\n",
        "from finbert.finbert_profile import ProfiledFinBert, profile_inference\n",
        "from finbert.profile_utils import get_model_size_mb, print_device_info, setup_nltk_data\n",
        "from finbert.utils import get_device\n",
        "\n",
        "LABEL_LIST = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 120)\n",
        "\n",
        "print(\"✓ FINBERT_ROOT:\", FINBERT_ROOT)\n",
        "print(\"✓ PROJECT_ROOT:\", PROJECT_ROOT)\n",
        "print(\"✓ torch:\", torch.__version__)\n",
        "print(\"✓ cuda available:\", torch.cuda.is_available())\n",
        "print(\"✓ mps available:\", hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ DATA_DIR: /home/tfs2123/hpml-project/pipelines/finBERT/data/sentiment_data\n",
            "✓ RUNS_DIR: /home/tfs2123/hpml-project/pipelines/finBERT/models/profiling_runs\n",
            "✓ BASELINE_CKPT_DIR: /home/tfs2123/hpml-project/pipelines/finBERT/models/sentiment\n",
            "✓ INFERENCE_VARIANTS: ['baseline', 'fp16_weights', 'amp_autocast']\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Experiment configuration\n",
        "# =========================\n",
        "\n",
        "BASE_MODEL_NAME = \"bert-base-uncased\"\n",
        "\n",
        "DATA_DIR = FINBERT_ROOT / \"data\" / \"sentiment_data\"\n",
        "\n",
        "# Where to write new trained models (kept separate from the shipped `models/sentiment` checkpoint)\n",
        "RUNS_DIR = FINBERT_ROOT / \"models\" / \"profiling_runs\"\n",
        "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# If you want to skip training, point this at an existing checkpoint directory\n",
        "BASELINE_CKPT_DIR = FINBERT_ROOT / \"models\" / \"sentiment\"\n",
        "\n",
        "# Training params (using optimal hyperparameters from W&B sweep: solar-sweep-21)\n",
        "TRAINING = dict(\n",
        "    num_train_epochs=6,\n",
        "    train_batch_size=32,\n",
        "    eval_batch_size=32,\n",
        "    learning_rate=1.4e-5,\n",
        "    warm_up_proportion=0.144,\n",
        "    max_seq_length=64,\n",
        "    discriminate=False,\n",
        "    gradual_unfreeze=False,\n",
        ")\n",
        "\n",
        "# Profiling params\n",
        "PROFILE_TRAIN_STEPS = 20  # first N optimizer steps to profile during training\n",
        "\n",
        "INFER_TEXT_BATCH_SIZE = 5\n",
        "# Number of test examples to use for profiling (for more representative results)\n",
        "INFER_PROFILE_NUM_EXAMPLES = 20  # Use multiple diverse examples instead of single text\n",
        "# Whether to use test dataset examples (True) or fallback to single text (False)\n",
        "USE_TEST_DATA_FOR_PROFILING = True\n",
        "# Fallback text if not using test data\n",
        "INFER_TEST_TEXT = \"\"\"Later that day Apple said it was revising down its earnings expectations in \\\n",
        "The fourth quarter of 2018, largely because of lower sales and signs of economic weakness in China. \\\n",
        "The news rapidly infected financial markets. Apple's share price fell by around 7% in after-hours \\\n",
        "Trading and the decline was extended to more than 10% when the market opened. The dollar fell \\\n",
        "By 3.7% against the yen in a matter of minutes after the announcement, before rapidly recovering \\\n",
        "Some ground. Asian stockmarkets closed down on January 3rd and European ones opened lower. \\\n",
        "Yields on government bonds fell as investors fled to the traditional haven in a market storm.\"\"\"\n",
        "# Number of warm-up passes before profiling (to account for CUDA kernel initialization, etc.)\n",
        "INFER_PROFILE_WARMUP_PASSES = 3\n",
        "\n",
        "# Device settings\n",
        "PREFER_GPU = True\n",
        "GPU_NAME = \"cuda:0\"  # only used when CUDA is present\n",
        "\n",
        "# Optional W&B logging \n",
        "USE_WANDB = True\n",
        "WANDB_ENTITY = \"si2449-columbia-university\"\n",
        "WANDB_PROJECT = \"finbert-experiments\"\n",
        "WANDB_GROUP = \"baseline\"\n",
        "\n",
        "# Which runs to execute\n",
        "RUN_TRAIN_BASELINE = True\n",
        "RUN_TRAIN_AMP = True\n",
        "RUN_INFER_BENCHMARKS = True\n",
        "\n",
        "# Safety\n",
        "OVERWRITE_EXISTING_RUN_DIRS = True\n",
        "\n",
        "# Variants (edit here to add/remove)\n",
        "INFERENCE_VARIANTS = {\n",
        "    \"baseline\": {\"torch_dtype\": None, \"use_amp\": False, \"requires_cuda\": False},\n",
        "    \"fp16_weights\": {\"torch_dtype\": torch.float16, \"use_amp\": False, \"requires_cuda\": True},\n",
        "    \"amp_autocast\": {\"torch_dtype\": None, \"use_amp\": True, \"requires_cuda\": True},\n",
        "}\n",
        "\n",
        "print(\"✓ DATA_DIR:\", DATA_DIR)\n",
        "print(\"✓ RUNS_DIR:\", RUNS_DIR)\n",
        "print(\"✓ BASELINE_CKPT_DIR:\", BASELINE_CKPT_DIR)\n",
        "print(\"✓ INFERENCE_VARIANTS:\", list(INFERENCE_VARIANTS.keys()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from contextlib import nullcontext\n",
        "from typing import Any\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "def resolve_device(prefer_gpu: bool = True, gpu_name: str = \"cuda:0\") -> torch.device:\n",
        "    if not prefer_gpu:\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "    device = get_device(no_cuda=False)\n",
        "    if device.type == \"cuda\" and gpu_name.startswith(\"cuda:\"):\n",
        "        return torch.device(gpu_name)\n",
        "    return device\n",
        "\n",
        "\n",
        "def autocast_ctx(device: torch.device, enabled: bool):\n",
        "    if not enabled:\n",
        "        return nullcontext()\n",
        "    if device.type != \"cuda\":\n",
        "        # Keep this conservative: AMP is only enabled on CUDA in this notebook.\n",
        "        return nullcontext()\n",
        "    try:\n",
        "        return torch.amp.autocast(device_type=\"cuda\", enabled=True)\n",
        "    except Exception:\n",
        "        # Older torch fallback\n",
        "        return torch.cuda.amp.autocast(enabled=True)\n",
        "\n",
        "\n",
        "def make_run_dir(prefix: str) -> Path:\n",
        "    ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    run_dir = RUNS_DIR / f\"{prefix}_{ts}\"\n",
        "\n",
        "    if run_dir.exists() and OVERWRITE_EXISTING_RUN_DIRS:\n",
        "        import shutil\n",
        "\n",
        "        shutil.rmtree(run_dir)\n",
        "\n",
        "    if run_dir.exists() and any(run_dir.iterdir()):\n",
        "        raise ValueError(f\"Run dir exists and is not empty: {run_dir}\")\n",
        "\n",
        "    return run_dir\n",
        "\n",
        "\n",
        "def make_finbert_config(*, model_dir: Path, use_amp: bool) -> Config:\n",
        "    # Guard AMP to CUDA only (FinBERT training uses torch.cuda.amp.*)\n",
        "    use_amp = bool(use_amp and torch.cuda.is_available())\n",
        "\n",
        "    bertmodel = AutoModelForSequenceClassification.from_pretrained(\n",
        "        BASE_MODEL_NAME, cache_dir=None, num_labels=3\n",
        "    )\n",
        "\n",
        "    cfg = Config(\n",
        "        data_dir=DATA_DIR,\n",
        "        bert_model=bertmodel,\n",
        "        model_dir=model_dir,\n",
        "        max_seq_length=TRAINING[\"max_seq_length\"],\n",
        "        train_batch_size=TRAINING[\"train_batch_size\"],\n",
        "        eval_batch_size=TRAINING[\"eval_batch_size\"],\n",
        "        learning_rate=TRAINING[\"learning_rate\"],\n",
        "        num_train_epochs=TRAINING[\"num_train_epochs\"],\n",
        "        warm_up_proportion=TRAINING[\"warm_up_proportion\"],\n",
        "        local_rank=-1,\n",
        "        output_mode=\"classification\",\n",
        "        discriminate=TRAINING[\"discriminate\"],\n",
        "        gradual_unfreeze=TRAINING[\"gradual_unfreeze\"],\n",
        "        fp16=False,\n",
        "        use_amp=use_amp,\n",
        "    )\n",
        "\n",
        "    # Read by `ProfiledFinBert.train()` via `getattr(self.config, 'profile_train_steps', 20)`\n",
        "    cfg.profile_train_steps = PROFILE_TRAIN_STEPS\n",
        "\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def calculate_metrics(results_df: pd.DataFrame) -> dict[str, float]:\n",
        "    \"\"\"Sweep-style metrics: CE loss + accuracy + macro/per-class F1.\"\"\"\n",
        "    y_true = np.asarray(results_df[\"labels\"], dtype=np.int64)\n",
        "    logits = np.stack(results_df[\"predictions\"].to_numpy())\n",
        "    y_pred = logits.argmax(axis=1)\n",
        "\n",
        "    loss = F.cross_entropy(torch.tensor(logits, dtype=torch.float32), torch.tensor(y_true)).item()\n",
        "    acc = float((y_true == y_pred).mean())\n",
        "\n",
        "    f1_per = f1_score(y_true, y_pred, average=None, labels=[0, 1, 2])\n",
        "    f1_macro = float(f1_score(y_true, y_pred, average=\"macro\"))\n",
        "\n",
        "    return {\n",
        "        \"loss\": float(loss),\n",
        "        \"accuracy\": acc,\n",
        "        \"f1_positive\": float(f1_per[0]),\n",
        "        \"f1_negative\": float(f1_per[1]),\n",
        "        \"f1_neutral\": float(f1_per[2]),\n",
        "        \"f1_macro\": f1_macro,\n",
        "    }\n",
        "\n",
        "\n",
        "def prepare_profiling_text(test_data, num_examples: int = 20) -> str:\n",
        "    \"\"\"\n",
        "    Prepare profiling text by sampling multiple diverse examples from test_data.\n",
        "    \n",
        "    Args:\n",
        "        test_data: List of InputExample objects from finbert.get_data()\n",
        "        num_examples: Number of examples to sample and concatenate\n",
        "    \n",
        "    Returns:\n",
        "        Concatenated text string suitable for profiling\n",
        "    \"\"\"\n",
        "    import random\n",
        "    \n",
        "    if len(test_data) < num_examples:\n",
        "        print(f\"Warning: Only {len(test_data)} examples available, using all of them\")\n",
        "        selected = test_data\n",
        "    else:\n",
        "        # Randomly sample diverse examples\n",
        "        selected = random.sample(test_data, num_examples)\n",
        "    \n",
        "    # Concatenate text from selected examples with spaces\n",
        "    texts = [ex.text for ex in selected]\n",
        "    return \" \".join(texts)\n",
        "\n",
        "\n",
        "def warmup_inference(model, text: str, device: torch.device, use_amp: bool, num_passes: int = 3):\n",
        "    \"\"\"\n",
        "    Perform warm-up inference passes to initialize CUDA kernels and memory.\n",
        "    \n",
        "    Args:\n",
        "        model: Model to warm up\n",
        "        text: Text to use for warm-up\n",
        "        device: Device to run on\n",
        "        use_amp: Whether to use AMP autocast\n",
        "        num_passes: Number of warm-up passes\n",
        "    \"\"\"\n",
        "    from nltk.tokenize import sent_tokenize\n",
        "    from finbert.utils import InputExample, convert_examples_to_features, chunks\n",
        "    from transformers import AutoTokenizer\n",
        "    \n",
        "    setup_nltk_data()\n",
        "    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "    label_list = ['positive', 'negative', 'neutral']\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    # Tokenize into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "    \n",
        "    # Process in batches (using same batch size as profiling)\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_passes):\n",
        "            for batch in chunks(sentences, INFER_TEXT_BATCH_SIZE):\n",
        "                examples = [InputExample(str(i), sentence) for i, sentence in enumerate(batch)]\n",
        "                features = convert_examples_to_features(examples, label_list, 64, tokenizer)\n",
        "                \n",
        "                all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long).to(device)\n",
        "                all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long).to(device)\n",
        "                all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long).to(device)\n",
        "                \n",
        "                with autocast_ctx(device, use_amp):\n",
        "                    _ = model(\n",
        "                        input_ids=all_input_ids,\n",
        "                        attention_mask=all_attention_mask,\n",
        "                        token_type_ids=all_token_type_ids\n",
        "                    )[0]\n",
        "    \n",
        "    # Synchronize if on CUDA\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize(device)\n",
        "    \n",
        "    print(f\"✓ Completed {num_passes} warm-up passes\")\n",
        "\n",
        "\n",
        "def timed_eval(\n",
        "    *, finbert: FinBert, model: torch.nn.Module, examples, use_amp: bool\n",
        ") -> tuple[pd.DataFrame, dict[str, Any]]:\n",
        "    \"\"\"Evaluation loop with optional CUDA autocast + timing (kept small for notebook use).\"\"\"\n",
        "    loader = finbert.get_loader(examples, phase=\"eval\")\n",
        "    device = finbert.device\n",
        "\n",
        "    model.eval()\n",
        "    preds: list[np.ndarray] = []\n",
        "    labels: list[int] = []\n",
        "\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize(device)\n",
        "\n",
        "    start = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, attention_mask, token_type_ids, label_ids, _agree_ids = batch\n",
        "\n",
        "            with autocast_ctx(device, enabled=bool(use_amp)):\n",
        "                logits = model(input_ids, attention_mask, token_type_ids)[0]\n",
        "\n",
        "            preds.extend(logits.detach().cpu().numpy())\n",
        "            labels.extend(label_ids.detach().cpu().numpy().tolist())\n",
        "\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize(device)\n",
        "\n",
        "    wall_s = time.perf_counter() - start\n",
        "    n = len(labels)\n",
        "\n",
        "    results_df = pd.DataFrame({\"predictions\": preds, \"labels\": labels})\n",
        "\n",
        "    timing = {\n",
        "        \"eval_wall_s\": float(wall_s),\n",
        "        \"eval_num_samples\": int(n),\n",
        "        \"eval_samples_per_s\": float(n / wall_s) if wall_s > 0 else float(\"inf\"),\n",
        "    }\n",
        "    return results_df, timing\n",
        "\n",
        "\n",
        "def maybe_wandb_init(run_name: str, config: dict[str, Any], group: str = None):\n",
        "    if not USE_WANDB:\n",
        "        return None\n",
        "    try:\n",
        "        import wandb\n",
        "\n",
        "        return wandb.init(\n",
        "            entity=WANDB_ENTITY,\n",
        "            project=WANDB_PROJECT,\n",
        "            group=group or WANDB_GROUP,\n",
        "            name=run_name,\n",
        "            config=config,\n",
        "            reinit=True,\n",
        "        )\n",
        "    except ImportError:\n",
        "        print(\"⚠ wandb is not installed; set USE_WANDB=False or install wandb\")\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"✓ Helper functions loaded\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Device: cuda:0\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 14.6 GB\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/14/2025 20:16:06 - WARNING - torchao -   Skipping import of cpp extensions due to incompatible torch version 2.9.1+cu128 for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "12/14/2025 20:16:08 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The anonymous setting has no effect and will be removed in a future version.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtfs2123\u001b[0m (\u001b[33msi2449-columbia-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/tfs2123/hpml-project/pipelines/finBERT/notebooks/wandb/run-20251214_201610-ymqp73kf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/ymqp73kf' target=\"_blank\">train-baseline</a></strong> to <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/ymqp73kf' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/ymqp73kf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/14/2025 20:16:11 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:16:11 - INFO - finbert.utils -   guid: train-1\n",
            "12/14/2025 20:16:11 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/14/2025 20:16:11 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:16:11 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:16:11 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:16:11 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/14/2025 20:16:12 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:16:12 - INFO - finbert.finbert -     Num examples = 3488\n",
            "12/14/2025 20:16:12 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:16:12 - INFO - finbert.finbert -     Num steps = 72\n",
            "/home/tfs2123/hpml-project/pipelines/finBERT/finbert/finbert_profile.py:130: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=self.config.use_amp)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Starting Profiled Training\n",
            "Device: cuda\n",
            "Profiling activities: [<ProfilerActivity.CPU: 0>, <ProfilerActivity.CUDA: 2>]\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration:  17%|█▋        | 19/109 [00:06<00:31,  2.88it/s]\n",
            "Epoch:   0%|          | 0/6 [00:06<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Profiling complete for first epoch (20 steps)\n",
            "Continuing full training without profiling...\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "PROFILING RESULTS - Training\n",
            "================================================================================\n",
            "\n",
            "\n",
            "By CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                  cudaStreamSynchronize        60.59%        4.436s        60.59%        4.436s      27.725ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           160  \n",
            "                                             aten::item         0.18%      13.441ms        36.48%        2.671s     330.456us       0.000us         0.00%      68.419us       0.008us           0 B           0 B           0 B           0 B          8082  \n",
            "                              aten::_local_scalar_dense         0.10%       7.015ms        36.30%        2.657s     328.793us      68.419us         0.00%      68.419us       0.008us           0 B           0 B           0 B           0 B          8082  \n",
            "                                               aten::to         0.05%       3.675ms        24.70%        1.809s     363.105us       0.000us         0.00%     456.788us       0.092us           0 B           0 B      13.47 MB           0 B          4981  \n",
            "                                            aten::copy_         0.06%       4.715ms        24.68%        1.807s       4.107ms       1.561ms         0.03%       1.600ms       3.636us           0 B           0 B           0 B           0 B           440  \n",
            "                                         aten::_to_copy         0.02%       1.576ms        24.65%        1.805s      11.281ms       0.000us         0.00%     456.788us       2.855us           0 B           0 B      13.47 MB           0 B           160  \n",
            "                                       loss_calculation         0.17%      12.125ms        19.07%        1.396s      69.806ms       0.000us         0.00%     184.542us       9.227us           0 B           0 B      21.00 KB     -19.00 KB            20  \n",
            "                                          backward_pass         9.85%     721.340ms        12.44%     910.831ms      45.542ms       0.000us         0.00%      51.167us       2.558us      -3.75 KB      -3.75 KB     -15.27 GB     -15.28 GB            20  \n",
            "                                           forward_pass         1.67%     122.556ms         8.99%     657.874ms      32.894ms       0.000us         0.00%        1.857s      92.871ms       3.75 KB         -80 B      23.61 GB      -6.00 GB            20  \n",
            "                                       cudaLaunchKernel         4.11%     300.934ms         8.92%     652.960ms      45.655us       0.000us         0.00%      99.217ms       6.937us           0 B           0 B           0 B           0 B         14302  \n",
            "                       Runtime Triggered Module Loading         7.30%     534.318ms         7.30%     534.318ms       8.096ms      61.499ms         1.00%      61.499ms     931.799us           0 B           0 B           0 B           0 B            66  \n",
            "                                          data_transfer         0.03%       2.442ms         6.05%     443.268ms      22.163ms       0.000us         0.00%     194.556us       9.728us           0 B           0 B      49.00 KB    -931.00 KB            20  \n",
            "                                         optimizer_step         0.71%      51.967ms         5.73%     419.567ms      20.978ms       0.000us         0.00%     943.304ms      47.165ms         804 B           0 B      -7.51 GB      -2.03 MB            20  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.45%      32.746ms         3.86%     282.798ms     191.080us       0.000us         0.00%        2.977s       2.011ms           0 B           0 B      -2.01 GB     -21.22 GB          1480  \n",
            "                                           aten::linear         0.22%      15.857ms         3.82%     279.917ms     189.133us       0.000us         0.00%        1.629s       1.101ms           0 B           0 B      12.67 GB           0 B          1480  \n",
            "                              Optimizer.step#AdamW.step         1.07%      78.122ms         3.48%     254.886ms      12.744ms       0.000us         0.00%     817.368ms      40.868ms         804 B        -160 B     836.46 MB      -8.22 GB            20  \n",
            "                                            aten::addmm         0.99%      72.783ms         3.13%     229.410ms     155.007us        1.621s        26.26%        1.629s       1.101ms           0 B           0 B      12.67 GB      12.67 GB          1480  \n",
            "                                         AddmmBackward0         0.28%      20.738ms         2.45%     179.100ms     121.014us       0.000us         0.00%        2.891s       1.954ms           0 B           0 B      19.20 GB           0 B          1480  \n",
            "autograd::engine::evaluate_function: EmbeddingBackwa...         0.01%     559.416us         2.03%     148.515ms       2.475ms       0.000us         0.00%      14.826ms     247.106us           0 B           0 B       1.67 GB    -123.75 MB            60  \n",
            "                                     EmbeddingBackward0         0.00%     234.137us         2.02%     147.956ms       2.466ms       0.000us         0.00%      14.826ms     247.106us           0 B           0 B       1.79 GB           0 B            60  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 7.321s\n",
            "Self CUDA time total: 6.172s\n",
            "\n",
            "\n",
            "By CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.45%      32.746ms         3.86%     282.798ms     191.080us       0.000us         0.00%        2.977s       2.011ms           0 B           0 B      -2.01 GB     -21.22 GB          1480  \n",
            "                                         AddmmBackward0         0.28%      20.738ms         2.45%     179.100ms     121.014us       0.000us         0.00%        2.891s       1.954ms           0 B           0 B      19.20 GB           0 B          1480  \n",
            "                                               aten::mm         1.10%      80.614ms         1.64%     120.056ms      40.560us        2.891s        46.84%        2.891s     976.753us           0 B           0 B      19.20 GB      19.20 GB          2960  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us        2.002s        32.44%        2.002s     100.098ms           0 B           0 B           0 B           0 B            20  \n",
            "                                           forward_pass         1.67%     122.556ms         8.99%     657.874ms      32.894ms       0.000us         0.00%        1.857s      92.871ms       3.75 KB         -80 B      23.61 GB      -6.00 GB            20  \n",
            "                                           aten::linear         0.22%      15.857ms         3.82%     279.917ms     189.133us       0.000us         0.00%        1.629s       1.101ms           0 B           0 B      12.67 GB           0 B          1480  \n",
            "                                            aten::addmm         0.99%      72.783ms         3.13%     229.410ms     155.007us        1.621s        26.26%        1.629s       1.101ms           0 B           0 B      12.67 GB      12.67 GB          1480  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us        1.098s        17.79%        1.098s     914.798us           0 B           0 B           0 B           0 B          1200  \n",
            "                                  volta_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us     976.521ms        15.82%     976.521ms     813.768us           0 B           0 B           0 B           0 B          1200  \n",
            "                                  volta_sgemm_128x64_nt         0.00%       0.000us         0.00%       0.000us       0.000us     953.437ms        15.45%     953.437ms     781.505us           0 B           0 B           0 B           0 B          1220  \n",
            "                                         optimizer_step         0.71%      51.967ms         5.73%     419.567ms      20.978ms       0.000us         0.00%     943.304ms      47.165ms         804 B           0 B      -7.51 GB      -2.03 MB            20  \n",
            "                              Optimizer.step#AdamW.step         1.07%      78.122ms         3.48%     254.886ms      12.744ms       0.000us         0.00%     817.368ms      40.868ms         804 B        -160 B     836.46 MB      -8.22 GB            20  \n",
            "                              Optimizer.step#AdamW.step         0.00%       0.000us         0.00%       0.000us       0.000us     773.489ms        12.53%     773.489ms      38.674ms           0 B           0 B           0 B           0 B            20  \n",
            "                                 volta_sgemm_128x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     521.856ms         8.46%     521.856ms       2.174ms           0 B           0 B           0 B           0 B           240  \n",
            "                                 volta_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     479.620ms         7.77%     479.620ms       1.998ms           0 B           0 B           0 B           0 B           240  \n",
            "                                 volta_sgemm_128x128_nt         0.00%       0.000us         0.00%       0.000us       0.000us     477.997ms         7.74%     477.997ms       1.992ms           0 B           0 B           0 B           0 B           240  \n",
            "                                    aten::_foreach_mul_         0.14%       9.926ms         0.35%      25.917ms     323.966us     225.062ms         3.65%     247.887ms       3.099ms           0 B           0 B           0 B           0 B            80  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.08%       6.124ms         1.09%      79.614ms     331.724us       0.000us         0.00%     244.394ms       1.018ms      -3.75 KB      -3.75 KB      -2.84 GB      -7.06 GB           240  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.04%       2.663ms         1.00%      73.490ms     306.209us       0.000us         0.00%     244.394ms       1.018ms           0 B           0 B       4.22 GB           0 B           240  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.08%       5.732ms         0.97%      70.827ms     295.112us       0.000us         0.00%     244.394ms       1.018ms           0 B           0 B       4.22 GB           0 B           240  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 7.321s\n",
            "Self CUDA time total: 6.172s\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "⚠ Failed to log profiler table: 'FunctionEventAvg' object has no attribute 'cuda_time_total'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:34<00:00,  3.13it/s]\n",
            "12/14/2025 20:17:31 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:17:31 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 20:17:31 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 20:17:31 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:17:31 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:17:31 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:17:31 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 20:17:31 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:17:31 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 20:17:31 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:17:31 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 10.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6052003227747403]\n",
            "No best model found\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:35<00:00,  3.03it/s]\n",
            "12/14/2025 20:18:09 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:18:09 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 20:18:09 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 20:18:09 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:18:09 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:18:09 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:18:09 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 20:18:09 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:18:09 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 20:18:09 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:18:09 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6052003227747403, 0.5464758781286386]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:37<00:00,  2.94it/s]\n",
            "12/14/2025 20:18:48 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:18:48 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 20:18:48 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 20:18:48 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:18:48 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:18:48 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:18:48 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 20:18:48 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:18:48 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 20:18:48 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:18:48 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6052003227747403, 0.5464758781286386, 0.5464758781286386]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:37<00:00,  2.89it/s]\n",
            "12/14/2025 20:19:28 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:19:28 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 20:19:28 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 20:19:28 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:19:28 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:19:28 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:19:28 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 20:19:28 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:19:28 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 20:19:28 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:19:28 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6052003227747403, 0.5464758781286386, 0.5464758781286386, 0.5464758781286386]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:37<00:00,  2.92it/s]\n",
            "12/14/2025 20:20:07 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:20:07 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 20:20:07 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 20:20:07 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:20:07 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:20:07 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:20:07 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 20:20:07 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:20:07 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 20:20:07 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:20:07 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6052003227747403, 0.5464758781286386, 0.5464758781286386, 0.5464758781286386, 0.5464758781286386]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:37<00:00,  2.90it/s]\n",
            "12/14/2025 20:20:47 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:20:47 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 20:20:47 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 20:20:47 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:20:47 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:20:47 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:20:47 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 20:20:47 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:20:47 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 20:20:47 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:20:47 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6052003227747403, 0.5464758781286386, 0.5464758781286386, 0.5464758781286386, 0.5464758781286386, 0.5464758781286386]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 6/6 [03:53<00:00, 38.91s/it]\n",
            "12/14/2025 20:20:50 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:20:50 - INFO - finbert.utils -   guid: test-1\n",
            "12/14/2025 20:20:50 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/14/2025 20:20:50 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:20:50 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:20:50 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:20:50 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/14/2025 20:20:50 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:20:50 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/14/2025 20:20:50 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:20:50 - INFO - finbert.finbert -     Num steps = 72\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▅▅▅▅▇▇▇▇▇█████</td></tr><tr><td>eval_num_samples</td><td>▁</td></tr><tr><td>eval_samples_per_s</td><td>▁</td></tr><tr><td>eval_wall_s</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_negative</td><td>▁</td></tr><tr><td>f1_neutral</td><td>▁</td></tr><tr><td>f1_positive</td><td>▁</td></tr><tr><td>learning_rate</td><td>█▆▅▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>+14</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.76082</td></tr><tr><td>device</td><td>cuda</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>eval_num_samples</td><td>970</td></tr><tr><td>eval_samples_per_s</td><td>279.68658</td></tr><tr><td>eval_wall_s</td><td>3.46817</td></tr><tr><td>f1_macro</td><td>0.74163</td></tr><tr><td>f1_negative</td><td>0.74766</td></tr><tr><td>f1_neutral</td><td>0.81181</td></tr><tr><td>f1_positive</td><td>0.66542</td></tr><tr><td>+18</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">train-baseline</strong> at: <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/ymqp73kf' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/ymqp73kf</a><br> View project at: <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_201610-ymqp73kf/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ BASELINE_CKPT_DIR set to: /home/tfs2123/hpml-project/pipelines/finBERT/models/profiling_runs/baseline_20251214_201606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "12/14/2025 20:20:56 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/tfs2123/hpml-project/pipelines/finBERT/notebooks/wandb/run-20251214_202057-gxgirypg</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/gxgirypg' target=\"_blank\">train-amp</a></strong> to <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/gxgirypg' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/gxgirypg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/14/2025 20:20:58 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:20:58 - INFO - finbert.utils -   guid: train-1\n",
            "12/14/2025 20:20:58 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/14/2025 20:20:58 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:20:58 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:20:58 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:20:58 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/14/2025 20:20:59 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:20:59 - INFO - finbert.finbert -     Num examples = 3488\n",
            "12/14/2025 20:20:59 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:20:59 - INFO - finbert.finbert -     Num steps = 72\n",
            "/home/tfs2123/hpml-project/pipelines/finBERT/finbert/finbert_profile.py:130: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=self.config.use_amp)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Starting Profiled Training\n",
            "Device: cuda\n",
            "Profiling activities: [<ProfilerActivity.CPU: 0>, <ProfilerActivity.CUDA: 2>]\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration:  17%|█▋        | 19/109 [00:02<00:12,  7.16it/s]\n",
            "Epoch:   0%|          | 0/6 [00:02<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Profiling complete for first epoch (20 steps)\n",
            "Continuing full training without profiling...\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "PROFILING RESULTS - Training\n",
            "================================================================================\n",
            "\n",
            "\n",
            "By CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          backward_pass        27.70%     922.131ms        27.93%     929.680ms      46.484ms       0.000us         0.00%      81.725us       4.086us      -3.75 KB      -3.75 KB     -10.24 GB     -10.24 GB            20  \n",
            "                                               aten::to         0.68%      22.487ms        21.16%     704.479ms      53.124us       0.000us         0.00%     204.737ms      15.439us           0 B           0 B      20.88 GB           0 B         13261  \n",
            "                                         aten::_to_copy         1.94%      64.625ms        20.49%     681.992ms      76.801us       0.000us         0.00%     204.737ms      23.056us           0 B           0 B      20.88 GB           0 B          8880  \n",
            "                                  cudaStreamSynchronize        19.44%     646.969ms        19.44%     646.969ms       3.594ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           180  \n",
            "                                           forward_pass         3.86%     128.606ms        18.52%     616.350ms      30.818ms       0.000us         0.00%     517.542ms      25.877ms       3.75 KB         -80 B      19.08 GB      -6.14 GB            20  \n",
            "                                            aten::copy_         2.06%      68.701ms        16.77%     558.174ms      62.576us     204.807ms         8.55%     204.891ms      22.970us           0 B           0 B           0 B           0 B          8920  \n",
            "                                           aten::linear         0.88%      29.327ms        16.20%     539.400ms     182.230us       0.000us         0.00%     656.790ms     221.889us           0 B           0 B      19.46 GB           0 B          2960  \n",
            "                                          data_transfer         0.07%       2.479ms        12.53%     417.100ms      20.855ms       0.000us         0.00%     204.596us      10.230us           0 B           0 B      49.00 KB    -931.00 KB            20  \n",
            "                                         optimizer_step         1.73%      57.657ms        12.35%     411.195ms      20.560ms       0.000us         0.00%     932.330ms      46.616ms         804 B           0 B      -8.01 GB      -2.09 MB            20  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.98%      32.713ms         7.72%     257.029ms     173.668us       0.000us         0.00%     584.086ms     394.653us           0 B           0 B      -5.93 GB     -15.88 GB          1480  \n",
            "                                             aten::item         0.38%      12.785ms         7.60%     253.017ms      31.229us       0.000us         0.00%     102.814us       0.013us           0 B           0 B           0 B           0 B          8102  \n",
            "                              aten::_local_scalar_dense         0.22%       7.257ms         7.22%     240.232ms      29.651us     102.814us         0.00%     102.814us       0.013us           0 B           0 B           0 B           0 B          8102  \n",
            "                              Optimizer.step#AdamW.step         2.19%      72.957ms         5.83%     194.188ms       9.709ms       0.000us         0.00%     737.218ms      36.861ms         804 B        -160 B     840.96 MB      -8.32 GB            20  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         1.12%      37.293ms         5.57%     185.540ms      46.853us       0.000us         0.00%     178.166ms      44.991us           0 B           0 B     627.59 MB     -12.06 GB          3960  \n",
            "                                       cudaLaunchKernel         5.33%     177.365ms         5.44%     181.047ms       8.088us       0.000us         0.00%      12.107ms       0.541us           0 B           0 B           0 B           0 B         22384  \n",
            "                                         AddmmBackward0         0.60%      20.118ms         4.93%     164.010ms     110.817us       0.000us         0.00%     530.489ms     358.439us           0 B           0 B       9.95 GB           0 B          1480  \n",
            "                                            aten::addmm         3.54%     117.846ms         4.48%     149.211ms     100.818us     257.829ms        10.76%     285.025ms     192.585us           0 B           0 B       6.36 GB       6.36 GB          1480  \n",
            "                                        ToCopyBackward0         0.32%      10.516ms         4.01%     133.316ms      33.666us       0.000us         0.00%     102.024ms      25.764us           0 B           0 B      12.67 GB           0 B          3960  \n",
            "                                               aten::mm         2.36%      78.454ms         3.22%     107.132ms      36.193us     530.489ms        22.15%     530.489ms     179.219us           0 B           0 B       9.95 GB       9.95 GB          2960  \n",
            "                                    aten::empty_strided         2.65%      88.179ms         2.66%      88.523ms       6.164us       0.000us         0.00%       0.000us       0.000us           0 B           0 B      32.40 GB      32.40 GB         14362  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 3.329s\n",
            "Self CUDA time total: 2.395s\n",
            "\n",
            "\n",
            "By CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                         optimizer_step         0.00%       0.000us         0.00%       0.000us       0.000us     964.813ms        40.28%     964.813ms      48.241ms           0 B           0 B           0 B           0 B            20  \n",
            "                                         optimizer_step         1.73%      57.657ms        12.35%     411.195ms      20.560ms       0.000us         0.00%     932.330ms      46.616ms         804 B           0 B      -8.01 GB      -2.09 MB            20  \n",
            "                              Optimizer.step#AdamW.step         0.00%       0.000us         0.00%       0.000us       0.000us     741.579ms        30.96%     741.579ms      37.079ms           0 B           0 B           0 B           0 B            20  \n",
            "                              Optimizer.step#AdamW.step         2.19%      72.957ms         5.83%     194.188ms       9.709ms       0.000us         0.00%     737.218ms      36.861ms         804 B        -160 B     840.96 MB      -8.32 GB            20  \n",
            "                                           aten::linear         0.88%      29.327ms        16.20%     539.400ms     182.230us       0.000us         0.00%     656.790ms     221.889us           0 B           0 B      19.46 GB           0 B          2960  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us     610.352ms        25.48%     610.352ms      30.518ms           0 B           0 B           0 B           0 B            20  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.98%      32.713ms         7.72%     257.029ms     173.668us       0.000us         0.00%     584.086ms     394.653us           0 B           0 B      -5.93 GB     -15.88 GB          1480  \n",
            "                                         AddmmBackward0         0.60%      20.118ms         4.93%     164.010ms     110.817us       0.000us         0.00%     530.489ms     358.439us           0 B           0 B       9.95 GB           0 B          1480  \n",
            "                                               aten::mm         2.36%      78.454ms         3.22%     107.132ms      36.193us     530.489ms        22.15%     530.489ms     179.219us           0 B           0 B       9.95 GB       9.95 GB          2960  \n",
            "                                           forward_pass         3.86%     128.606ms        18.52%     616.350ms      30.818ms       0.000us         0.00%     517.542ms      25.877ms       3.75 KB         -80 B      19.08 GB      -6.14 GB            20  \n",
            "                                            aten::addmm         3.54%     117.846ms         4.48%     149.211ms     100.818us     257.829ms        10.76%     285.025ms     192.585us           0 B           0 B       6.36 GB       6.36 GB          1480  \n",
            "turing_fp16_s1688gemm_fp16_128x256_ldg8_f2f_stages_3...         0.00%       0.000us         0.00%       0.000us       0.000us     268.144ms        11.19%     268.144ms     186.211us           0 B           0 B           0 B           0 B          1440  \n",
            "                                    aten::_foreach_mul_         0.28%       9.183ms         0.43%      14.420ms     180.245us     224.596ms         9.38%     224.596ms       2.807ms           0 B           0 B           0 B           0 B            80  \n",
            "                                            aten::copy_         2.06%      68.701ms        16.77%     558.174ms      62.576us     204.807ms         8.55%     204.891ms      22.970us           0 B           0 B           0 B           0 B          8920  \n",
            "                                               aten::to         0.68%      22.487ms        21.16%     704.479ms      53.124us       0.000us         0.00%     204.737ms      15.439us           0 B           0 B      20.88 GB           0 B         13261  \n",
            "                                         aten::_to_copy         1.94%      64.625ms        20.49%     681.992ms      76.801us       0.000us         0.00%     204.737ms      23.056us           0 B           0 B      20.88 GB           0 B          8880  \n",
            "turing_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_3...         0.00%       0.000us         0.00%       0.000us       0.000us     188.501ms         7.87%     188.501ms     157.084us           0 B           0 B           0 B           0 B          1200  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         1.12%      37.293ms         5.57%     185.540ms      46.853us       0.000us         0.00%     178.166ms      44.991us           0 B           0 B     627.59 MB     -12.06 GB          3960  \n",
            "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     149.641ms         6.25%     149.641ms     534.433us           0 B           0 B           0 B           0 B           280  \n",
            "                                aten::_foreach_addcdiv_         0.20%       6.563ms         0.29%       9.646ms     241.141us     140.517ms         5.87%     140.517ms       3.513ms           0 B           0 B           0 B           0 B            40  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 3.329s\n",
            "Self CUDA time total: 2.395s\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "⚠ Failed to log profiler table: 'FunctionEventAvg' object has no attribute 'cuda_time_total'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:13<00:00,  8.07it/s]\n",
            "12/14/2025 20:22:05 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:22:05 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 20:22:05 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 20:22:05 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:22:05 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:22:05 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:22:05 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 20:22:05 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:22:05 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 20:22:05 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:22:05 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6536286519123957]\n",
            "No best model found\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:13<00:00,  7.95it/s]\n",
            "12/14/2025 20:22:21 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:22:21 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 20:22:21 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 20:22:21 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:22:21 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:22:21 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:22:21 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 20:22:21 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:22:21 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 20:22:21 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:22:21 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  8.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6536286519123957, 0.5867621027506315]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:13<00:00,  7.96it/s]\n",
            "12/14/2025 20:22:37 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:22:37 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 20:22:37 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 20:22:37 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:22:37 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:22:37 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:22:37 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 20:22:37 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:22:37 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 20:22:37 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:22:37 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6536286519123957, 0.5867621027506315, 0.5867621027506315]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:13<00:00,  8.04it/s]\n",
            "12/14/2025 20:22:53 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:22:53 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 20:22:53 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 20:22:53 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:22:53 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:22:53 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:22:53 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 20:22:53 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:22:53 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 20:22:53 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:22:53 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6536286519123957, 0.5867621027506315, 0.5867621027506315, 0.5867621027506315]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:13<00:00,  8.08it/s]\n",
            "12/14/2025 20:23:08 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:08 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 20:23:08 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 20:23:08 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:08 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:08 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:08 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 20:23:08 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:23:08 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 20:23:08 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:23:08 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6536286519123957, 0.5867621027506315, 0.5867621027506315, 0.5867621027506315, 0.5867621027506315]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:13<00:00,  8.06it/s]\n",
            "12/14/2025 20:23:24 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:24 - INFO - finbert.utils -   guid: validation-1\n",
            "12/14/2025 20:23:24 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/14/2025 20:23:24 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:24 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:24 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:24 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/14/2025 20:23:24 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:23:24 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/14/2025 20:23:24 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:23:24 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.6536286519123957, 0.5867621027506315, 0.5867621027506315, 0.5867621027506315, 0.5867621027506315, 0.5867621027506315]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 6/6 [01:34<00:00, 15.77s/it]\n",
            "12/14/2025 20:23:27 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:27 - INFO - finbert.utils -   guid: test-1\n",
            "12/14/2025 20:23:27 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/14/2025 20:23:27 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:27 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:27 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:27 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/14/2025 20:23:27 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:23:27 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/14/2025 20:23:27 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:23:27 - INFO - finbert.finbert -     Num steps = 72\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▄▄▄▄▅▅▅▅▅▅▅▇▇▇▇▇▇████████</td></tr><tr><td>eval_num_samples</td><td>▁</td></tr><tr><td>eval_samples_per_s</td><td>▁</td></tr><tr><td>eval_wall_s</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_negative</td><td>▁</td></tr><tr><td>f1_neutral</td><td>▁</td></tr><tr><td>f1_positive</td><td>▁</td></tr><tr><td>learning_rate</td><td>█▇▆▆▅▄▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>+14</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.78041</td></tr><tr><td>device</td><td>cuda</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>eval_num_samples</td><td>970</td></tr><tr><td>eval_samples_per_s</td><td>1127.66184</td></tr><tr><td>eval_wall_s</td><td>0.86019</td></tr><tr><td>f1_macro</td><td>0.76467</td></tr><tr><td>f1_negative</td><td>0.76774</td></tr><tr><td>f1_neutral</td><td>0.82785</td></tr><tr><td>f1_positive</td><td>0.69841</td></tr><tr><td>+18</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">train-amp</strong> at: <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/gxgirypg' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/gxgirypg</a><br> View project at: <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_202057-gxgirypg/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run</th>\n",
              "      <th>use_amp</th>\n",
              "      <th>device</th>\n",
              "      <th>model_dir</th>\n",
              "      <th>train_wall_s</th>\n",
              "      <th>train_examples</th>\n",
              "      <th>train_examples_per_s</th>\n",
              "      <th>model_size_mb</th>\n",
              "      <th>profile_train_steps</th>\n",
              "      <th>train_data_transfer_ms</th>\n",
              "      <th>...</th>\n",
              "      <th>train_optimizer_step_ms</th>\n",
              "      <th>eval_wall_s</th>\n",
              "      <th>eval_num_samples</th>\n",
              "      <th>eval_samples_per_s</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_positive</th>\n",
              "      <th>f1_negative</th>\n",
              "      <th>f1_neutral</th>\n",
              "      <th>f1_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>baseline</td>\n",
              "      <td>False</td>\n",
              "      <td>cuda</td>\n",
              "      <td>/home/tfs2123/hpml-project/pipelines/finBERT/models/profiling_runs/baseline_20251214_201606</td>\n",
              "      <td>279.127465</td>\n",
              "      <td>3488</td>\n",
              "      <td>74.976499</td>\n",
              "      <td>417.658215</td>\n",
              "      <td>20</td>\n",
              "      <td>443.268123</td>\n",
              "      <td>...</td>\n",
              "      <td>419.566644</td>\n",
              "      <td>3.468168</td>\n",
              "      <td>970</td>\n",
              "      <td>279.686577</td>\n",
              "      <td>0.648285</td>\n",
              "      <td>0.760825</td>\n",
              "      <td>0.665421</td>\n",
              "      <td>0.747664</td>\n",
              "      <td>0.811808</td>\n",
              "      <td>0.741631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>amp</td>\n",
              "      <td>True</td>\n",
              "      <td>cuda</td>\n",
              "      <td>/home/tfs2123/hpml-project/pipelines/finBERT/models/profiling_runs/amp_20251214_202056</td>\n",
              "      <td>149.105554</td>\n",
              "      <td>3488</td>\n",
              "      <td>140.356945</td>\n",
              "      <td>417.658215</td>\n",
              "      <td>20</td>\n",
              "      <td>417.099585</td>\n",
              "      <td>...</td>\n",
              "      <td>411.194942</td>\n",
              "      <td>0.860187</td>\n",
              "      <td>970</td>\n",
              "      <td>1127.661839</td>\n",
              "      <td>0.638034</td>\n",
              "      <td>0.780412</td>\n",
              "      <td>0.698413</td>\n",
              "      <td>0.767742</td>\n",
              "      <td>0.827846</td>\n",
              "      <td>0.764667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        run  use_amp device  \\\n",
              "0  baseline    False   cuda   \n",
              "1       amp     True   cuda   \n",
              "\n",
              "                                                                                     model_dir  \\\n",
              "0  /home/tfs2123/hpml-project/pipelines/finBERT/models/profiling_runs/baseline_20251214_201606   \n",
              "1       /home/tfs2123/hpml-project/pipelines/finBERT/models/profiling_runs/amp_20251214_202056   \n",
              "\n",
              "   train_wall_s  train_examples  train_examples_per_s  model_size_mb  \\\n",
              "0    279.127465            3488             74.976499     417.658215   \n",
              "1    149.105554            3488            140.356945     417.658215   \n",
              "\n",
              "   profile_train_steps  train_data_transfer_ms  ...  train_optimizer_step_ms  \\\n",
              "0                   20              443.268123  ...               419.566644   \n",
              "1                   20              417.099585  ...               411.194942   \n",
              "\n",
              "   eval_wall_s  eval_num_samples  eval_samples_per_s      loss  accuracy  \\\n",
              "0     3.468168               970          279.686577  0.648285  0.760825   \n",
              "1     0.860187               970         1127.661839  0.638034  0.780412   \n",
              "\n",
              "   f1_positive  f1_negative  f1_neutral  f1_macro  \n",
              "0     0.665421     0.747664    0.811808  0.741631  \n",
              "1     0.698413     0.767742    0.827846  0.764667  \n",
              "\n",
              "[2 rows x 23 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# =========================\n",
        "# Training: baseline vs AMP\n",
        "# =========================\n",
        "\n",
        "if not DATA_DIR.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"DATA_DIR not found: {DATA_DIR}\\n\"\n",
        "        \"Create train/validation/test TSVs under data/sentiment_data (see pipelines/finBERT/README.md).\"\n",
        "    )\n",
        "\n",
        "device = resolve_device(PREFER_GPU, GPU_NAME)\n",
        "print_device_info(device)\n",
        "\n",
        "training_summaries: list[dict[str, Any]] = []\n",
        "trained_ckpts: dict[str, Path] = {}\n",
        "\n",
        "\n",
        "def run_train(tag: str, *, use_amp: bool) -> tuple[dict[str, Any], Path]:\n",
        "    run_dir = make_run_dir(tag)\n",
        "\n",
        "    cfg = make_finbert_config(model_dir=run_dir, use_amp=use_amp)\n",
        "\n",
        "    finbert = ProfiledFinBert(cfg)\n",
        "    finbert.base_model = BASE_MODEL_NAME\n",
        "    finbert.prepare_model(label_list=LABEL_LIST)\n",
        "\n",
        "    train_data = finbert.get_data(\"train\")\n",
        "    test_data = finbert.get_data(\"test\")\n",
        "\n",
        "    model = finbert.create_the_model()\n",
        "\n",
        "    wb = maybe_wandb_init(\n",
        "        run_name=f\"train-{tag}\",\n",
        "        config={\"tag\": tag, \"use_amp\": bool(use_amp), **TRAINING},\n",
        "        group=tag,\n",
        "    )\n",
        "\n",
        "    start = time.perf_counter()\n",
        "    trained_model = finbert.train(train_examples=train_data, model=model)\n",
        "    train_wall_s = time.perf_counter() - start\n",
        "\n",
        "    eval_df, eval_timing = timed_eval(\n",
        "        finbert=finbert, model=trained_model, examples=test_data, use_amp=bool(use_amp)\n",
        "    )\n",
        "    metrics = calculate_metrics(eval_df)\n",
        "\n",
        "    summary = {\n",
        "        \"run\": tag,\n",
        "        \"use_amp\": bool(use_amp and torch.cuda.is_available()),\n",
        "        \"device\": str(finbert.device),\n",
        "        \"model_dir\": str(run_dir),\n",
        "        \"train_wall_s\": float(train_wall_s),\n",
        "        \"train_examples\": int(len(train_data)),\n",
        "        \"train_examples_per_s\": float((len(train_data) * TRAINING[\"num_train_epochs\"]) / train_wall_s)\n",
        "        if train_wall_s > 0\n",
        "        else float(\"inf\"),\n",
        "        \"model_size_mb\": float(get_model_size_mb(trained_model)),\n",
        "        \"profile_train_steps\": int(getattr(cfg, \"profile_train_steps\", PROFILE_TRAIN_STEPS)),\n",
        "        **(finbert.profile_results.get(\"training_summary\", {}) or {}),\n",
        "        **eval_timing,\n",
        "        **metrics,\n",
        "    }\n",
        "\n",
        "    if wb is not None:\n",
        "        import wandb\n",
        "\n",
        "        wandb.log(summary)\n",
        "        wb.finish()\n",
        "\n",
        "    return summary, run_dir\n",
        "\n",
        "\n",
        "if RUN_TRAIN_BASELINE:\n",
        "    baseline_summary, baseline_dir = run_train(\"baseline\", use_amp=False)\n",
        "    training_summaries.append(baseline_summary)\n",
        "    trained_ckpts[\"baseline\"] = baseline_dir\n",
        "\n",
        "    # Use the freshly trained baseline checkpoint for inference benchmarking\n",
        "    BASELINE_CKPT_DIR = baseline_dir\n",
        "    print(\"✓ BASELINE_CKPT_DIR set to:\", BASELINE_CKPT_DIR)\n",
        "else:\n",
        "    print(\"Skipping baseline training. Using BASELINE_CKPT_DIR =\", BASELINE_CKPT_DIR)\n",
        "\n",
        "if RUN_TRAIN_AMP:\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"⚠ RUN_TRAIN_AMP=True but CUDA is not available — skipping AMP training.\")\n",
        "    else:\n",
        "        amp_summary, amp_dir = run_train(\"amp\", use_amp=True)\n",
        "        training_summaries.append(amp_summary)\n",
        "        trained_ckpts[\"amp\"] = amp_dir\n",
        "else:\n",
        "    print(\"Skipping AMP training.\")\n",
        "\n",
        "train_summary_df = pd.DataFrame(training_summaries)\n",
        "train_summary_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Device: cuda:0\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 14.6 GB\n",
            "================================================================================\n",
            "\n",
            "✓ Using baseline checkpoint: /home/tfs2123/hpml-project/pipelines/finBERT/models/profiling_runs/baseline_20251214_201606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/14/2025 20:23:30 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/tfs2123/hpml-project/pipelines/finBERT/notebooks/wandb/run-20251214_202331-k8slbil0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/k8slbil0' target=\"_blank\">infer-baseline</a></strong> to <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/k8slbil0' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/k8slbil0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/14/2025 20:23:33 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:33 - INFO - finbert.utils -   guid: test-1\n",
            "12/14/2025 20:23:33 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/14/2025 20:23:33 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:33 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:33 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:33 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/14/2025 20:23:33 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:23:33 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/14/2025 20:23:33 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:23:33 - INFO - finbert.finbert -     Num steps = 30\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Using 20 diverse examples from test dataset for profiling\n",
            "✓ Performing 3 warm-up passes...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   tokens: [CLS] the chilled meat products category led the meat , fish and poultry market in finland items in 2004 the new policy was also aimed at making the companies more profitable and competitive the group ' s business is balanced by its broad portfolio of sports and presence in all major markets the expansion will be delivered in the fourth quarter of 2006 [SEP]\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   input_ids: 101 1996 23362 6240 3688 4696 2419 1996 6240 1010 3869 1998 22468 3006 1999 6435 5167 1999 2432 1996 2047 3343 2001 2036 6461 2012 2437 1996 3316 2062 15282 1998 6975 1996 2177 1005 1055 2449 2003 12042 2011 2049 5041 11103 1997 2998 1998 3739 1999 2035 2350 6089 1996 4935 2097 2022 5359 1999 1996 2959 4284 1997 2294 102\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   label: None (id = 9090)\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   tokens: [CLS] the chilled meat products category led the meat , fish and poultry market in finland items in 2004 the new policy was also aimed at making the companies more profitable and competitive the group ' s business is balanced by its broad portfolio of sports and presence in all major markets the expansion will be delivered in the fourth quarter of 2006 [SEP]\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   input_ids: 101 1996 23362 6240 3688 4696 2419 1996 6240 1010 3869 1998 22468 3006 1999 6435 5167 1999 2432 1996 2047 3343 2001 2036 6461 2012 2437 1996 3316 2062 15282 1998 6975 1996 2177 1005 1055 2449 2003 12042 2011 2049 5041 11103 1997 2998 1998 3739 1999 2035 2350 6089 1996 4935 2097 2022 5359 1999 1996 2959 4284 1997 2294 102\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   label: None (id = 9090)\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   tokens: [CLS] the chilled meat products category led the meat , fish and poultry market in finland items in 2004 the new policy was also aimed at making the companies more profitable and competitive the group ' s business is balanced by its broad portfolio of sports and presence in all major markets the expansion will be delivered in the fourth quarter of 2006 [SEP]\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   input_ids: 101 1996 23362 6240 3688 4696 2419 1996 6240 1010 3869 1998 22468 3006 1999 6435 5167 1999 2432 1996 2047 3343 2001 2036 6461 2012 2437 1996 3316 2062 15282 1998 6975 1996 2177 1005 1055 2449 2003 12042 2011 2049 5041 11103 1997 2998 1998 3739 1999 2035 2350 6089 1996 4935 2097 2022 5359 1999 1996 2959 4284 1997 2294 102\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:37 - INFO - finbert.utils -   label: None (id = 9090)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Completed 3 warm-up passes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "12/14/2025 20:23:38 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:38 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 20:23:38 - INFO - finbert.utils -   tokens: [CLS] the chilled meat products category led the meat , fish and poultry market in finland items in 2004 the new policy was also aimed at making the companies more profitable and competitive the group ' s business is balanced by its broad portfolio of sports and presence in all major markets the expansion will be delivered in the fourth quarter of 2006 [SEP]\n",
            "12/14/2025 20:23:38 - INFO - finbert.utils -   input_ids: 101 1996 23362 6240 3688 4696 2419 1996 6240 1010 3869 1998 22468 3006 1999 6435 5167 1999 2432 1996 2047 3343 2001 2036 6461 2012 2437 1996 3316 2062 15282 1998 6975 1996 2177 1005 1055 2449 2003 12042 2011 2049 5041 11103 1997 2998 1998 3739 1999 2035 2350 6089 1996 4935 2097 2022 5359 1999 1996 2959 4284 1997 2294 102\n",
            "12/14/2025 20:23:38 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/14/2025 20:23:38 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:38 - INFO - finbert.utils -   label: None (id = 9090)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Device: cuda:0\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 14.6 GB\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Inference Profiling - baseline\n",
            "================================================================================\n",
            "\n",
            "By CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                      inference_forward        15.88%       5.543ms        44.27%      15.457ms      15.457ms       0.000us         0.00%       4.285ms       4.285ms           0 B          -8 B         512 B     -41.44 MB             1  \n",
            "                                    convert_to_features        36.60%      12.778ms        36.60%      12.778ms      12.778ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             1  \n",
            "                                           aten::linear         2.07%     722.689us        16.19%       5.654ms      76.404us       0.000us         0.00%       3.903ms      52.745us           0 B           0 B      20.25 MB           0 B            74  \n",
            "                                        model_to_device        10.06%       3.513ms        11.09%       3.873ms       3.873ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             1  \n",
            "                                            aten::addmm         7.40%       2.583ms        10.82%       3.779ms      51.069us       3.903ms        91.06%       3.903ms      52.745us           0 B           0 B      20.25 MB      20.25 MB            74  \n",
            "                                       cudaLaunchKernel         4.65%       1.624ms         4.65%       1.624ms       7.959us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           204  \n",
            "                                    postprocess_results         3.93%       1.371ms         4.17%       1.454ms       1.454ms       0.000us         0.00%       1.152us       1.152us           0 B         -12 B        -512 B        -512 B             1  \n",
            "                                       aten::layer_norm         0.43%     149.209us         3.78%       1.321ms      52.849us       0.000us         0.00%     105.182us       4.207us           0 B           0 B       4.69 MB     -25.00 KB            25  \n",
            "                                        prepare_tensors         0.84%     292.006us         3.39%       1.185ms       1.185ms       0.000us         0.00%       0.000us       0.000us           0 B      -1.50 KB       1.50 KB           0 B             1  \n",
            "                                aten::native_layer_norm         1.52%     530.826us         3.36%       1.172ms      46.880us     105.182us         2.45%     105.182us       4.207us           0 B           0 B       4.71 MB           0 B            25  \n",
            "                     aten::scaled_dot_product_attention         0.48%     165.947us         3.01%       1.051ms      87.601us       0.000us         0.00%     189.499us      15.792us           8 B        -184 B       2.25 MB           0 B            12  \n",
            "                                               aten::to         0.41%     142.453us         2.96%       1.035ms       4.905us       0.000us         0.00%       1.152us       0.005us          12 B           0 B       1.50 KB           0 B           211  \n",
            "                                         aten::_to_copy         0.11%      38.417us         2.56%     892.420us     223.105us       0.000us         0.00%       1.152us       0.288us          12 B           0 B       1.50 KB           0 B             4  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.38%     133.338us         2.54%     885.271us      73.773us       0.000us         0.00%     189.499us      15.792us         192 B           0 B       2.25 MB           0 B            12  \n",
            "                                            aten::copy_         0.20%      71.261us         2.26%     787.773us     196.943us       1.152us         0.03%       1.152us       0.288us           0 B           0 B           0 B           0 B             4  \n",
            "                                        aten::transpose         1.54%     538.391us         2.24%     782.952us       4.606us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           170  \n",
            "                                            aten::empty         1.94%     678.345us         1.94%     678.345us       5.258us       0.000us         0.00%       0.000us       0.000us       1.69 KB       1.69 KB       6.96 MB       6.96 MB           129  \n",
            "                                              aten::add         1.21%     421.674us         1.80%     627.270us      25.091us      53.663us         1.25%      53.663us       2.147us           0 B           0 B       4.69 MB       4.69 MB            25  \n",
            "                                Activity Buffer Request         1.74%     609.008us         1.74%     609.008us     609.008us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             1  \n",
            "                                                aten::t         0.68%     237.655us         1.72%     598.921us       8.094us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B            74  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 34.915ms\n",
            "Self CUDA time total: 4.286ms\n",
            "\n",
            "\n",
            "By CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                      inference_forward         0.00%       0.000us         0.00%       0.000us       0.000us      12.235ms       285.45%      12.235ms      12.235ms           0 B           0 B           0 B           0 B             1  \n",
            "                                      inference_forward        15.88%       5.543ms        44.27%      15.457ms      15.457ms       0.000us         0.00%       4.285ms       4.285ms           0 B          -8 B         512 B     -41.44 MB             1  \n",
            "                                           aten::linear         2.07%     722.689us        16.19%       5.654ms      76.404us       0.000us         0.00%       3.903ms      52.745us           0 B           0 B      20.25 MB           0 B            74  \n",
            "                                            aten::addmm         7.40%       2.583ms        10.82%       3.779ms      51.069us       3.903ms        91.06%       3.903ms      52.745us           0 B           0 B      20.25 MB      20.25 MB            74  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us       3.738ms        87.21%       3.738ms      60.289us           0 B           0 B           0 B           0 B            62  \n",
            "                     aten::scaled_dot_product_attention         0.48%     165.947us         3.01%       1.051ms      87.601us       0.000us         0.00%     189.499us      15.792us           8 B        -184 B       2.25 MB           0 B            12  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.38%     133.338us         2.54%     885.271us      73.773us       0.000us         0.00%     189.499us      15.792us         192 B           0 B       2.25 MB           0 B            12  \n",
            "                     aten::_efficient_attention_forward         0.65%     228.113us         1.63%     570.186us      47.516us     189.499us         4.42%     189.499us      15.792us         192 B           0 B       2.25 MB           0 B            12  \n",
            "fmha_cutlassF_f32_aligned_64x64_rf_sm75(PyTorchMemEf...         0.00%       0.000us         0.00%       0.000us       0.000us     189.499us         4.42%     189.499us      18.950us           0 B           0 B           0 B           0 B            10  \n",
            "void cublasLt::splitKreduce_kernel<32, 16, int, floa...         0.00%       0.000us         0.00%       0.000us       0.000us     142.043us         3.31%     142.043us       3.551us           0 B           0 B           0 B           0 B            40  \n",
            "                                       aten::layer_norm         0.43%     149.209us         3.78%       1.321ms      52.849us       0.000us         0.00%     105.182us       4.207us           0 B           0 B       4.69 MB     -25.00 KB            25  \n",
            "                                aten::native_layer_norm         1.52%     530.826us         3.36%       1.172ms      46.880us     105.182us         2.45%     105.182us       4.207us           0 B           0 B       4.71 MB           0 B            25  \n",
            "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us     105.182us         2.45%     105.182us       4.781us           0 B           0 B           0 B           0 B            22  \n",
            "                                              aten::add         1.21%     421.674us         1.80%     627.270us      25.091us      53.663us         1.25%      53.663us       2.147us           0 B           0 B       4.69 MB       4.69 MB            25  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      53.663us         1.25%      53.663us       2.439us           0 B           0 B           0 B           0 B            22  \n",
            "                                             aten::gelu         0.57%     197.753us         0.89%     309.843us      25.820us      31.615us         0.74%      31.615us       2.635us           0 B           0 B       9.00 MB       9.00 MB            12  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      31.615us         0.74%      31.615us       2.874us           0 B           0 B           0 B           0 B            11  \n",
            "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us      11.167us         0.26%      11.167us      11.167us           0 B           0 B           0 B           0 B             1  \n",
            "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us       8.190us         0.19%       8.190us       0.372us           0 B           0 B           0 B           0 B            22  \n",
            "                                             aten::tanh         0.06%      19.243us         0.08%      29.009us      29.009us       1.920us         0.04%       1.920us       1.920us           0 B           0 B       3.00 KB       3.00 KB             1  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 34.915ms\n",
            "Self CUDA time total: 4.286ms\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "⚠ Failed to log profiler table: 'FunctionEventAvg' object has no attribute 'cuda_time_total'\n",
            "\n",
            "Inference Summary:\n",
            "  Total sentences: 1\n",
            "  Total inference time: 15.40 ms\n",
            "  Time per sentence: 15.40 ms\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>eval_num_samples</td><td>▁</td></tr><tr><td>eval_samples_per_s</td><td>▁</td></tr><tr><td>eval_wall_s</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_negative</td><td>▁</td></tr><tr><td>f1_neutral</td><td>▁</td></tr><tr><td>f1_positive</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>model_size_mb</td><td>▁</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.76082</td></tr><tr><td>device</td><td>cuda:0</td></tr><tr><td>eval_num_samples</td><td>970</td></tr><tr><td>eval_samples_per_s</td><td>274.69663</td></tr><tr><td>eval_wall_s</td><td>3.53117</td></tr><tr><td>f1_macro</td><td>0.74163</td></tr><tr><td>f1_negative</td><td>0.74766</td></tr><tr><td>f1_neutral</td><td>0.81181</td></tr><tr><td>f1_positive</td><td>0.66542</td></tr><tr><td>loss</td><td>0.64828</td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">infer-baseline</strong> at: <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/k8slbil0' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/k8slbil0</a><br> View project at: <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_202331-k8slbil0/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/tfs2123/hpml-project/pipelines/finBERT/notebooks/wandb/run-20251214_202340-8gxxojwk</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/8gxxojwk' target=\"_blank\">infer-fp16_weights</a></strong> to <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/8gxxojwk' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/8gxxojwk</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "12/14/2025 20:23:42 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:42 - INFO - finbert.utils -   guid: test-1\n",
            "12/14/2025 20:23:42 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/14/2025 20:23:42 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:42 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:42 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:42 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/14/2025 20:23:42 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:23:42 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/14/2025 20:23:42 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:23:42 - INFO - finbert.finbert -     Num steps = 30\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Using 20 diverse examples from test dataset for profiling\n",
            "✓ Performing 3 warm-up passes...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/14/2025 20:23:43 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   tokens: [CLS] the subsidiary will be responsible for filter sales , local assembly of filters and after in 2007 , huh ##tama ##ki will continue to invest in organic growth copper , lead and nickel also dropped . . . hbo ##s ( hbo ##s ) plum ##met ##ed 20 % to 70 . 3 pen ##ce after saying this year + o ? [SEP]\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   input_ids: 101 1996 7506 2097 2022 3625 2005 11307 4341 1010 2334 3320 1997 17736 1998 2044 1999 2289 1010 9616 28282 3211 2097 3613 2000 15697 1999 7554 3930 6967 1010 2599 1998 15519 2036 3333 1012 1012 1012 14633 2015 1006 14633 2015 1007 22088 11368 2098 2322 1003 2000 3963 1012 1017 7279 3401 2044 3038 2023 2095 1009 1051 1029 102\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   label: None (id = 9090)\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   tokens: [CLS] the subsidiary will be responsible for filter sales , local assembly of filters and after in 2007 , huh ##tama ##ki will continue to invest in organic growth copper , lead and nickel also dropped . . . hbo ##s ( hbo ##s ) plum ##met ##ed 20 % to 70 . 3 pen ##ce after saying this year + o ? [SEP]\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   input_ids: 101 1996 7506 2097 2022 3625 2005 11307 4341 1010 2334 3320 1997 17736 1998 2044 1999 2289 1010 9616 28282 3211 2097 3613 2000 15697 1999 7554 3930 6967 1010 2599 1998 15519 2036 3333 1012 1012 1012 14633 2015 1006 14633 2015 1007 22088 11368 2098 2322 1003 2000 3963 1012 1017 7279 3401 2044 3038 2023 2095 1009 1051 1029 102\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   label: None (id = 9090)\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   tokens: [CLS] the subsidiary will be responsible for filter sales , local assembly of filters and after in 2007 , huh ##tama ##ki will continue to invest in organic growth copper , lead and nickel also dropped . . . hbo ##s ( hbo ##s ) plum ##met ##ed 20 % to 70 . 3 pen ##ce after saying this year + o ? [SEP]\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   input_ids: 101 1996 7506 2097 2022 3625 2005 11307 4341 1010 2334 3320 1997 17736 1998 2044 1999 2289 1010 9616 28282 3211 2097 3613 2000 15697 1999 7554 3930 6967 1010 2599 1998 15519 2036 3333 1012 1012 1012 14633 2015 1006 14633 2015 1007 22088 11368 2098 2322 1003 2000 3963 1012 1017 7279 3401 2044 3038 2023 2095 1009 1051 1029 102\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:43 - INFO - finbert.utils -   label: None (id = 9090)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Completed 3 warm-up passes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/14/2025 20:23:44 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:44 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 20:23:44 - INFO - finbert.utils -   tokens: [CLS] the subsidiary will be responsible for filter sales , local assembly of filters and after in 2007 , huh ##tama ##ki will continue to invest in organic growth copper , lead and nickel also dropped . . . hbo ##s ( hbo ##s ) plum ##met ##ed 20 % to 70 . 3 pen ##ce after saying this year + o ? [SEP]\n",
            "12/14/2025 20:23:44 - INFO - finbert.utils -   input_ids: 101 1996 7506 2097 2022 3625 2005 11307 4341 1010 2334 3320 1997 17736 1998 2044 1999 2289 1010 9616 28282 3211 2097 3613 2000 15697 1999 7554 3930 6967 1010 2599 1998 15519 2036 3333 1012 1012 1012 14633 2015 1006 14633 2015 1007 22088 11368 2098 2322 1003 2000 3963 1012 1017 7279 3401 2044 3038 2023 2095 1009 1051 1029 102\n",
            "12/14/2025 20:23:44 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/14/2025 20:23:44 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:44 - INFO - finbert.utils -   label: None (id = 9090)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Device: cuda:0\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 14.6 GB\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Inference Profiling - fp16_weights\n",
            "================================================================================\n",
            "\n",
            "By CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                      inference_forward        16.27%       6.291ms        45.79%      17.703ms      17.703ms       0.000us         0.00%       1.714ms       1.714ms           0 B           0 B         512 B     -41.35 MB             1  \n",
            "                                    convert_to_features        34.10%      13.183ms        34.10%      13.183ms      13.183ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             1  \n",
            "                                           aten::linear         2.20%     849.260us        16.66%       6.441ms      87.043us       0.000us         0.00%       1.449ms      19.583us           0 B           0 B      20.25 MB           0 B            74  \n",
            "                                            aten::addmm         8.45%       3.267ms        11.16%       4.315ms      58.309us       1.449ms        84.48%       1.449ms      19.583us           0 B           0 B      20.25 MB      20.25 MB            74  \n",
            "                                        model_to_device         9.40%       3.635ms        10.39%       4.017ms       4.017ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             1  \n",
            "                                        prepare_tensors         0.83%     320.555us         5.20%       2.011ms       2.011ms       0.000us         0.00%       0.000us       0.000us           0 B      -3.00 KB       3.00 KB           0 B             1  \n",
            "                                       cudaLaunchKernel         4.87%       1.883ms         4.87%       1.883ms      11.274us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           167  \n",
            "                                               aten::to         0.40%     155.435us         4.77%       1.845ms       8.744us       0.000us         0.00%       1.472us       0.007us          12 B           0 B       3.00 KB           0 B           211  \n",
            "                                         aten::_to_copy         0.12%      47.641us         4.37%       1.690ms     422.390us       0.000us         0.00%       1.472us       0.368us          12 B           0 B       3.00 KB           0 B             4  \n",
            "                                            aten::copy_         0.25%      97.808us         4.06%       1.569ms     392.263us       1.472us         0.09%       1.472us       0.368us           0 B           0 B           0 B           0 B             4  \n",
            "                                       aten::layer_norm         0.41%     159.617us         3.86%       1.493ms      59.739us       0.000us         0.00%      87.451us       3.498us           0 B           0 B       4.69 MB     -25.00 KB            25  \n",
            "                                    postprocess_results         3.52%       1.359ms         3.72%       1.439ms       1.439ms       0.000us         0.00%       1.472us       1.472us           0 B         -12 B        -512 B        -512 B             1  \n",
            "                                aten::native_layer_norm         1.57%     606.440us         3.45%       1.334ms      53.354us      87.451us         5.10%      87.451us       3.498us           0 B           0 B       4.71 MB           0 B            25  \n",
            "                     aten::scaled_dot_product_attention         0.44%     168.691us         3.08%       1.189ms      99.122us       0.000us         0.00%      94.142us       7.845us           0 B        -192 B       2.25 MB           0 B            12  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.41%     157.572us         2.64%       1.021ms      85.064us       0.000us         0.00%      94.142us       7.845us         192 B           0 B       2.25 MB           0 B            12  \n",
            "                                        aten::transpose         1.64%     632.990us         2.35%     908.582us       5.345us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           170  \n",
            "                                              aten::add         1.27%     492.218us         2.21%     852.729us      34.109us      43.870us         2.56%      43.870us       1.755us           0 B           0 B       4.69 MB       4.69 MB            25  \n",
            "                                        cudaMemcpyAsync         2.13%     824.339us         2.13%     824.339us     164.868us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             5  \n",
            "                                            aten::empty         1.90%     735.402us         1.90%     735.402us       5.701us       0.000us         0.00%       0.000us       0.000us       3.19 KB       3.19 KB       6.96 MB       6.96 MB           129  \n",
            "                                                aten::t         0.73%     283.384us         1.73%     669.244us       9.044us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B            74  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 38.657ms\n",
            "Self CUDA time total: 1.715ms\n",
            "\n",
            "\n",
            "By CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                      inference_forward         0.00%       0.000us         0.00%       0.000us       0.000us      13.247ms       772.29%      13.247ms      13.247ms           0 B           0 B           0 B           0 B             1  \n",
            "                                      inference_forward        16.27%       6.291ms        45.79%      17.703ms      17.703ms       0.000us         0.00%       1.714ms       1.714ms           0 B           0 B         512 B     -41.35 MB             1  \n",
            "                                           aten::linear         2.20%     849.260us        16.66%       6.441ms      87.043us       0.000us         0.00%       1.449ms      19.583us           0 B           0 B      20.25 MB           0 B            74  \n",
            "                                            aten::addmm         8.45%       3.267ms        11.16%       4.315ms      58.309us       1.449ms        84.48%       1.449ms      19.583us           0 B           0 B      20.25 MB      20.25 MB            74  \n",
            "turing_fp16_s1688gemm_fp16_64x64_sliced1x4_ldg8_relu...         0.00%       0.000us         0.00%       0.000us       0.000us     652.721us        38.05%     652.721us      16.736us           0 B           0 B           0 B           0 B            39  \n",
            "         turing_fp16_s1688gemm_fp16_128x128_ldg8_f2f_tn         0.00%       0.000us         0.00%       0.000us       0.000us     363.575us        21.20%     363.575us      36.357us           0 B           0 B           0 B           0 B            10  \n",
            "    turing_fp16_s1688gemm_fp16_128x128_ldg8_relu_f2f_tn         0.00%       0.000us         0.00%       0.000us       0.000us     362.614us        21.14%     362.614us      36.261us           0 B           0 B           0 B           0 B            10  \n",
            "                     aten::scaled_dot_product_attention         0.44%     168.691us         3.08%       1.189ms      99.122us       0.000us         0.00%      94.142us       7.845us           0 B        -192 B       2.25 MB           0 B            12  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.41%     157.572us         2.64%       1.021ms      85.064us       0.000us         0.00%      94.142us       7.845us         192 B           0 B       2.25 MB           0 B            12  \n",
            "                     aten::_efficient_attention_forward         0.66%     256.833us         1.70%     657.081us      54.757us      94.142us         5.49%      94.142us       7.845us         192 B           0 B       2.25 MB           0 B            12  \n",
            "fmha_cutlassF_f16_aligned_64x64_rf_sm75(PyTorchMemEf...         0.00%       0.000us         0.00%       0.000us       0.000us      94.142us         5.49%      94.142us       9.414us           0 B           0 B           0 B           0 B            10  \n",
            "                                       aten::layer_norm         0.41%     159.617us         3.86%       1.493ms      59.739us       0.000us         0.00%      87.451us       3.498us           0 B           0 B       4.69 MB     -25.00 KB            25  \n",
            "                                aten::native_layer_norm         1.57%     606.440us         3.45%       1.334ms      53.354us      87.451us         5.10%      87.451us       3.498us           0 B           0 B       4.71 MB           0 B            25  \n",
            "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us      87.451us         5.10%      87.451us       4.373us           0 B           0 B           0 B           0 B            20  \n",
            "void cublasLt::splitKreduce_kernel<32, 16, int, __ha...         0.00%       0.000us         0.00%       0.000us       0.000us      55.231us         3.22%      55.231us       5.523us           0 B           0 B           0 B           0 B            10  \n",
            "                                              aten::add         1.27%     492.218us         2.21%     852.729us      34.109us      43.870us         2.56%      43.870us       1.755us           0 B           0 B       4.69 MB       4.69 MB            25  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      43.870us         2.56%      43.870us       2.193us           0 B           0 B           0 B           0 B            20  \n",
            "                                             aten::gelu         0.59%     228.683us         0.90%     348.071us      29.006us      37.405us         2.18%      37.405us       3.117us           0 B           0 B       9.00 MB       9.00 MB            12  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      37.405us         2.18%      37.405us       3.740us           0 B           0 B           0 B           0 B            10  \n",
            "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, tr...         0.00%       0.000us         0.00%       0.000us       0.000us      15.008us         0.87%      15.008us       7.504us           0 B           0 B           0 B           0 B             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 38.657ms\n",
            "Self CUDA time total: 1.715ms\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "⚠ Failed to log profiler table: 'FunctionEventAvg' object has no attribute 'cuda_time_total'\n",
            "\n",
            "Inference Summary:\n",
            "  Total sentences: 2\n",
            "  Total inference time: 17.64 ms\n",
            "  Time per sentence: 8.82 ms\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>eval_num_samples</td><td>▁</td></tr><tr><td>eval_samples_per_s</td><td>▁</td></tr><tr><td>eval_wall_s</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_negative</td><td>▁</td></tr><tr><td>f1_neutral</td><td>▁</td></tr><tr><td>f1_positive</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>model_size_mb</td><td>▁</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.76082</td></tr><tr><td>device</td><td>cuda:0</td></tr><tr><td>eval_num_samples</td><td>970</td></tr><tr><td>eval_samples_per_s</td><td>1286.09098</td></tr><tr><td>eval_wall_s</td><td>0.75422</td></tr><tr><td>f1_macro</td><td>0.74163</td></tr><tr><td>f1_negative</td><td>0.74766</td></tr><tr><td>f1_neutral</td><td>0.81181</td></tr><tr><td>f1_positive</td><td>0.66542</td></tr><tr><td>loss</td><td>0.64829</td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">infer-fp16_weights</strong> at: <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/8gxxojwk' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/8gxxojwk</a><br> View project at: <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_202340-8gxxojwk/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/tfs2123/hpml-project/pipelines/finBERT/notebooks/wandb/run-20251214_202346-sznnc969</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/sznnc969' target=\"_blank\">infer-amp_autocast</a></strong> to <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/sznnc969' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/sznnc969</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/14/2025 20:23:48 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:48 - INFO - finbert.utils -   guid: test-1\n",
            "12/14/2025 20:23:48 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/14/2025 20:23:48 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:48 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:48 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:48 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/14/2025 20:23:48 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/14/2025 20:23:48 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/14/2025 20:23:48 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/14/2025 20:23:48 - INFO - finbert.finbert -     Num steps = 30\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Using 20 diverse examples from test dataset for profiling\n",
            "✓ Performing 3 warm-up passes...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "12/14/2025 20:23:49 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:49 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 20:23:49 - INFO - finbert.utils -   tokens: [CLS] both operating profit and net sales for the six - month period increased , respectively ##uance of a maximum of 30 ##m ##n new shares in one or more share issues the company booked april - june new orders worth 94 ##9 ml ##n eu ##r , compared with 78 ##6 ml ##n eu ##r in the same period a year ago [SEP]\n",
            "12/14/2025 20:23:49 - INFO - finbert.utils -   input_ids: 101 2119 4082 5618 1998 5658 4341 2005 1996 2416 1011 3204 2558 3445 1010 4414 26620 1997 1037 4555 1997 2382 2213 2078 2047 6661 1999 2028 2030 2062 3745 3314 1996 2194 17414 2258 1011 2238 2047 4449 4276 6365 2683 19875 2078 7327 2099 1010 4102 2007 6275 2575 19875 2078 7327 2099 1999 1996 2168 2558 1037 2095 3283 102\n",
            "12/14/2025 20:23:49 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/14/2025 20:23:49 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:49 - INFO - finbert.utils -   label: None (id = 9090)\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   tokens: [CLS] both operating profit and net sales for the six - month period increased , respectively ##uance of a maximum of 30 ##m ##n new shares in one or more share issues the company booked april - june new orders worth 94 ##9 ml ##n eu ##r , compared with 78 ##6 ml ##n eu ##r in the same period a year ago [SEP]\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   input_ids: 101 2119 4082 5618 1998 5658 4341 2005 1996 2416 1011 3204 2558 3445 1010 4414 26620 1997 1037 4555 1997 2382 2213 2078 2047 6661 1999 2028 2030 2062 3745 3314 1996 2194 17414 2258 1011 2238 2047 4449 4276 6365 2683 19875 2078 7327 2099 1010 4102 2007 6275 2575 19875 2078 7327 2099 1999 1996 2168 2558 1037 2095 3283 102\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   label: None (id = 9090)\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   tokens: [CLS] both operating profit and net sales for the six - month period increased , respectively ##uance of a maximum of 30 ##m ##n new shares in one or more share issues the company booked april - june new orders worth 94 ##9 ml ##n eu ##r , compared with 78 ##6 ml ##n eu ##r in the same period a year ago [SEP]\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   input_ids: 101 2119 4082 5618 1998 5658 4341 2005 1996 2416 1011 3204 2558 3445 1010 4414 26620 1997 1037 4555 1997 2382 2213 2078 2047 6661 1999 2028 2030 2062 3745 3314 1996 2194 17414 2258 1011 2238 2047 4449 4276 6365 2683 19875 2078 7327 2099 1010 4102 2007 6275 2575 19875 2078 7327 2099 1999 1996 2168 2558 1037 2095 3283 102\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   label: None (id = 9090)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Completed 3 warm-up passes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   *** Example ***\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   guid: 0\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   tokens: [CLS] both operating profit and net sales for the six - month period increased , respectively ##uance of a maximum of 30 ##m ##n new shares in one or more share issues the company booked april - june new orders worth 94 ##9 ml ##n eu ##r , compared with 78 ##6 ml ##n eu ##r in the same period a year ago [SEP]\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   input_ids: 101 2119 4082 5618 1998 5658 4341 2005 1996 2416 1011 3204 2558 3445 1010 4414 26620 1997 1037 4555 1997 2382 2213 2078 2047 6661 1999 2028 2030 2062 3745 3314 1996 2194 17414 2258 1011 2238 2047 4449 4276 6365 2683 19875 2078 7327 2099 1010 4102 2007 6275 2575 19875 2078 7327 2099 1999 1996 2168 2558 1037 2095 3283 102\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/14/2025 20:23:50 - INFO - finbert.utils -   label: None (id = 9090)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Device: cuda:0\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 14.6 GB\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Inference Profiling - amp_autocast\n",
            "================================================================================\n",
            "\n",
            "By CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                      inference_forward        14.70%       6.138ms        53.23%      22.231ms      22.231ms       0.000us         0.00%       3.860ms       3.860ms           0 B           0 B         512 B    -223.29 MB             1  \n",
            "                                           aten::linear         3.39%       1.416ms        41.29%      17.244ms     116.513us       0.000us         0.00%       4.759ms      32.155us           0 B           0 B     217.86 MB      -4.31 MB           148  \n",
            "                                    convert_to_features        30.23%      12.626ms        30.23%      12.626ms      12.626ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             1  \n",
            "                                               aten::to         1.20%     503.115us        16.92%       7.068ms      17.324us       0.000us         0.00%       2.210ms       5.416us           6 B           0 B     201.92 MB           0 B           408  \n",
            "                                         aten::_to_copy         2.65%       1.109ms        15.72%       6.565ms      32.661us       0.000us         0.00%       2.210ms      10.993us           6 B           0 B     201.92 MB           0 B           201  \n",
            "                                            aten::copy_         3.71%       1.550ms         9.93%       4.149ms      20.640us       2.210ms        57.22%       2.210ms      10.993us           0 B           0 B           0 B           0 B           201  \n",
            "                                            aten::addmm         6.32%       2.639ms         8.76%       3.658ms      49.435us       1.276ms        33.03%       1.276ms      17.238us           0 B           0 B      10.13 MB      10.13 MB            74  \n",
            "                                        model_to_device         7.75%       3.238ms         8.53%       3.562ms       3.562ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             1  \n",
            "                                       cudaLaunchKernel         7.07%       2.954ms         7.07%       2.954ms       7.154us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           413  \n",
            "                                        prepare_tensors         0.61%     253.803us         3.96%       1.652ms       1.652ms       0.000us         0.00%       0.000us       0.000us           0 B      -1.50 KB       1.50 KB           0 B             1  \n",
            "                                    postprocess_results         3.49%       1.456ms         3.67%       1.533ms       1.533ms       0.000us         0.00%       1.984us       1.984us           0 B          -6 B        -512 B        -512 B             1  \n",
            "                                       aten::layer_norm         0.52%     215.843us         3.49%       1.459ms      58.367us       0.000us         0.00%     110.240us       4.410us           0 B           0 B       4.69 MB     -25.00 KB            25  \n",
            "                                    aten::empty_strided         3.13%       1.308ms         3.13%       1.308ms       6.506us       0.000us         0.00%       0.000us       0.000us           6 B           6 B     201.92 MB     201.92 MB           201  \n",
            "                                aten::native_layer_norm         1.23%     511.835us         2.98%       1.243ms      49.734us     110.240us         2.85%     110.240us       4.410us           0 B           0 B       4.71 MB           0 B            25  \n",
            "                     aten::scaled_dot_product_attention         0.41%     171.747us         2.40%       1.004ms      83.685us       0.000us         0.00%     104.478us       8.707us           0 B        -192 B       1.12 MB           0 B            12  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.30%     124.436us         1.99%     832.467us      69.372us       0.000us         0.00%     104.478us       8.707us         192 B           0 B       1.12 MB           0 B            12  \n",
            "                                        aten::transpose         1.34%     561.101us         1.91%     796.246us       4.684us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           170  \n",
            "                                            aten::empty         1.77%     738.911us         1.77%     738.911us       5.728us       0.000us         0.00%       0.000us       0.000us       1.69 KB       1.69 KB       5.84 MB       5.84 MB           129  \n",
            "                                        cudaMemcpyAsync         1.52%     635.367us         1.52%     635.367us     127.073us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B             5  \n",
            "                                              aten::add         1.00%     419.112us         1.51%     628.636us      25.145us     128.572us         3.33%     128.572us       5.143us           0 B           0 B       4.69 MB       4.69 MB            25  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 41.764ms\n",
            "Self CUDA time total: 3.862ms\n",
            "\n",
            "\n",
            "By CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                      inference_forward         0.00%       0.000us         0.00%       0.000us       0.000us      19.074ms       493.92%      19.074ms      19.074ms           0 B           0 B           0 B           0 B             1  \n",
            "                                           aten::linear         3.39%       1.416ms        41.29%      17.244ms     116.513us       0.000us         0.00%       4.759ms      32.155us           0 B           0 B     217.86 MB      -4.31 MB           148  \n",
            "                                      inference_forward        14.70%       6.138ms        53.23%      22.231ms      22.231ms       0.000us         0.00%       3.860ms       3.860ms           0 B           0 B         512 B    -223.29 MB             1  \n",
            "                                               aten::to         1.20%     503.115us        16.92%       7.068ms      17.324us       0.000us         0.00%       2.210ms       5.416us           6 B           0 B     201.92 MB           0 B           408  \n",
            "                                         aten::_to_copy         2.65%       1.109ms        15.72%       6.565ms      32.661us       0.000us         0.00%       2.210ms      10.993us           6 B           0 B     201.92 MB           0 B           201  \n",
            "                                            aten::copy_         3.71%       1.550ms         9.93%       4.149ms      20.640us       2.210ms        57.22%       2.210ms      10.993us           0 B           0 B           0 B           0 B           201  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.208ms        57.17%       2.208ms      12.064us           0 B           0 B           0 B           0 B           183  \n",
            "                                            aten::addmm         6.32%       2.639ms         8.76%       3.658ms      49.435us       1.276ms        33.03%       1.276ms      17.238us           0 B           0 B      10.13 MB      10.13 MB            74  \n",
            "turing_fp16_s1688gemm_fp16_128x64_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us     757.256us        19.61%     757.256us      13.522us           0 B           0 B           0 B           0 B            56  \n",
            "turing_fp16_s1688gemm_fp16_128x64_sliced1x2_ldg8_rel...         0.00%       0.000us         0.00%       0.000us       0.000us     305.272us         7.91%     305.272us      27.752us           0 B           0 B           0 B           0 B            11  \n",
            "void cublasLt::splitKreduce_kernel<32, 16, int, __ha...         0.00%       0.000us         0.00%       0.000us       0.000us     203.544us         5.27%     203.544us       3.635us           0 B           0 B           0 B           0 B            56  \n",
            "                                              aten::add         1.00%     419.112us         1.51%     628.636us      25.145us     128.572us         3.33%     128.572us       5.143us           0 B           0 B       4.69 MB       4.69 MB            25  \n",
            "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us     128.572us         3.33%     128.572us       5.590us           0 B           0 B           0 B           0 B            23  \n",
            "                                       aten::layer_norm         0.52%     215.843us         3.49%       1.459ms      58.367us       0.000us         0.00%     110.240us       4.410us           0 B           0 B       4.69 MB     -25.00 KB            25  \n",
            "                                aten::native_layer_norm         1.23%     511.835us         2.98%       1.243ms      49.734us     110.240us         2.85%     110.240us       4.410us           0 B           0 B       4.71 MB           0 B            25  \n",
            "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us     110.240us         2.85%     110.240us       4.793us           0 B           0 B           0 B           0 B            23  \n",
            "                     aten::scaled_dot_product_attention         0.41%     171.747us         2.40%       1.004ms      83.685us       0.000us         0.00%     104.478us       8.707us           0 B        -192 B       1.12 MB           0 B            12  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.30%     124.436us         1.99%     832.467us      69.372us       0.000us         0.00%     104.478us       8.707us         192 B           0 B       1.12 MB           0 B            12  \n",
            "                     aten::_efficient_attention_forward         0.48%     200.502us         1.28%     535.832us      44.653us     104.478us         2.71%     104.478us       8.707us         192 B           0 B       1.12 MB           0 B            12  \n",
            "fmha_cutlassF_f16_aligned_64x64_rf_sm75(PyTorchMemEf...         0.00%       0.000us         0.00%       0.000us       0.000us     104.478us         2.71%     104.478us       9.498us           0 B           0 B           0 B           0 B            11  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 41.764ms\n",
            "Self CUDA time total: 3.862ms\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "⚠ Failed to log profiler table: 'FunctionEventAvg' object has no attribute 'cuda_time_total'\n",
            "\n",
            "Inference Summary:\n",
            "  Total sentences: 1\n",
            "  Total inference time: 22.17 ms\n",
            "  Time per sentence: 22.17 ms\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>eval_num_samples</td><td>▁</td></tr><tr><td>eval_samples_per_s</td><td>▁</td></tr><tr><td>eval_wall_s</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_negative</td><td>▁</td></tr><tr><td>f1_neutral</td><td>▁</td></tr><tr><td>f1_positive</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>model_size_mb</td><td>▁</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.76082</td></tr><tr><td>device</td><td>cuda:0</td></tr><tr><td>eval_num_samples</td><td>970</td></tr><tr><td>eval_samples_per_s</td><td>1082.3448</td></tr><tr><td>eval_wall_s</td><td>0.8962</td></tr><tr><td>f1_macro</td><td>0.74163</td></tr><tr><td>f1_negative</td><td>0.74766</td></tr><tr><td>f1_neutral</td><td>0.81181</td></tr><tr><td>f1_positive</td><td>0.66542</td></tr><tr><td>loss</td><td>0.64828</td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">infer-amp_autocast</strong> at: <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/sznnc969' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/sznnc969</a><br> View project at: <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_202346-sznnc969/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ================================================\n",
        "# Inference benchmarking: baseline ckpt variations\n",
        "# ================================================\n",
        "\n",
        "if RUN_INFER_BENCHMARKS:\n",
        "    device = resolve_device(PREFER_GPU, GPU_NAME)\n",
        "    use_gpu = device.type != \"cpu\"\n",
        "\n",
        "    print_device_info(device)\n",
        "    print(\"✓ Using baseline checkpoint:\", BASELINE_CKPT_DIR)\n",
        "\n",
        "    # Ensure sentence tokenizer is available\n",
        "    setup_nltk_data()\n",
        "\n",
        "    # FinBERT instance for data loading + batching (model_dir must be empty)\n",
        "    eval_dir = make_run_dir(\"_eval\")\n",
        "    eval_cfg = Config(\n",
        "        data_dir=DATA_DIR,\n",
        "        bert_model=None,\n",
        "        model_dir=eval_dir,\n",
        "        max_seq_length=TRAINING[\"max_seq_length\"],\n",
        "        train_batch_size=TRAINING[\"eval_batch_size\"],\n",
        "        eval_batch_size=TRAINING[\"eval_batch_size\"],\n",
        "        learning_rate=TRAINING[\"learning_rate\"],\n",
        "        num_train_epochs=1,\n",
        "        warm_up_proportion=TRAINING[\"warm_up_proportion\"],\n",
        "        local_rank=-1,\n",
        "        output_mode=\"classification\",\n",
        "        discriminate=False,\n",
        "        gradual_unfreeze=False,\n",
        "        fp16=False,\n",
        "        use_amp=False,\n",
        "    )\n",
        "\n",
        "    finbert_eval = FinBert(eval_cfg)\n",
        "    finbert_eval.base_model = BASE_MODEL_NAME\n",
        "    finbert_eval.prepare_model(label_list=LABEL_LIST)\n",
        "    test_data = finbert_eval.get_data(\"test\")\n",
        "\n",
        "    def load_model_from_ckpt(*, ckpt_dir: Path, torch_dtype=None) -> torch.nn.Module:\n",
        "        if torch_dtype is None:\n",
        "            model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                ckpt_dir, cache_dir=None, num_labels=3\n",
        "            )\n",
        "        else:\n",
        "            model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                ckpt_dir, cache_dir=None, num_labels=3, torch_dtype=torch_dtype\n",
        "            )\n",
        "        return model.to(device)\n",
        "\n",
        "    variants = list(INFERENCE_VARIANTS.items())\n",
        "\n",
        "    inference_rows: list[dict[str, Any]] = []\n",
        "\n",
        "    # Start separate W&B runs for each variant instead of one big run\n",
        "    # This allows comparing them as separate runs in the dashboard (Grouped by name or variant)\n",
        "    \n",
        "    for variant_name, spec in variants:\n",
        "        if spec[\"requires_cuda\"] and device.type != \"cuda\":\n",
        "            print(f\"Skipping {variant_name} (requires CUDA; current device={device})\")\n",
        "            continue\n",
        "\n",
        "        # Init W&B for this specific variant run\n",
        "        wb = maybe_wandb_init(\n",
        "            run_name=f\"infer-{variant_name}\",\n",
        "            config={\n",
        "                \"variant\": variant_name, \n",
        "                \"baseline_ckpt\": str(BASELINE_CKPT_DIR), \n",
        "                **TRAINING\n",
        "            },\n",
        "            group=variant_name,\n",
        "        )\n",
        "\n",
        "        use_amp = bool(spec[\"use_amp\"])\n",
        "        model = load_model_from_ckpt(ckpt_dir=BASELINE_CKPT_DIR, torch_dtype=spec[\"torch_dtype\"])\n",
        "\n",
        "        # Dataset eval: throughput + accuracy\n",
        "        eval_df, eval_timing = timed_eval(\n",
        "            finbert=finbert_eval, model=model, examples=test_data, use_amp=use_amp\n",
        "        )\n",
        "        metrics = calculate_metrics(eval_df)\n",
        "\n",
        "        # Prepare profiling text: use test data if enabled, otherwise fallback\n",
        "        if USE_TEST_DATA_FOR_PROFILING and test_data:\n",
        "            profiling_text = prepare_profiling_text(test_data, INFER_PROFILE_NUM_EXAMPLES)\n",
        "            print(f\"✓ Using {INFER_PROFILE_NUM_EXAMPLES} diverse examples from test dataset for profiling\")\n",
        "        else:\n",
        "            profiling_text = INFER_TEST_TEXT\n",
        "            print(\"✓ Using fallback single text for profiling\")\n",
        "        \n",
        "        # Warm-up passes before profiling (to account for CUDA kernel initialization, etc.)\n",
        "        if INFER_PROFILE_WARMUP_PASSES > 0:\n",
        "            print(f\"✓ Performing {INFER_PROFILE_WARMUP_PASSES} warm-up passes...\")\n",
        "            warmup_inference(model, profiling_text, device, use_amp, INFER_PROFILE_WARMUP_PASSES)\n",
        "\n",
        "        # Text inference profiling (torch.profiler + forward timing)\n",
        "        _pred_df, prof_metrics = profile_inference(\n",
        "            profiling_text,\n",
        "            model,\n",
        "            variant_name=variant_name,\n",
        "            use_gpu=use_gpu,\n",
        "            gpu_name=GPU_NAME,\n",
        "            batch_size=INFER_TEXT_BATCH_SIZE,\n",
        "            use_amp=use_amp,\n",
        "        )\n",
        "\n",
        "        # Prefix the text-inference metrics to avoid collisions\n",
        "        text_metrics = {f\"text_{k}\": v for k, v in prof_metrics.items() if k != \"variant\"}\n",
        "\n",
        "        row = {\n",
        "            \"variant\": variant_name,\n",
        "            \"device\": str(device),\n",
        "            \"use_amp\": use_amp,\n",
        "            \"model_size_mb\": float(get_model_size_mb(model)),\n",
        "            **eval_timing,\n",
        "            **metrics,\n",
        "            **text_metrics,\n",
        "        }\n",
        "        inference_rows.append(row)\n",
        "\n",
        "        if wb is not None:\n",
        "            import wandb\n",
        "            # Log metrics without variant prefix so they line up on charts across runs\n",
        "            wandb.log({k: v for k, v in row.items() if k != \"variant\"})\n",
        "            wb.finish()\n",
        "\n",
        "    inference_summary_df = pd.DataFrame(inference_rows)\n",
        "    inference_summary_df\n",
        "else:\n",
        "    inference_summary_df = pd.DataFrame()\n",
        "    print(\"Skipping inference benchmarking\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Training summary ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run</th>\n",
              "      <th>use_amp</th>\n",
              "      <th>device</th>\n",
              "      <th>train_wall_s</th>\n",
              "      <th>train_examples_per_s</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>train_forward_pass_ms</th>\n",
              "      <th>train_backward_pass_ms</th>\n",
              "      <th>train_optimizer_step_ms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>amp</td>\n",
              "      <td>True</td>\n",
              "      <td>cuda</td>\n",
              "      <td>149.105554</td>\n",
              "      <td>140.356945</td>\n",
              "      <td>0.780412</td>\n",
              "      <td>0.764667</td>\n",
              "      <td>616.350180</td>\n",
              "      <td>929.680063</td>\n",
              "      <td>411.194942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>baseline</td>\n",
              "      <td>False</td>\n",
              "      <td>cuda</td>\n",
              "      <td>279.127465</td>\n",
              "      <td>74.976499</td>\n",
              "      <td>0.760825</td>\n",
              "      <td>0.741631</td>\n",
              "      <td>657.874043</td>\n",
              "      <td>910.830685</td>\n",
              "      <td>419.566644</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        run  use_amp device  train_wall_s  train_examples_per_s  accuracy  \\\n",
              "1       amp     True   cuda    149.105554            140.356945  0.780412   \n",
              "0  baseline    False   cuda    279.127465             74.976499  0.760825   \n",
              "\n",
              "   f1_macro  train_forward_pass_ms  train_backward_pass_ms  \\\n",
              "1  0.764667             616.350180              929.680063   \n",
              "0  0.741631             657.874043              910.830685   \n",
              "\n",
              "   train_optimizer_step_ms  \n",
              "1               411.194942  \n",
              "0               419.566644  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training speedup (baseline/amp): 1.87x | Δaccuracy (amp-baseline): +0.0196 | Δf1_macro (amp-baseline): +0.0230\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Inference summary ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>variant</th>\n",
              "      <th>device</th>\n",
              "      <th>model_size_mb</th>\n",
              "      <th>eval_samples_per_s</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>text_time_per_sentence_ms</th>\n",
              "      <th>eval_speedup_vs_baseline</th>\n",
              "      <th>compression_vs_baseline</th>\n",
              "      <th>text_latency_speedup_vs_baseline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>amp_autocast</td>\n",
              "      <td>cuda:0</td>\n",
              "      <td>417.658215</td>\n",
              "      <td>1082.344803</td>\n",
              "      <td>0.760825</td>\n",
              "      <td>0.741631</td>\n",
              "      <td>22.168159</td>\n",
              "      <td>3.940146</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.694547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>baseline</td>\n",
              "      <td>cuda:0</td>\n",
              "      <td>417.658215</td>\n",
              "      <td>274.696628</td>\n",
              "      <td>0.760825</td>\n",
              "      <td>0.741631</td>\n",
              "      <td>15.396833</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fp16_weights</td>\n",
              "      <td>cuda:0</td>\n",
              "      <td>208.833014</td>\n",
              "      <td>1286.090981</td>\n",
              "      <td>0.760825</td>\n",
              "      <td>0.741631</td>\n",
              "      <td>8.819580</td>\n",
              "      <td>4.681859</td>\n",
              "      <td>1.999963</td>\n",
              "      <td>1.745756</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        variant  device  model_size_mb  eval_samples_per_s  accuracy  \\\n",
              "0  amp_autocast  cuda:0     417.658215         1082.344803  0.760825   \n",
              "1      baseline  cuda:0     417.658215          274.696628  0.760825   \n",
              "2  fp16_weights  cuda:0     208.833014         1286.090981  0.760825   \n",
              "\n",
              "   f1_macro  text_time_per_sentence_ms  eval_speedup_vs_baseline  \\\n",
              "0  0.741631                  22.168159                  3.940146   \n",
              "1  0.741631                  15.396833                  1.000000   \n",
              "2  0.741631                   8.819580                  4.681859   \n",
              "\n",
              "   compression_vs_baseline  text_latency_speedup_vs_baseline  \n",
              "0                 1.000000                          0.694547  \n",
              "1                 1.000000                          1.000000  \n",
              "2                 1.999963                          1.745756  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fp16_weights: Δaccuracy=+0.0000, Δf1_macro=+0.0000, eval_speedup=4.68x, compression=2.00x\n",
            "amp_autocast: Δaccuracy=+0.0000, Δf1_macro=+0.0000, eval_speedup=3.94x, compression=1.00x\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =========================\n",
        "# Results: tables + plots\n",
        "# =========================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "\n",
        "print(\"\\n=== Training summary ===\")\n",
        "if \"train_summary_df\" in globals() and not train_summary_df.empty:\n",
        "    cols = [\n",
        "        \"run\",\n",
        "        \"use_amp\",\n",
        "        \"device\",\n",
        "        \"train_wall_s\",\n",
        "        \"train_examples_per_s\",\n",
        "        \"accuracy\",\n",
        "        \"f1_macro\",\n",
        "        \"train_forward_pass_ms\",\n",
        "        \"train_backward_pass_ms\",\n",
        "        \"train_optimizer_step_ms\",\n",
        "    ]\n",
        "    cols = [c for c in cols if c in train_summary_df.columns]\n",
        "    display(train_summary_df[cols].sort_values(\"run\"))\n",
        "\n",
        "    if {\"baseline\", \"amp\"}.issubset(set(train_summary_df[\"run\"])):\n",
        "        base = train_summary_df[train_summary_df[\"run\"] == \"baseline\"].iloc[0]\n",
        "        amp = train_summary_df[train_summary_df[\"run\"] == \"amp\"].iloc[0]\n",
        "        print(\n",
        "            f\"Training speedup (baseline/amp): {base['train_wall_s'] / amp['train_wall_s']:.2f}x | \"\n",
        "            f\"Δaccuracy (amp-baseline): {amp['accuracy'] - base['accuracy']:+.4f} | \"\n",
        "            f\"Δf1_macro (amp-baseline): {amp['f1_macro'] - base['f1_macro']:+.4f}\"\n",
        "        )\n",
        "\n",
        "    ax = train_summary_df.set_index(\"run\")[\"train_wall_s\"].plot(\n",
        "        kind=\"bar\", title=\"Training wall time (s)\", rot=0\n",
        "    )\n",
        "    ax.set_ylabel(\"seconds\")\n",
        "    plt.show()\n",
        "\n",
        "    ax = train_summary_df.set_index(\"run\")[\"train_examples_per_s\"].plot(\n",
        "        kind=\"bar\", title=\"Training throughput (examples/sec)\", rot=0\n",
        "    )\n",
        "    ax.set_ylabel(\"examples/sec\")\n",
        "    plt.show()\n",
        "\n",
        "    ax = train_summary_df.set_index(\"run\")[[\"accuracy\", \"f1_macro\"]].plot(\n",
        "        kind=\"bar\", title=\"Test metrics\", rot=0\n",
        "    )\n",
        "    ax.set_ylabel(\"score\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"(no training runs executed)\")\n",
        "\n",
        "\n",
        "print(\"\\n=== Inference summary ===\")\n",
        "if \"inference_summary_df\" in globals() and not inference_summary_df.empty:\n",
        "    df = inference_summary_df.copy()\n",
        "\n",
        "    if \"baseline\" in set(df[\"variant\"]):\n",
        "        base = df[df[\"variant\"] == \"baseline\"].iloc[0]\n",
        "        df[\"eval_speedup_vs_baseline\"] = df[\"eval_samples_per_s\"] / base[\"eval_samples_per_s\"]\n",
        "        df[\"compression_vs_baseline\"] = base[\"model_size_mb\"] / df[\"model_size_mb\"]\n",
        "        if \"text_time_per_sentence_ms\" in df.columns and base.get(\"text_time_per_sentence_ms\"):\n",
        "            df[\"text_latency_speedup_vs_baseline\"] = (\n",
        "                base[\"text_time_per_sentence_ms\"] / df[\"text_time_per_sentence_ms\"]\n",
        "            )\n",
        "\n",
        "    display(\n",
        "        df[[\n",
        "            \"variant\",\n",
        "            \"device\",\n",
        "            \"model_size_mb\",\n",
        "            \"eval_samples_per_s\",\n",
        "            \"accuracy\",\n",
        "            \"f1_macro\",\n",
        "            \"text_time_per_sentence_ms\",\n",
        "            \"eval_speedup_vs_baseline\",\n",
        "            \"compression_vs_baseline\",\n",
        "            \"text_latency_speedup_vs_baseline\",\n",
        "        ]]\n",
        "        .sort_values(\"variant\")\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    if \"baseline\" in set(df[\"variant\"]):\n",
        "        base = df[df[\"variant\"] == \"baseline\"].iloc[0]\n",
        "        for _, row in df.iterrows():\n",
        "            if row[\"variant\"] == \"baseline\":\n",
        "                continue\n",
        "            print(\n",
        "                f\"{row['variant']}: Δaccuracy={row['accuracy'] - base['accuracy']:+.4f}, \"\n",
        "                f\"Δf1_macro={row['f1_macro'] - base['f1_macro']:+.4f}, \"\n",
        "                f\"eval_speedup={row.get('eval_speedup_vs_baseline', float('nan')):.2f}x, \"\n",
        "                f\"compression={row.get('compression_vs_baseline', float('nan')):.2f}x\"\n",
        "            )\n",
        "\n",
        "    ax = df.set_index(\"variant\")[\"eval_samples_per_s\"].plot(\n",
        "        kind=\"bar\", title=\"Test-set throughput (samples/sec)\", rot=0\n",
        "    )\n",
        "    ax.set_ylabel(\"samples/sec\")\n",
        "    plt.show()\n",
        "\n",
        "    if \"text_time_per_sentence_ms\" in df.columns:\n",
        "        ax = df.set_index(\"variant\")[\"text_time_per_sentence_ms\"].plot(\n",
        "            kind=\"bar\", title=\"Text inference latency (ms/sentence)\", rot=0\n",
        "        )\n",
        "        ax.set_ylabel(\"ms/sentence\")\n",
        "        plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"(no inference benchmarks executed)\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
