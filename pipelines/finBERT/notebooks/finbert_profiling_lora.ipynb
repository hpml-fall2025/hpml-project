{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FinBERT Profiling: LoRA\n",
        "\n",
        "This notebook reuses the profiling utilities in `pipelines/finBERT/finbert/` (especially `finbert/finbert_profile.py` and `finbert/profile_utils.py`) instead of copying large code blocks.\n",
        "\n",
        "The purpose of this notebook is to profile training the original FinBERT model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Helper utilities loaded\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import os\n",
        "import logging\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from textblob import TextBlob\n",
        "from pprint import pprint\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "from finbert.finbert import *\n",
        "from finbert.finbert_profile import *\n",
        "from finbert.profile_utils import get_model_size_mb, print_device_info, setup_nltk_data, timed_eval\n",
        "import finbert.utils as tools\n",
        "\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "project_dir = Path.cwd().parent\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msi2449\u001b[0m (\u001b[33msi2449-columbia-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/si2449/hpml-project/pipelines/finBERT/notebooks/wandb/run-20251220_013543-mytixq6n</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/mytixq6n' target=\"_blank\">training-lora-profiled</a></strong> to <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/mytixq6n' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/mytixq6n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/mytixq6n?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f06ad4c4f10>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(\n",
        "    entity=\"si2449-columbia-university\",\n",
        "    project=\"finbert-experiments\",\n",
        "    name=\"training-lora-profiled\",\n",
        "    group=\"lora\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "cl_path = project_dir/'models'/'teacher_lora'\n",
        "cl_data_path = project_dir/'data'/'sentiment_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    shutil.rmtree(cl_path) \n",
        "except:\n",
        "    pass\n",
        "\n",
        "bertmodel = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', cache_dir=None, num_labels=3)\n",
        "\n",
        "config = Config(\n",
        "    data_dir=cl_data_path,\n",
        "    bert_model=bertmodel,\n",
        "\n",
        "    learning_rate=0.0009640727001180892,\n",
        "    max_seq_length=48,\n",
        "    num_train_epochs=10,\n",
        "    train_batch_size=32,\n",
        "    warm_up_proportion=0.26534125891570404,\n",
        "\n",
        "    use_lora=True,\n",
        "    lora_r=8,\n",
        "    lora_alpha=8,\n",
        "    lora_dropout=0.02385391306485725,\n",
        "    lora_target_modules=[\"query\", \"value\", \"dense\"],\n",
        "\n",
        "    model_dir=cl_path,\n",
        "    output_mode=\"classification\",\n",
        "    local_rank=-1,\n",
        "\n",
        "    # Keep these off for LoRA\n",
        "    discriminate=False,\n",
        "    gradual_unfreeze=False,\n",
        ")\n",
        "\n",
        "config.profile_train_steps = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "finbert = ProfiledFinBert(config)\n",
        "finbert.base_model = 'bert-base-uncased'\n",
        "finbert.config.discriminate=True\n",
        "finbert.config.gradual_unfreeze=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/20/2025 01:35:46 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n"
          ]
        }
      ],
      "source": [
        "finbert.prepare_model(label_list=['positive','negative','neutral'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = finbert.get_data('train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,194,243 || all params: 110,678,790 || trainable%: 1.0790\n"
          ]
        }
      ],
      "source": [
        "model = finbert.create_the_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/20/2025 01:35:48 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 01:35:48 - INFO - finbert.utils -   guid: train-1\n",
            "12/20/2025 01:35:48 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/20/2025 01:35:48 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:35:48 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:35:48 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:35:48 - INFO - finbert.utils -   label: positive (id = 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/20/2025 01:35:49 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 01:35:49 - INFO - finbert.finbert -     Num examples = 3488\n",
            "12/20/2025 01:35:49 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 01:35:49 - INFO - finbert.finbert -     Num steps = 120\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Starting Profiled Training\n",
            "Device: cuda\n",
            "Profiling activities: [<ProfilerActivity.CPU: 0>, <ProfilerActivity.CUDA: 2>]\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration:  17%|█▋        | 19/109 [00:04<00:21,  4.19it/s]\n",
            "Epoch:   0%|          | 0/10 [00:04<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Profiling complete for first epoch (20 steps)\n",
            "Continuing full training without profiling...\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "PROFILING RESULTS - Training\n",
            "================================================================================\n",
            "\n",
            "\n",
            "By CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                  cudaStreamSynchronize        31.87%        1.737s        31.87%        1.737s      10.858ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           160  \n",
            "                                          backward_pass        21.21%        1.156s        21.87%        1.192s      59.622ms       0.000us         0.00%      49.177us       2.459us     -13.28 KB     -13.28 KB     -22.12 GB     -22.12 GB            20  \n",
            "                                           forward_pass         5.47%     297.994ms        20.84%        1.136s      56.804ms       0.000us         0.00%        1.821s      91.046ms      13.28 KB       9.45 KB      22.22 GB     -36.39 GB            20  \n",
            "                                             aten::item         0.17%       9.282ms        16.85%     918.648ms     183.656us       0.000us         0.00%      66.714us       0.013us           0 B           0 B           0 B           0 B          5002  \n",
            "                              aten::_local_scalar_dense         0.11%       5.774ms        16.68%     909.366ms     181.800us      66.714us         0.00%      66.714us       0.013us           0 B           0 B           0 B           0 B          5002  \n",
            "                                       loss_calculation         0.29%      15.661ms        16.00%     872.091ms      43.605ms       0.000us         0.00%     175.931us       8.797us           0 B           0 B      21.00 KB     -19.00 KB            20  \n",
            "                                               aten::to         0.10%       5.481ms        15.64%     852.562ms     146.892us       0.000us         0.00%     458.747us       0.079us           0 B           0 B       7.76 MB           0 B          5804  \n",
            "                                            aten::copy_         0.08%       4.510ms        15.59%     849.873ms       1.932ms       1.423ms         0.04%       1.460ms       3.319us           0 B           0 B           0 B           0 B           440  \n",
            "                                         aten::_to_copy         0.02%       1.282ms        15.54%     847.081ms       5.294ms       0.000us         0.00%     458.747us       2.867us           0 B           0 B       7.76 MB           0 B           160  \n",
            "                                       cudaLaunchKernel         4.92%     268.215ms        10.17%     554.204ms      19.399us       0.000us         0.00%       4.297ms       0.150us           0 B           0 B           0 B           0 B         28568  \n",
            "                                               aten::mm         4.56%     248.377ms         7.25%     395.128ms      45.313us        1.494s        39.09%        1.494s     171.346us           0 B           0 B      26.18 GB      26.18 GB          8720  \n",
            "                                           aten::linear         0.50%      27.250ms         7.12%     388.283ms      99.052us       0.000us         0.00%        1.356s     346.021us           0 B           0 B      18.03 GB           0 B          3920  \n",
            "                                         optimizer_step         1.24%      67.604ms         6.03%     328.617ms      16.431ms       0.000us         0.00%      14.167ms     708.331us         496 B           0 B     -82.01 MB      -1.27 MB            20  \n",
            "       autograd::engine::evaluate_function: MmBackward0         0.67%      36.403ms         5.88%     320.580ms     131.385us       0.000us         0.00%     250.424ms     102.633us           0 B           0 B      -8.60 GB     -17.00 GB          2440  \n",
            "                       Runtime Triggered Module Loading         5.63%     306.923ms         5.63%     306.923ms       4.514ms       5.395ms         0.14%       5.395ms      79.337us           0 B           0 B           0 B           0 B            68  \n",
            "                                            MmBackward0         0.53%      29.069ms         5.21%     284.177ms     116.466us       0.000us         0.00%     250.424ms     102.633us           0 B           0 B       8.41 GB           0 B          2440  \n",
            "                                           aten::matmul         0.42%      23.008ms         3.28%     178.775ms      73.269us       0.000us         0.00%     145.386ms      59.584us           0 B           0 B       8.53 GB           0 B          2440  \n",
            "                              Optimizer.step#AdamW.step         0.93%      50.935ms         3.12%     169.876ms       8.494ms       0.000us         0.00%      11.897ms     594.858us         496 B        -160 B       9.11 MB     -91.12 MB            20  \n",
            "                                                aten::t         1.01%      54.986ms         2.46%     133.857ms       8.853us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B         15120  \n",
            "     autograd::engine::evaluate_function: ViewBackward0         0.83%      45.272ms         2.37%     129.113ms      21.236us       0.000us         0.00%     123.889ms      20.377us           0 B           0 B      -9.23 GB      -9.23 GB          6080  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 5.452s\n",
            "Self CUDA time total: 3.821s\n",
            "\n",
            "\n",
            "By CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us        1.962s        51.35%        1.962s      98.093ms           0 B           0 B           0 B           0 B            20  \n",
            "                                           forward_pass         5.47%     297.994ms        20.84%        1.136s      56.804ms       0.000us         0.00%        1.821s      91.046ms      13.28 KB       9.45 KB      22.22 GB     -36.39 GB            20  \n",
            "                                               aten::mm         4.56%     248.377ms         7.25%     395.128ms      45.313us        1.494s        39.09%        1.494s     171.346us           0 B           0 B      26.18 GB      26.18 GB          8720  \n",
            "                                           aten::linear         0.50%      27.250ms         7.12%     388.283ms      99.052us       0.000us         0.00%        1.356s     346.021us           0 B           0 B      18.03 GB           0 B          3920  \n",
            "                                            aten::addmm         1.40%      76.398ms         2.19%     119.578ms      80.796us        1.207s        31.60%        1.211s     818.256us           0 B           0 B       9.50 GB       9.50 GB          1480  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.24%      13.262ms         2.17%     118.272ms      83.290us       0.000us         0.00%        1.099s     773.623us           0 B           0 B       1.18 MB      -9.24 GB          1420  \n",
            "                                         AddmmBackward0         0.20%      10.833ms         1.70%      92.748ms      65.315us       0.000us         0.00%        1.098s     773.471us           0 B           0 B       9.24 GB           0 B          1420  \n",
            "                                  volta_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us        1.096s        28.67%        1.096s     793.885us           0 B           0 B           0 B           0 B          1380  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     816.078ms        21.36%     816.078ms     566.721us           0 B           0 B           0 B           0 B          1440  \n",
            "                                 volta_sgemm_128x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     435.710ms        11.40%     435.710ms     363.092us           0 B           0 B           0 B           0 B          1200  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     308.891ms         8.08%     308.891ms      81.287us           0 B           0 B           0 B           0 B          3800  \n",
            "       autograd::engine::evaluate_function: MmBackward0         0.67%      36.403ms         5.88%     320.580ms     131.385us       0.000us         0.00%     250.424ms     102.633us           0 B           0 B      -8.60 GB     -17.00 GB          2440  \n",
            "                                            MmBackward0         0.53%      29.069ms         5.21%     284.177ms     116.466us       0.000us         0.00%     250.424ms     102.633us           0 B           0 B       8.41 GB           0 B          2440  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.11%       6.132ms         1.26%      68.718ms     286.323us       0.000us         0.00%     209.233ms     871.803us      -3.75 KB      -3.75 KB      -2.25 GB      -5.34 GB           240  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.06%       3.063ms         1.15%      62.585ms     260.773us       0.000us         0.00%     209.233ms     871.803us           0 B           0 B       3.08 GB     -90.00 MB           240  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.10%       5.670ms         1.09%      59.523ms     248.012us       0.000us         0.00%     209.233ms     871.803us           0 B           0 B       3.17 GB           0 B           240  \n",
            "                    aten::_efficient_attention_backward         0.17%       9.342ms         0.83%      45.060ms     187.750us     183.274ms         4.80%     209.233ms     871.803us           0 B           0 B       3.17 GB      -2.50 GB           240  \n",
            "fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm75(PyT...         0.00%       0.000us         0.00%       0.000us       0.000us     183.274ms         4.80%     183.274ms     763.643us           0 B           0 B           0 B           0 B           240  \n",
            "                                              aten::mul         0.94%      51.067ms         1.58%      86.266ms      31.950us     166.549ms         4.36%     166.671ms      61.730us           0 B           0 B      17.95 GB      17.95 GB          2700  \n",
            "                                             aten::add_         0.48%      25.986ms         0.79%      42.887ms       9.364us     165.534ms         4.33%     165.582ms      36.153us           0 B           0 B           0 B           0 B          4580  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 5.452s\n",
            "Self CUDA time total: 3.821s\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "⚠ Failed to log profiler table: 'FunctionEventAvg' object has no attribute 'cuda_time_total'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.76it/s]\n",
            "12/20/2025 01:37:13 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 01:37:13 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 01:37:13 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 01:37:13 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:37:13 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:37:13 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:37:13 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 01:37:14 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 01:37:14 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 01:37:14 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 01:37:14 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 10.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.5871844796034006]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.76it/s]\n",
            "12/20/2025 01:37:38 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 01:37:38 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 01:37:38 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 01:37:38 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:37:38 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:37:38 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:37:38 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 01:37:38 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 01:37:38 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 01:37:38 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 01:37:38 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.5871844796034006, 0.3599228916259912]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.86it/s]\n",
            "12/20/2025 01:38:03 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 01:38:03 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 01:38:03 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 01:38:03 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:38:03 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:38:03 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:38:03 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 01:38:03 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 01:38:03 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 01:38:03 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 01:38:03 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.23it/s]\n",
            "Epoch:  30%|███       | 3/10 [01:13<02:50, 24.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.5871844796034006, 0.3599228916259912, 0.36749536257523757]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.85it/s]\n",
            "12/20/2025 01:38:26 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 01:38:26 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 01:38:26 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 01:38:26 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:38:26 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:38:26 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:38:26 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 01:38:27 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 01:38:27 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 01:38:27 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 01:38:27 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.15it/s]\n",
            "Epoch:  40%|████      | 4/10 [01:37<02:24, 24.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.5871844796034006, 0.3599228916259912, 0.36749536257523757, 0.3841015799687459]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.81it/s]\n",
            "12/20/2025 01:38:50 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 01:38:50 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 01:38:50 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 01:38:50 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:38:50 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:38:50 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:38:50 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 01:38:50 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 01:38:50 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 01:38:50 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 01:38:50 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.08it/s]\n",
            "Epoch:  50%|█████     | 5/10 [02:01<02:00, 24.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.5871844796034006, 0.3599228916259912, 0.36749536257523757, 0.3841015799687459, 0.43091932282998013]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.81it/s]\n",
            "12/20/2025 01:39:14 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 01:39:14 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 01:39:14 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 01:39:14 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:39:14 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:39:14 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:39:14 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 01:39:14 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 01:39:14 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 01:39:14 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 01:39:14 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.14it/s]\n",
            "Epoch:  60%|██████    | 6/10 [02:25<01:36, 24.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.5871844796034006, 0.3599228916259912, 0.36749536257523757, 0.3841015799687459, 0.43091932282998013, 0.583551031895555]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.82it/s]\n",
            "12/20/2025 01:39:38 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 01:39:38 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 01:39:38 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 01:39:38 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:39:38 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:39:38 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:39:38 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 01:39:38 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 01:39:38 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 01:39:38 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 01:39:38 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.17it/s]\n",
            "Epoch:  70%|███████   | 7/10 [02:48<01:11, 23.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.5871844796034006, 0.3599228916259912, 0.36749536257523757, 0.3841015799687459, 0.43091932282998013, 0.583551031895555, 0.6456741197751119]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.82it/s]\n",
            "12/20/2025 01:40:02 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 01:40:02 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 01:40:02 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 01:40:02 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:40:02 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:40:02 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:40:02 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 01:40:02 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 01:40:02 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 01:40:02 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 01:40:02 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.07it/s]\n",
            "Epoch:  80%|████████  | 8/10 [03:12<00:47, 23.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.5871844796034006, 0.3599228916259912, 0.36749536257523757, 0.3841015799687459, 0.43091932282998013, 0.583551031895555, 0.6456741197751119, 0.6280336895814309]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.82it/s]\n",
            "12/20/2025 01:40:26 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 01:40:26 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 01:40:26 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 01:40:26 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:40:26 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:40:26 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:40:26 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 01:40:26 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 01:40:26 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 01:40:26 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 01:40:26 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.13it/s]\n",
            "Epoch:  90%|█████████ | 9/10 [03:36<00:23, 23.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.5871844796034006, 0.3599228916259912, 0.36749536257523757, 0.3841015799687459, 0.43091932282998013, 0.583551031895555, 0.6456741197751119, 0.6280336895814309, 0.706452316389634]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:22<00:00,  4.82it/s]\n",
            "12/20/2025 01:40:50 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 01:40:50 - INFO - finbert.utils -   guid: validation-1\n",
            "12/20/2025 01:40:50 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/20/2025 01:40:50 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:40:50 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:40:50 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:40:50 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/20/2025 01:40:50 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 01:40:50 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/20/2025 01:40:50 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 01:40:50 - INFO - finbert.finbert -     Num steps = 120\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00, 11.11it/s]\n",
            "Epoch: 100%|██████████| 10/10 [04:00<00:00, 24.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.5871844796034006, 0.3599228916259912, 0.36749536257523757, 0.3841015799687459, 0.43091932282998013, 0.583551031895555, 0.6456741197751119, 0.6280336895814309, 0.706452316389634, 0.7327835789093604]\n"
          ]
        }
      ],
      "source": [
        "start = time.perf_counter()\n",
        "trained_model = finbert.train(train_examples = train_data, model = model)\n",
        "train_wall_s = time.perf_counter() - start\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/20/2025 01:40:52 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 01:40:52 - INFO - finbert.utils -   guid: test-1\n",
            "12/20/2025 01:40:52 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/20/2025 01:40:52 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:40:52 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:40:52 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:40:52 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/20/2025 01:40:53 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 01:40:53 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/20/2025 01:40:53 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 01:40:53 - INFO - finbert.finbert -     Num steps = 300\n",
            "12/20/2025 01:40:53 - INFO - finbert.finbert -   ***** Running evaluation ***** \n",
            "12/20/2025 01:40:53 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/20/2025 01:40:53 - INFO - finbert.finbert -     Batch size = 32\n",
            "Testing:   0%|          | 0/31 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing: 100%|██████████| 31/31 [00:02<00:00, 10.73it/s]\n",
            "12/20/2025 01:40:56 - INFO - finbert.utils -   *** Example ***\n",
            "12/20/2025 01:40:56 - INFO - finbert.utils -   guid: test-1\n",
            "12/20/2025 01:40:56 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/20/2025 01:40:56 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:40:56 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:40:56 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/20/2025 01:40:56 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/20/2025 01:40:56 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/20/2025 01:40:56 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/20/2025 01:40:56 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/20/2025 01:40:56 - INFO - finbert.finbert -     Num steps = 300\n"
          ]
        }
      ],
      "source": [
        "test_data = finbert.get_data(\"test\")\n",
        "\n",
        "results = finbert.evaluate(examples=test_data, model=trained_model)\n",
        "\n",
        "\n",
        "eval_df, eval_timing = timed_eval(\n",
        "    finbert=finbert, model=trained_model, examples=test_data, use_amp=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def report(df, cols=['label','prediction','logits']):\n",
        "    #print('Validation loss:{0:.2f}'.format(metrics['best_validation_loss']))\n",
        "    cs = CrossEntropyLoss(weight=finbert.class_weights)\n",
        "    loss = cs(torch.tensor(list(df[cols[2]])),torch.tensor(list(df[cols[0]])))\n",
        "    print(\"Evaluation Loss:{0:.2f}\".format(loss))\n",
        "    print(\"Evaluation Accuracy:{0:.2f}\".format((df[cols[0]] == df[cols[1]]).sum() / df.shape[0]) )\n",
        "    print(\"\\nClassification Report:\")\n",
        "    return_val = classification_report(df[cols[0]], df[cols[1]], output_dict=True)\n",
        "    print(return_val)\n",
        "    return_val[\"Evalaution Loss\"] = loss\n",
        "    return_val[\"Evaluation Accuracy\"] = (df[cols[0]] == df[cols[1]]).sum() / df.shape[0]\n",
        "    return return_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "results['prediction'] = results.predictions.apply(lambda x: np.argmax(x,axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/tmp/ipykernel_373266/1446198405.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  loss = cs(torch.tensor(list(df[cols[2]])),torch.tensor(list(df[cols[0]])))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Loss:0.40\n",
            "Evaluation Accuracy:0.80\n",
            "\n",
            "Classification Report:\n",
            "{'0': {'precision': 0.698051948051948, 'recall': 0.8052434456928839, 'f1-score': 0.7478260869565218, 'support': 267.0}, '1': {'precision': 0.6666666666666666, 'recall': 0.921875, 'f1-score': 0.7737704918032787, 'support': 128.0}, '2': {'precision': 0.9092783505154639, 'recall': 0.7669565217391304, 'f1-score': 0.8320754716981132, 'support': 575.0}, 'accuracy': 0.797938144329897, 'macro avg': {'precision': 0.7579989884113595, 'recall': 0.8313583224773381, 'f1-score': 0.784557350152638, 'support': 970.0}, 'weighted avg': {'precision': 0.8191219123810258, 'recall': 0.797938144329897, 'f1-score': 0.8011913241181712, 'support': 970.0}}\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Evalaution Loss</td><td>▁</td></tr><tr><td>Evaluation Accuracy</td><td>▁</td></tr><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇██</td></tr><tr><td>eval_num_samples</td><td>▁</td></tr><tr><td>eval_samples_per_s</td><td>▁</td></tr><tr><td>eval_wall_s</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁▂▃▃▃▄▄▅▆▆▇▇███▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▁▁</td></tr><tr><td>model_size_mb</td><td>▁</td></tr><tr><td>profile_train_steps</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Evalaution Loss</td><td>0.40373</td></tr><tr><td>Evaluation Accuracy</td><td>0.79794</td></tr><tr><td>accuracy</td><td>0.79794</td></tr><tr><td>device</td><td>cuda</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>eval_num_samples</td><td>970</td></tr><tr><td>eval_samples_per_s</td><td>336.09796</td></tr><tr><td>eval_wall_s</td><td>2.88606</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>model_dir</td><td>/home/si2449/hpml-pr...</td></tr><tr><td>+13</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">training-lora-profiled</strong> at: <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/mytixq6n' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/mytixq6n</a><br> View project at: <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251220_013543-mytixq6n/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb_report = report(results,cols=['labels','prediction','predictions'])\n",
        "\n",
        "summary = {\n",
        "        \"device\": str(finbert.device),\n",
        "        \"model_dir\": str(cl_path),\n",
        "        \"train_wall_s\": float(train_wall_s),\n",
        "        \"train_examples\": int(len(train_data)),\n",
        "        \"train_examples_per_s\": float((len(train_data) * finbert.config.num_train_epochs) / train_wall_s)\n",
        "        if train_wall_s > 0\n",
        "        else float(\"inf\"),\n",
        "        \"model_size_mb\": float(get_model_size_mb(trained_model)),\n",
        "        \"profile_train_steps\": finbert.config.profile_train_steps,\n",
        "        **(finbert.profile_results.get(\"training_summary\", {}) or {}),\n",
        "        **eval_timing,\n",
        "        **wandb_report,\n",
        "    }\n",
        "\n",
        "wandb.log(summary)\n",
        "wandb.finish()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
