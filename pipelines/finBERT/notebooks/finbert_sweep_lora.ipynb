{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FinBERT LoRA Hyperparameter Sweep\n",
        "\n",
        "This notebook extends the standard FinBERT sweep to tune **LoRA-specific** hyperparameters:\n",
        "- LoRA rank (`lora_r`)\n",
        "- LoRA alpha (`lora_alpha`) \n",
        "- LoRA dropout (`lora_dropout`)\n",
        "- Target modules for LoRA adaptation\n",
        "- Higher learning rates suitable for LoRA training\n",
        "\n",
        "## Key Differences from Standard Sweep\n",
        "- `discriminate=False` and `gradual_unfreeze=False` are fixed (incompatible with LoRA)\n",
        "- Learning rate range is higher (1e-4 to 1e-3 vs 1e-5 to 5e-5)\n",
        "- Additional LoRA-specific hyperparameters in sweep space\n",
        "\n",
        "## Prerequisites\n",
        "```bash\n",
        "pip install wandb peft\n",
        "wandb login\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imports loaded successfully\n",
            "Project directory: /home/si2449/hpml-project/pipelines/finBERT\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "import os\n",
        "import logging\n",
        "import sys\n",
        "import numpy as np\n",
        "sys.path.append('..')\n",
        "\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "from finbert.finbert import *\n",
        "import finbert.utils as tools\n",
        "\n",
        "# Weights & Biases\n",
        "import wandb\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "project_dir = Path.cwd().parent\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
        "                    level = logging.ERROR)\n",
        "\n",
        "print(\"Imports loaded successfully\")\n",
        "print(f\"Project directory: {project_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n",
        "\n",
        "Set up paths and W&B project name.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model path: /home/si2449/hpml-project/pipelines/finBERT/models/sentiment_lora\n",
            "Data path: /home/si2449/hpml-project/pipelines/finBERT/data/sentiment_data\n",
            "W&B Project: finbert-lora-hyperparameter-sweep\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "cl_path = project_dir/'models'/'sentiment_lora'\n",
        "cl_data_path = project_dir/'data'/'sentiment_data'\n",
        "\n",
        "# W&B Configuration\n",
        "WANDB_PROJECT = \"Project-Runs\"\n",
        "WANDB_ENTITY = None  # Set your W&B entity/username if needed\n",
        "\n",
        "print(f\"Model path: {cl_path}\")\n",
        "print(f\"Data path: {cl_data_path}\")\n",
        "print(f\"W&B Project: {WANDB_PROJECT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Define LoRA Sweep Configuration\n",
        "\n",
        "This defines the hyperparameter search space specifically for LoRA fine-tuning.\n",
        "\n",
        "### Key LoRA Parameters:\n",
        "- **lora_r**: Rank of the low-rank matrices. Higher = more parameters, more capacity\n",
        "- **lora_alpha**: Scaling factor. Often set to 2*r or equal to r\n",
        "- **lora_dropout**: Dropout applied to LoRA layers\n",
        "- **lora_target_modules**: Which attention matrices to apply LoRA to\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LoRA Sweep configuration created\n",
            "  Method: bayes\n",
            "  Optimization metric: val_loss\n",
            "  LoRA parameters being tuned:\n",
            "    - lora_r: [4, 8, 16, 32]\n",
            "    - lora_alpha: [8, 16, 32, 64]\n",
            "    - lora_dropout: [0.0, 0.2]\n"
          ]
        }
      ],
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes',  # 'grid', 'random', or 'bayes'\n",
        "    'metric': {\n",
        "        'name': 'val_loss',\n",
        "        'goal': 'minimize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        # LoRA-specific parameters\n",
        "        'lora_r': {\n",
        "            'values': [4, 8, 16, 32]\n",
        "        },\n",
        "        'lora_alpha': {\n",
        "            'values': [8, 16, 32, 64]\n",
        "        },\n",
        "        'lora_dropout': {\n",
        "            'distribution': 'uniform',\n",
        "            'min': 0.0,\n",
        "            'max': 0.2\n",
        "        },\n",
        "        'lora_target_modules': {\n",
        "            'values': [\n",
        "                ['query', 'value'],           # Standard: Q and V matrices\n",
        "                ['query', 'key', 'value'],    # All attention matrices\n",
        "                ['query', 'value', 'dense'],  # Q, V + output projection\n",
        "            ]\n",
        "        },\n",
        "        # Higher learning rates for LoRA (key difference from full fine-tuning)\n",
        "        'learning_rate': {\n",
        "            'distribution': 'log_uniform_values',\n",
        "            'min': 1e-4,\n",
        "            'max': 1e-3\n",
        "        },\n",
        "        # Standard training parameters\n",
        "        'num_train_epochs': {\n",
        "            'values': [5, 8, 10, 15]\n",
        "        },\n",
        "        'train_batch_size': {\n",
        "            'values': [16, 32, 64]\n",
        "        },\n",
        "        'warm_up_proportion': {\n",
        "            'distribution': 'uniform',\n",
        "            'min': 0.1,\n",
        "            'max': 0.3\n",
        "        },\n",
        "        'max_seq_length': {\n",
        "            'values': [48, 64, 96]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"LoRA Sweep configuration created\")\n",
        "print(f\"  Method: {sweep_config['method']}\")\n",
        "print(f\"  Optimization metric: {sweep_config['metric']['name']}\")\n",
        "print(f\"  LoRA parameters being tuned:\")\n",
        "print(f\"    - lora_r: {sweep_config['parameters']['lora_r']['values']}\")\n",
        "print(f\"    - lora_alpha: {sweep_config['parameters']['lora_alpha']['values']}\")\n",
        "print(f\"    - lora_dropout: [{sweep_config['parameters']['lora_dropout']['min']}, {sweep_config['parameters']['lora_dropout']['max']}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training Function with LoRA and W&B Integration\n",
        "\n",
        "This wraps the LoRA-enabled training code with W&B logging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Main training function defined\n"
          ]
        }
      ],
      "source": [
        "def train_with_lora_config(config=None):\n",
        "    \"\"\"\n",
        "    Training function that W&B will call with different LoRA hyperparameters.\n",
        "    \"\"\"\n",
        "    # Initialize W&B run\n",
        "    with wandb.init(config=config):\n",
        "        # Get hyperparameters from W&B\n",
        "        config = wandb.config\n",
        "        \n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Starting LoRA training run with config:\")\n",
        "        print(f\"  LoRA r: {config.lora_r}\")\n",
        "        print(f\"  LoRA alpha: {config.lora_alpha}\")\n",
        "        print(f\"  LoRA dropout: {config.lora_dropout:.4f}\")\n",
        "        print(f\"  LoRA target modules: {config.lora_target_modules}\")\n",
        "        print(f\"  Learning rate: {config.learning_rate:.6f}\")\n",
        "        print(f\"  Epochs: {config.num_train_epochs}\")\n",
        "        print(f\"  Batch size: {config.train_batch_size}\")\n",
        "        print(f\"  Warmup: {config.warm_up_proportion:.4f}\")\n",
        "        print(f\"  Max seq length: {config.max_seq_length}\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "        \n",
        "        # Clean previous model directory\n",
        "        model_path = project_dir / 'models' / 'lora_sweep' / f'sweep_{wandb.run.id}'\n",
        "        try:\n",
        "            shutil.rmtree(model_path)\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        # Create BERT model\n",
        "        bertmodel = AutoModelForSequenceClassification.from_pretrained(\n",
        "            'bert-base-uncased', cache_dir=None, num_labels=3\n",
        "        )\n",
        "        \n",
        "        # Create FinBERT config with LoRA hyperparameters from sweep\n",
        "        finbert_config = Config(\n",
        "            data_dir=cl_data_path,\n",
        "            bert_model=bertmodel,\n",
        "            num_train_epochs=config.num_train_epochs,\n",
        "            model_dir=model_path,\n",
        "            max_seq_length=config.max_seq_length,\n",
        "            train_batch_size=config.train_batch_size,\n",
        "            learning_rate=config.learning_rate,\n",
        "            output_mode='classification',\n",
        "            warm_up_proportion=config.warm_up_proportion,\n",
        "            local_rank=-1,\n",
        "            # LoRA settings\n",
        "            use_lora=True,\n",
        "            lora_r=config.lora_r,\n",
        "            lora_alpha=config.lora_alpha,\n",
        "            lora_dropout=config.lora_dropout,\n",
        "            lora_target_modules=tuple(config.lora_target_modules),\n",
        "            # These must be OFF for LoRA\n",
        "            discriminate=False,\n",
        "            gradual_unfreeze=False\n",
        "        )\n",
        "        \n",
        "        # Initialize FinBERT\n",
        "        finbert = FinBert(finbert_config)\n",
        "        finbert.base_model = 'bert-base-uncased'\n",
        "        finbert.prepare_model(label_list=['positive', 'negative', 'neutral'])\n",
        "        \n",
        "        # Load data\n",
        "        train_data = finbert.get_data('train')\n",
        "        test_data = finbert.get_data('test')\n",
        "        \n",
        "        # Create model with LoRA\n",
        "        model = finbert.create_the_model()\n",
        "        \n",
        "        # Log trainable parameters info\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        wandb.log({\n",
        "            'total_params': total_params,\n",
        "            'trainable_params': trainable_params,\n",
        "            'trainable_percent': 100 * trainable_params / total_params\n",
        "        })\n",
        "        \n",
        "        # Train with W&B logging\n",
        "        trained_model = train_lora_with_wandb_logging(\n",
        "            finbert, train_data, model, test_data\n",
        "        )\n",
        "        \n",
        "        # Final evaluation\n",
        "        results = finbert.evaluate(examples=test_data, model=trained_model)\n",
        "        results['prediction'] = results.predictions.apply(lambda x: np.argmax(x, axis=0))\n",
        "        \n",
        "        # Calculate metrics\n",
        "        metrics = calculate_metrics(results, finbert)\n",
        "        \n",
        "        # Log final metrics to W&B\n",
        "        wandb.log({\n",
        "            'final_test_loss': metrics['loss'],\n",
        "            'final_test_accuracy': metrics['accuracy'],\n",
        "            'final_f1_positive': metrics['f1_positive'],\n",
        "            'final_f1_negative': metrics['f1_negative'],\n",
        "            'final_f1_neutral': metrics['f1_neutral'],\n",
        "            'final_f1_macro': metrics['f1_macro']\n",
        "        })\n",
        "        \n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Final Results:\")\n",
        "        print(f\"  Test Loss: {metrics['loss']:.4f}\")\n",
        "        print(f\"  Test Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"  Macro F1: {metrics['f1_macro']:.4f}\")\n",
        "        print(f\"  Trainable params: {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "\n",
        "print(\"Main training function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions defined\n"
          ]
        }
      ],
      "source": [
        "def train_lora_with_wandb_logging(finbert, train_data, model, test_data):\n",
        "    \"\"\"\n",
        "    Modified training loop with W&B logging for LoRA models.\n",
        "    Note: gradual_unfreeze is disabled for LoRA training.\n",
        "    \"\"\"\n",
        "    validation_examples = finbert.get_data('validation')\n",
        "    global_step = 0\n",
        "    finbert.validation_losses = []\n",
        "    \n",
        "    train_dataloader = finbert.get_loader(train_data, 'train') \n",
        "    model.train()\n",
        "    step_number = len(train_dataloader)\n",
        "    \n",
        "    best_val_loss = float('inf')\n",
        "    best_model_epoch = 0\n",
        "    \n",
        "    for epoch in trange(int(finbert.config.num_train_epochs), desc=\"Epoch\"):\n",
        "        model.train()\n",
        "        tr_loss = 0\n",
        "        nb_tr_examples, nb_tr_steps = 0, 0\n",
        "        \n",
        "        for step, batch in enumerate(tqdm(train_dataloader, desc='Iteration')):\n",
        "            batch = tuple(t.to(finbert.device) for t in batch)\n",
        "            input_ids, attention_mask, token_type_ids, label_ids, agree_ids = batch\n",
        "            \n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids\n",
        "            )\n",
        "            logits = outputs.logits\n",
        "            weights = finbert.class_weights.to(finbert.device)\n",
        "            \n",
        "            if finbert.config.output_mode == \"classification\":\n",
        "                loss_fct = CrossEntropyLoss(weight=weights)\n",
        "                loss = loss_fct(logits.view(-1, finbert.num_labels), label_ids.view(-1))\n",
        "            elif finbert.config.output_mode == \"regression\":\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
        "            \n",
        "            if finbert.config.gradient_accumulation_steps > 1:\n",
        "                loss = loss / finbert.config.gradient_accumulation_steps\n",
        "            else:\n",
        "                loss.backward()\n",
        "            \n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_examples += input_ids.size(0)\n",
        "            nb_tr_steps += 1\n",
        "            \n",
        "            if (step + 1) % finbert.config.gradient_accumulation_steps == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(\n",
        "                    (p for p in model.parameters() if p.requires_grad), 1.0\n",
        "                )\n",
        "                finbert.optimizer.step()\n",
        "                finbert.scheduler.step()\n",
        "                finbert.optimizer.zero_grad()\n",
        "                global_step += 1\n",
        "                \n",
        "                # Log to W&B every N steps\n",
        "                if global_step % 10 == 0:\n",
        "                    wandb.log({\n",
        "                        'train_loss': tr_loss / nb_tr_steps,\n",
        "                        'learning_rate': finbert.optimizer.param_groups[0]['lr'],\n",
        "                        'epoch': epoch,\n",
        "                        'step': global_step\n",
        "                    })\n",
        "        \n",
        "        # Validation at end of epoch\n",
        "        validation_loader = finbert.get_loader(validation_examples, 'eval')\n",
        "        model.eval()\n",
        "        \n",
        "        valid_loss, valid_accuracy = 0, 0\n",
        "        nb_valid_steps, nb_valid_examples = 0, 0\n",
        "        \n",
        "        for input_ids, attention_mask, token_type_ids, label_ids, agree_ids in tqdm(validation_loader, desc=\"Validating\"):\n",
        "            input_ids = input_ids.to(finbert.device)\n",
        "            attention_mask = attention_mask.to(finbert.device)\n",
        "            token_type_ids = token_type_ids.to(finbert.device)\n",
        "            label_ids = label_ids.to(finbert.device)\n",
        "            agree_ids = agree_ids.to(finbert.device)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                outputs = model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    token_type_ids=token_type_ids\n",
        "                )\n",
        "                logits = outputs.logits\n",
        "                \n",
        "                if finbert.config.output_mode == \"classification\":\n",
        "                    loss_fct = CrossEntropyLoss(weight=weights)\n",
        "                    tmp_valid_loss = loss_fct(logits.view(-1, finbert.num_labels), label_ids.view(-1))\n",
        "                elif finbert.config.output_mode == \"regression\":\n",
        "                    loss_fct = MSELoss()\n",
        "                    tmp_valid_loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
        "                \n",
        "                valid_loss += tmp_valid_loss.mean().item()\n",
        "                nb_valid_steps += 1\n",
        "        \n",
        "        valid_loss = valid_loss / nb_valid_steps\n",
        "        finbert.validation_losses.append(valid_loss)\n",
        "        \n",
        "        # Log validation metrics to W&B\n",
        "        wandb.log({\n",
        "            'val_loss': valid_loss,\n",
        "            'epoch': epoch,\n",
        "            'best_val_loss': min(finbert.validation_losses)\n",
        "        })\n",
        "        \n",
        "        print(f\"Epoch {epoch}: Validation loss = {valid_loss:.4f}\")\n",
        "        \n",
        "        # Save best model\n",
        "        if valid_loss == min(finbert.validation_losses):\n",
        "            try:\n",
        "                os.remove(finbert.config.model_dir / ('temporary' + str(best_model_epoch)))\n",
        "            except:\n",
        "                pass\n",
        "            torch.save({'epoch': str(epoch), 'state_dict': model.state_dict()},\n",
        "                       finbert.config.model_dir / ('temporary' + str(epoch)))\n",
        "            best_model_epoch = epoch\n",
        "            best_val_loss = valid_loss\n",
        "    \n",
        "    # Load best model\n",
        "    checkpoint = torch.load(finbert.config.model_dir / ('temporary' + str(best_model_epoch)))\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    \n",
        "    # Save final model\n",
        "    model_to_save = model.module if hasattr(model, 'module') else model\n",
        "    output_model_file = os.path.join(finbert.config.model_dir, 'pytorch_model.bin')\n",
        "    torch.save(model_to_save.state_dict(), output_model_file)\n",
        "    \n",
        "    # Clean up temporary files\n",
        "    try:\n",
        "        os.remove(finbert.config.model_dir / ('temporary' + str(best_model_epoch)))\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def calculate_metrics(results, finbert):\n",
        "    \"\"\"\n",
        "    Calculate comprehensive metrics for evaluation.\n",
        "    \"\"\"\n",
        "    cs = CrossEntropyLoss(weight=finbert.class_weights)\n",
        "    loss = cs(\n",
        "        torch.tensor(list(results['predictions'])),\n",
        "        torch.tensor(list(results['labels']))\n",
        "    )\n",
        "    \n",
        "    accuracy = (results['labels'] == results['prediction']).sum() / results.shape[0]\n",
        "    \n",
        "    # Calculate per-class F1 scores\n",
        "    f1_scores = f1_score(results['labels'], results['prediction'], average=None)\n",
        "    f1_macro = f1_score(results['labels'], results['prediction'], average='macro')\n",
        "    \n",
        "    return {\n",
        "        'loss': loss.item(),\n",
        "        'accuracy': accuracy,\n",
        "        'f1_positive': f1_scores[0],\n",
        "        'f1_negative': f1_scores[1],\n",
        "        'f1_neutral': f1_scores[2],\n",
        "        'f1_macro': f1_macro\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"Helper functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Initialize and Run LoRA Sweep\n",
        "\n",
        "This will start the hyperparameter sweep. W&B will automatically try different LoRA configurations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: wgeew1ms\n",
            "Sweep URL: https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/sweeps/wgeew1ms\n",
            "LoRA Sweep initialized with ID: wgeew1ms\n",
            "View at: https://wandb.ai/your-username/finbert-lora-hyperparameter-sweep/sweeps/wgeew1ms\n"
          ]
        }
      ],
      "source": [
        "# Initialize the sweep\n",
        "sweep_id = wandb.sweep(\n",
        "    sweep_config, \n",
        "    project=WANDB_PROJECT,\n",
        "    entity=WANDB_ENTITY\n",
        ")\n",
        "\n",
        "print(f\"LoRA Sweep initialized with ID: {sweep_id}\")\n",
        "print(f\"View at: https://wandb.ai/{WANDB_ENTITY or 'your-username'}/{WANDB_PROJECT}/sweeps/{sweep_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wai0o21b with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009999359926900096\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.043564732222302394\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_target_modules: ['query', 'value']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_length: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \twarm_up_proportion: 0.1021149770831856\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/si2449/hpml-project/pipelines/finBERT/notebooks/wandb/run-20251217_061707-wai0o21b</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/runs/wai0o21b' target=\"_blank\">autumn-sweep-1</a></strong> to <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/sweeps/wgeew1ms' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/sweeps/wgeew1ms</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/sweeps/wgeew1ms' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/sweeps/wgeew1ms</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/runs/wai0o21b' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/runs/wai0o21b</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Starting LoRA training run with config:\n",
            "  LoRA r: 32\n",
            "  LoRA alpha: 32\n",
            "  LoRA dropout: 0.0436\n",
            "  LoRA target modules: ['query', 'value']\n",
            "  Learning rate: 0.001000\n",
            "  Epochs: 8\n",
            "  Batch size: 64\n",
            "  Warmup: 0.1021\n",
            "  Max seq length: 64\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "12/17/2025 06:17:09 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "12/17/2025 06:17:10 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:17:10 - INFO - finbert.utils -   guid: train-1\n",
            "12/17/2025 06:17:10 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/17/2025 06:17:10 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:17:10 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:17:10 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:17:10 - INFO - finbert.utils -   label: positive (id = 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,181,955 || all params: 110,666,502 || trainable%: 1.0680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 06:17:11 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:17:11 - INFO - finbert.finbert -     Num examples = 3488\n",
            "12/17/2025 06:17:11 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:17:11 - INFO - finbert.finbert -     Num steps = 48\n",
            "Iteration: 100%|██████████| 55/55 [00:24<00:00,  2.24it/s]\n",
            "12/17/2025 06:17:36 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:17:36 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:17:36 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:17:36 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:17:36 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:17:36 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:17:36 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:17:36 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:17:36 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:17:36 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:17:36 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Validation loss = 0.6346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 55/55 [00:23<00:00,  2.36it/s]\n",
            "12/17/2025 06:18:01 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:18:01 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:18:01 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:18:01 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:18:01 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:18:01 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:18:01 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:18:01 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:18:01 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:18:01 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:18:01 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Validation loss = 0.4713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 55/55 [00:22<00:00,  2.40it/s]\n",
            "12/17/2025 06:18:26 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:18:26 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:18:26 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:18:26 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:18:26 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:18:26 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:18:26 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:18:26 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:18:26 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:18:26 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:18:26 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: Validation loss = 0.4683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 55/55 [00:23<00:00,  2.36it/s]\n",
            "12/17/2025 06:18:52 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:18:52 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:18:52 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:18:52 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:18:52 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:18:52 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:18:52 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:18:52 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:18:52 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:18:52 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:18:52 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: Validation loss = 0.4683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 55/55 [00:23<00:00,  2.35it/s]\n",
            "12/17/2025 06:19:17 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:19:17 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:19:17 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:19:17 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:19:17 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:19:17 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:19:17 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:19:17 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:19:17 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:19:17 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:19:17 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: Validation loss = 0.4683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 55/55 [00:23<00:00,  2.37it/s]\n",
            "12/17/2025 06:19:43 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:19:43 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:19:43 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:19:43 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:19:43 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:19:43 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:19:43 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:19:43 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:19:43 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:19:43 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:19:43 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: Validation loss = 0.4683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 55/55 [00:23<00:00,  2.37it/s]\n",
            "12/17/2025 06:20:08 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:20:08 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:20:08 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:20:08 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:20:08 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:20:08 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:20:08 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:20:08 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:20:08 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:20:08 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:20:08 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: Validation loss = 0.4683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 55/55 [00:23<00:00,  2.37it/s]\n",
            "12/17/2025 06:20:33 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:20:33 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:20:33 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:20:33 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:20:33 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:20:33 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:20:33 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:20:33 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:20:33 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:20:33 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:20:33 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: Validation loss = 0.4683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 8/8 [03:24<00:00, 25.52s/it]\n",
            "12/17/2025 06:20:36 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:20:36 - INFO - finbert.utils -   guid: test-1\n",
            "12/17/2025 06:20:36 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/17/2025 06:20:36 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:20:36 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:20:36 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:20:36 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/17/2025 06:20:37 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:20:37 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/17/2025 06:20:37 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:20:37 - INFO - finbert.finbert -     Num steps = 48\n",
            "12/17/2025 06:20:37 - INFO - finbert.finbert -   ***** Running evaluation ***** \n",
            "12/17/2025 06:20:37 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/17/2025 06:20:37 - INFO - finbert.finbert -     Batch size = 32\n",
            "Testing: 100%|██████████| 16/16 [00:03<00:00,  5.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Final Results:\n",
            "  Test Loss: 0.3827\n",
            "  Test Accuracy: 0.8010\n",
            "  Macro F1: 0.7922\n",
            "  Trainable params: 1,181,955 (1.07%)\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/var/tmp/ipykernel_3836044/1780291689.py:147: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  torch.tensor(list(results['predictions'])),\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>█▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>final_f1_macro</td><td>▁</td></tr><tr><td>final_f1_negative</td><td>▁</td></tr><tr><td>final_f1_neutral</td><td>▁</td></tr><tr><td>final_f1_positive</td><td>▁</td></tr><tr><td>final_test_accuracy</td><td>▁</td></tr><tr><td>final_test_loss</td><td>▁</td></tr><tr><td>learning_rate</td><td>▇█▇▇▆▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>0.46833</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>final_f1_macro</td><td>0.79216</td></tr><tr><td>final_f1_negative</td><td>0.79743</td></tr><tr><td>final_f1_neutral</td><td>0.83206</td></tr><tr><td>final_f1_positive</td><td>0.74699</td></tr><tr><td>final_test_accuracy</td><td>0.80103</td></tr><tr><td>final_test_loss</td><td>0.38271</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>step</td><td>440</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">autumn-sweep-1</strong> at: <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/runs/wai0o21b' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/runs/wai0o21b</a><br> View project at: <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251217_061707-wai0o21b/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ady3g432 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00021745065577951636\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.1916646090717016\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_target_modules: ['query', 'key', 'value']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_length: 96\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \twarm_up_proportion: 0.2806742825451016\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/si2449/hpml-project/pipelines/finBERT/notebooks/wandb/run-20251217_062052-ady3g432</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/runs/ady3g432' target=\"_blank\">true-sweep-2</a></strong> to <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/sweeps/wgeew1ms' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/sweeps/wgeew1ms</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/sweeps/wgeew1ms' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/sweeps/wgeew1ms</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/runs/ady3g432' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/runs/ady3g432</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Starting LoRA training run with config:\n",
            "  LoRA r: 4\n",
            "  LoRA alpha: 64\n",
            "  LoRA dropout: 0.1917\n",
            "  LoRA target modules: ['query', 'key', 'value']\n",
            "  Learning rate: 0.000217\n",
            "  Epochs: 15\n",
            "  Batch size: 32\n",
            "  Warmup: 0.2807\n",
            "  Max seq length: 96\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "12/17/2025 06:20:53 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "12/17/2025 06:20:55 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:20:55 - INFO - finbert.utils -   guid: train-1\n",
            "12/17/2025 06:20:55 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/17/2025 06:20:55 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:20:55 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:20:55 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:20:55 - INFO - finbert.utils -   label: positive (id = 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 223,491 || all params: 109,708,038 || trainable%: 0.2037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 06:20:56 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:20:56 - INFO - finbert.finbert -     Num examples = 3488\n",
            "12/17/2025 06:20:56 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:20:56 - INFO - finbert.finbert -     Num steps = 180\n",
            "Iteration: 100%|██████████| 109/109 [00:40<00:00,  2.67it/s]\n",
            "12/17/2025 06:21:37 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:21:37 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:21:37 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:21:37 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:21:37 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:21:37 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:21:37 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:21:37 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:21:37 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:21:37 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:21:37 - INFO - finbert.finbert -     Num steps = 180\n",
            "Validating: 100%|██████████| 13/13 [00:02<00:00,  5.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Validation loss = 0.8333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:40<00:00,  2.72it/s]\n",
            "12/17/2025 06:22:20 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:22:20 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:22:20 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:22:20 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:22:20 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:22:20 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:22:20 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:22:20 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:22:20 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:22:20 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:22:20 - INFO - finbert.finbert -     Num steps = 180\n",
            "Validating: 100%|██████████| 13/13 [00:02<00:00,  6.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Validation loss = 0.5159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:40<00:00,  2.71it/s]\n",
            "12/17/2025 06:23:03 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:23:03 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:23:03 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:23:03 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:23:03 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:23:03 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:23:03 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:23:03 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:23:03 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:23:03 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:23:03 - INFO - finbert.finbert -     Num steps = 180\n",
            "Validating: 100%|██████████| 13/13 [00:02<00:00,  5.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: Validation loss = 0.4145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:40<00:00,  2.71it/s]\n",
            "12/17/2025 06:23:47 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:23:47 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:23:47 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:23:47 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:23:47 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:23:47 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:23:47 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:23:47 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:23:47 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:23:47 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:23:47 - INFO - finbert.finbert -     Num steps = 180\n",
            "Validating: 100%|██████████| 13/13 [00:02<00:00,  5.92it/s]\n",
            "Epoch:  27%|██▋       | 4/15 [02:53<07:53, 43.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: Validation loss = 0.4156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:40<00:00,  2.70it/s]\n",
            "12/17/2025 06:24:29 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:24:29 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:24:29 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:24:29 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:24:29 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:24:29 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:24:29 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:24:29 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:24:29 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:24:29 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:24:29 - INFO - finbert.finbert -     Num steps = 180\n",
            "Validating: 100%|██████████| 13/13 [00:02<00:00,  5.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: Validation loss = 0.4142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:40<00:00,  2.72it/s]\n",
            "12/17/2025 06:25:13 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:25:13 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:25:13 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:25:13 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:25:13 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:25:13 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:25:13 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:25:13 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:25:13 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:25:13 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:25:13 - INFO - finbert.finbert -     Num steps = 180\n",
            "Validating: 100%|██████████| 13/13 [00:02<00:00,  5.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: Validation loss = 0.4142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:40<00:00,  2.70it/s]\n",
            "12/17/2025 06:25:56 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:25:56 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:25:56 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:25:56 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:25:56 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:25:56 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:25:56 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:25:56 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:25:56 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:25:56 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:25:56 - INFO - finbert.finbert -     Num steps = 180\n",
            "Validating: 100%|██████████| 13/13 [00:02<00:00,  5.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: Validation loss = 0.4142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:40<00:00,  2.71it/s]\n",
            "12/17/2025 06:26:40 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:26:40 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:26:40 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:26:40 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:26:40 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:26:40 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:26:40 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:26:40 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:26:40 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:26:40 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:26:40 - INFO - finbert.finbert -     Num steps = 180\n",
            "Validating: 100%|██████████| 13/13 [00:02<00:00,  5.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: Validation loss = 0.4142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:40<00:00,  2.71it/s]\n",
            "12/17/2025 06:27:23 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:27:23 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:27:23 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:27:23 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:27:23 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:27:23 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:27:23 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:27:23 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:27:23 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:27:23 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:27:23 - INFO - finbert.finbert -     Num steps = 180\n",
            "Validating: 100%|██████████| 13/13 [00:02<00:00,  5.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: Validation loss = 0.4142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:40<00:00,  2.71it/s]\n",
            "12/17/2025 06:28:07 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:28:07 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:28:07 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:28:07 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:28:07 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:28:07 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:28:07 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:28:07 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:28:07 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:28:07 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:28:07 - INFO - finbert.finbert -     Num steps = 180\n",
            "Validating: 100%|██████████| 13/13 [00:02<00:00,  5.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: Validation loss = 0.4142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:40<00:00,  2.71it/s]\n",
            "12/17/2025 06:28:50 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:28:50 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:28:50 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:28:50 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:28:50 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:28:50 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:28:50 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:28:50 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:28:50 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:28:50 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:28:50 - INFO - finbert.finbert -     Num steps = 180\n",
            "Validating: 100%|██████████| 13/13 [00:02<00:00,  5.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: Validation loss = 0.4142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:40<00:00,  2.71it/s]\n",
            "12/17/2025 06:29:34 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:29:34 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:29:34 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:29:34 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:29:34 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:29:34 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:29:34 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:29:34 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:29:34 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:29:34 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:29:34 - INFO - finbert.finbert -     Num steps = 180\n",
            "Validating: 100%|██████████| 13/13 [00:02<00:00,  5.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Validation loss = 0.4142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:40<00:00,  2.71it/s]\n",
            "12/17/2025 06:30:17 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:30:17 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:30:17 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:30:17 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:30:17 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:30:17 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:30:17 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:30:17 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:30:17 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:30:17 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:30:17 - INFO - finbert.finbert -     Num steps = 180\n",
            "Validating: 100%|██████████| 13/13 [00:02<00:00,  5.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Validation loss = 0.4142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:40<00:00,  2.71it/s]\n",
            "12/17/2025 06:31:01 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:31:01 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:31:01 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:31:01 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:31:01 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:31:01 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:31:01 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:31:01 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:31:01 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:31:01 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:31:01 - INFO - finbert.finbert -     Num steps = 180\n",
            "Validating: 100%|██████████| 13/13 [00:02<00:00,  5.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Validation loss = 0.4142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:40<00:00,  2.71it/s]\n",
            "12/17/2025 06:31:44 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:31:44 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:31:44 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:31:44 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:31:44 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:31:44 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:31:44 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:31:44 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:31:44 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:31:44 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:31:44 - INFO - finbert.finbert -     Num steps = 180\n",
            "Validating: 100%|██████████| 13/13 [00:02<00:00,  5.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: Validation loss = 0.4142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 15/15 [10:51<00:00, 43.44s/it]\n",
            "12/17/2025 06:31:49 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:31:49 - INFO - finbert.utils -   guid: test-1\n",
            "12/17/2025 06:31:49 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/17/2025 06:31:49 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:31:49 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:31:49 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:31:49 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/17/2025 06:31:49 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:31:49 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/17/2025 06:31:49 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 06:31:49 - INFO - finbert.finbert -     Num steps = 180\n",
            "12/17/2025 06:31:49 - INFO - finbert.finbert -   ***** Running evaluation ***** \n",
            "12/17/2025 06:31:49 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/17/2025 06:31:49 - INFO - finbert.finbert -     Batch size = 32\n",
            "Testing: 100%|██████████| 31/31 [00:05<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Final Results:\n",
            "  Test Loss: 0.4386\n",
            "  Test Accuracy: 0.8196\n",
            "  Macro F1: 0.8110\n",
            "  Trainable params: 223,491 (0.20%)\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>final_f1_macro</td><td>▁</td></tr><tr><td>final_f1_negative</td><td>▁</td></tr><tr><td>final_f1_neutral</td><td>▁</td></tr><tr><td>final_f1_positive</td><td>▁</td></tr><tr><td>final_test_accuracy</td><td>▁</td></tr><tr><td>final_test_loss</td><td>▁</td></tr><tr><td>learning_rate</td><td>▄▅▆██▆▆▅▄▄▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▁▁▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>0.41422</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>final_f1_macro</td><td>0.81097</td></tr><tr><td>final_f1_negative</td><td>0.81229</td></tr><tr><td>final_f1_neutral</td><td>0.84666</td></tr><tr><td>final_f1_positive</td><td>0.77397</td></tr><tr><td>final_test_accuracy</td><td>0.81959</td></tr><tr><td>final_test_loss</td><td>0.43856</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>step</td><td>1630</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">true-sweep-2</strong> at: <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/runs/ady3g432' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/runs/ady3g432</a><br> View project at: <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251217_062052-ady3g432/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jzxi6mvt with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006106285174241048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.08506980874071064\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_target_modules: ['query', 'key', 'value']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_length: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \twarm_up_proportion: 0.13099513283919728\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/si2449/hpml-project/pipelines/finBERT/notebooks/wandb/run-20251217_063158-jzxi6mvt</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/runs/jzxi6mvt' target=\"_blank\">robust-sweep-3</a></strong> to <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/sweeps/wgeew1ms' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/sweeps/wgeew1ms</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/sweeps/wgeew1ms' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/sweeps/wgeew1ms</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/runs/jzxi6mvt' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/runs/jzxi6mvt</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Starting LoRA training run with config:\n",
            "  LoRA r: 4\n",
            "  LoRA alpha: 64\n",
            "  LoRA dropout: 0.0851\n",
            "  LoRA target modules: ['query', 'key', 'value']\n",
            "  Learning rate: 0.000611\n",
            "  Epochs: 8\n",
            "  Batch size: 64\n",
            "  Warmup: 0.1310\n",
            "  Max seq length: 64\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "12/17/2025 06:31:59 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "12/17/2025 06:32:01 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:32:01 - INFO - finbert.utils -   guid: train-1\n",
            "12/17/2025 06:32:01 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/17/2025 06:32:01 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:32:01 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:32:01 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:32:01 - INFO - finbert.utils -   label: positive (id = 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 223,491 || all params: 109,708,038 || trainable%: 0.2037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 06:32:01 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:32:01 - INFO - finbert.finbert -     Num examples = 3488\n",
            "12/17/2025 06:32:01 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:32:01 - INFO - finbert.finbert -     Num steps = 48\n",
            "Iteration: 100%|██████████| 55/55 [00:23<00:00,  2.29it/s]\n",
            "12/17/2025 06:32:25 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:32:25 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:32:25 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:32:25 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:32:25 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:32:25 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:32:25 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:32:25 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:32:25 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:32:25 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:32:25 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Validation loss = 0.6306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 55/55 [00:24<00:00,  2.28it/s]\n",
            "12/17/2025 06:32:52 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:32:52 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:32:52 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:32:52 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:32:52 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:32:52 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:32:52 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:32:52 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:32:52 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:32:52 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:32:52 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Validation loss = 0.5212\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 55/55 [00:23<00:00,  2.32it/s]\n",
            "12/17/2025 06:33:17 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:33:17 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:33:17 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:33:17 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:33:17 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:33:17 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:33:17 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:33:17 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:33:17 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:33:17 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:33:17 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.49it/s]\n",
            "Epoch:  38%|███▊      | 3/8 [01:17<02:08, 25.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: Validation loss = 0.5223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 55/55 [00:23<00:00,  2.31it/s]\n",
            "12/17/2025 06:33:43 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:33:43 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:33:43 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:33:43 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:33:43 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:33:43 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:33:43 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:33:43 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:33:43 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:33:43 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:33:43 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.47it/s]\n",
            "Epoch:  50%|█████     | 4/8 [01:42<01:41, 25.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: Validation loss = 0.5223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 55/55 [00:23<00:00,  2.30it/s]\n",
            "12/17/2025 06:34:08 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:34:08 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:34:08 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:34:08 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:34:08 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:34:08 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:34:08 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:34:08 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:34:08 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:34:08 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:34:08 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.45it/s]\n",
            "Epoch:  62%|██████▎   | 5/8 [02:07<01:16, 25.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: Validation loss = 0.5223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 55/55 [00:23<00:00,  2.30it/s]\n",
            "12/17/2025 06:34:33 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:34:33 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:34:33 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:34:33 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:34:33 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:34:33 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:34:33 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:34:33 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:34:33 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:34:33 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:34:33 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.46it/s]\n",
            "Epoch:  75%|███████▌  | 6/8 [02:33<00:50, 25.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: Validation loss = 0.5223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 55/55 [00:23<00:00,  2.30it/s]\n",
            "12/17/2025 06:34:58 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:34:58 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:34:58 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:34:58 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:34:58 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:34:58 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:34:58 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:34:58 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:34:58 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:34:58 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:34:58 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.47it/s]\n",
            "Epoch:  88%|████████▊ | 7/8 [02:58<00:25, 25.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: Validation loss = 0.5223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 55/55 [00:23<00:00,  2.30it/s]\n",
            "12/17/2025 06:35:24 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 06:35:24 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 06:35:24 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 06:35:24 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:35:24 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:35:24 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 06:35:24 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 06:35:24 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 06:35:24 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 06:35:24 - INFO - finbert.finbert -     Batch size = 64\n",
            "12/17/2025 06:35:24 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 7/7 [00:01<00:00,  5.46it/s]\n",
            "Epoch: 100%|██████████| 8/8 [03:23<00:00, 25.46s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: Validation loss = 0.5223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 967, in save\n",
            "    _save(\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 1268, in _save\n",
            "    zip_file.write_record(name, storage, num_bytes)\n",
            "RuntimeError: [enforce fail at inline_container.cc:858] . PytorchStreamWriter failed writing file data/263: file write failed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/var/tmp/ipykernel_3836044/1136645875.py\", line 80, in train_with_lora_config\n",
            "    trained_model = train_lora_with_wandb_logging(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/var/tmp/ipykernel_3836044/1780291689.py\", line 130, in train_lora_with_wandb_logging\n",
            "    torch.save(model_to_save.state_dict(), output_model_file)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 966, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 798, in __exit__\n",
            "    self.file_like.write_end_of_file()\n",
            "RuntimeError: [enforce fail at inline_container.cc:664] . unexpected pos 417688768 vs 417688656\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 967, in save\n",
            "    _save(\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 1268, in _save\n",
            "    zip_file.write_record(name, storage, num_bytes)\n",
            "RuntimeError: [enforce fail at inline_container.cc:858] . PytorchStreamWriter failed writing file data/263: file write failed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/var/tmp/ipykernel_3836044/1136645875.py\", line 80, in train_with_lora_config\n",
            "    trained_model = train_lora_with_wandb_logging(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/var/tmp/ipykernel_3836044/1780291689.py\", line 130, in train_lora_with_wandb_logging\n",
            "    torch.save(model_to_save.state_dict(), output_model_file)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 966, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 798, in __exit__\n",
            "    self.file_like.write_end_of_file()\n",
            "RuntimeError: [enforce fail at inline_container.cc:664] . unexpected pos 417688768 vs 417688656\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/logging/__init__.py\", line 1114, in emit\n",
            "    self.flush()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/logging/__init__.py\", line 1094, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 1002, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 296, in _run_job\n",
            "    self._function()\n",
            "  File \"/var/tmp/ipykernel_3836044/1136645875.py\", line 6, in train_with_lora_config\n",
            "    with wandb.init(config=config):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 3642, in __exit__\n",
            "    self._finish(exit_code=exit_code)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 400, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2295, in _finish\n",
            "    hook.call()\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_init.py\", line 614, in _jupyter_teardown\n",
            "    if self.notebook.save_ipynb():\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/jupyter.py\", line 359, in save_ipynb\n",
            "    logger.info(\"not saving jupyter notebook\")\n",
            "Message: 'not saving jupyter notebook'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 967, in save\n",
            "    _save(\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 1268, in _save\n",
            "    zip_file.write_record(name, storage, num_bytes)\n",
            "RuntimeError: [enforce fail at inline_container.cc:858] . PytorchStreamWriter failed writing file data/263: file write failed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/var/tmp/ipykernel_3836044/1136645875.py\", line 80, in train_with_lora_config\n",
            "    trained_model = train_lora_with_wandb_logging(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/var/tmp/ipykernel_3836044/1780291689.py\", line 130, in train_lora_with_wandb_logging\n",
            "    torch.save(model_to_save.state_dict(), output_model_file)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 966, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 798, in __exit__\n",
            "    self.file_like.write_end_of_file()\n",
            "RuntimeError: [enforce fail at inline_container.cc:664] . unexpected pos 417688768 vs 417688656\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/logging/__init__.py\", line 1114, in emit\n",
            "    self.flush()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/logging/__init__.py\", line 1094, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 1002, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 296, in _run_job\n",
            "    self._function()\n",
            "  File \"/var/tmp/ipykernel_3836044/1136645875.py\", line 6, in train_with_lora_config\n",
            "    with wandb.init(config=config):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 3642, in __exit__\n",
            "    self._finish(exit_code=exit_code)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 400, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2295, in _finish\n",
            "    hook.call()\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_init.py\", line 618, in _jupyter_teardown\n",
            "    self._logger.info(\"cleaning up jupyter logic\")\n",
            "Message: 'cleaning up jupyter logic'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 967, in save\n",
            "    _save(\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 1268, in _save\n",
            "    zip_file.write_record(name, storage, num_bytes)\n",
            "RuntimeError: [enforce fail at inline_container.cc:858] . PytorchStreamWriter failed writing file data/263: file write failed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/var/tmp/ipykernel_3836044/1136645875.py\", line 80, in train_with_lora_config\n",
            "    trained_model = train_lora_with_wandb_logging(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/var/tmp/ipykernel_3836044/1780291689.py\", line 130, in train_lora_with_wandb_logging\n",
            "    torch.save(model_to_save.state_dict(), output_model_file)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 966, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 798, in __exit__\n",
            "    self.file_like.write_end_of_file()\n",
            "RuntimeError: [enforce fail at inline_container.cc:664] . unexpected pos 417688768 vs 417688656\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/logging/__init__.py\", line 1114, in emit\n",
            "    self.flush()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/logging/__init__.py\", line 1094, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 1002, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 296, in _run_job\n",
            "    self._function()\n",
            "  File \"/var/tmp/ipykernel_3836044/1136645875.py\", line 6, in train_with_lora_config\n",
            "    with wandb.init(config=config):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 3642, in __exit__\n",
            "    self._finish(exit_code=exit_code)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 400, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2303, in _finish\n",
            "    self._atexit_cleanup(exit_code=exit_code)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2486, in _atexit_cleanup\n",
            "    logger.info(f\"got exitcode: {exit_code}\")\n",
            "Message: 'got exitcode: 1'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 967, in save\n",
            "    _save(\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 1268, in _save\n",
            "    zip_file.write_record(name, storage, num_bytes)\n",
            "RuntimeError: [enforce fail at inline_container.cc:858] . PytorchStreamWriter failed writing file data/263: file write failed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/var/tmp/ipykernel_3836044/1136645875.py\", line 80, in train_with_lora_config\n",
            "    trained_model = train_lora_with_wandb_logging(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/var/tmp/ipykernel_3836044/1780291689.py\", line 130, in train_lora_with_wandb_logging\n",
            "    torch.save(model_to_save.state_dict(), output_model_file)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 966, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 798, in __exit__\n",
            "    self.file_like.write_end_of_file()\n",
            "RuntimeError: [enforce fail at inline_container.cc:664] . unexpected pos 417688768 vs 417688656\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/logging/__init__.py\", line 1114, in emit\n",
            "    self.flush()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/logging/__init__.py\", line 1094, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 1002, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 296, in _run_job\n",
            "    self._function()\n",
            "  File \"/var/tmp/ipykernel_3836044/1136645875.py\", line 6, in train_with_lora_config\n",
            "    with wandb.init(config=config):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 3642, in __exit__\n",
            "    self._finish(exit_code=exit_code)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 400, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2303, in _finish\n",
            "    self._atexit_cleanup(exit_code=exit_code)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2498, in _atexit_cleanup\n",
            "    self._on_finish()\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2706, in _on_finish\n",
            "    self._console_stop()  # TODO: there's a race here with jupyter console logging\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2527, in _console_stop\n",
            "    self._restore()\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2468, in _restore\n",
            "    logger.info(\"restore\")\n",
            "Message: 'restore'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 967, in save\n",
            "    _save(\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 1268, in _save\n",
            "    zip_file.write_record(name, storage, num_bytes)\n",
            "RuntimeError: [enforce fail at inline_container.cc:858] . PytorchStreamWriter failed writing file data/263: file write failed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/var/tmp/ipykernel_3836044/1136645875.py\", line 80, in train_with_lora_config\n",
            "    trained_model = train_lora_with_wandb_logging(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/var/tmp/ipykernel_3836044/1780291689.py\", line 130, in train_lora_with_wandb_logging\n",
            "    torch.save(model_to_save.state_dict(), output_model_file)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 966, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 798, in __exit__\n",
            "    self.file_like.write_end_of_file()\n",
            "RuntimeError: [enforce fail at inline_container.cc:664] . unexpected pos 417688768 vs 417688656\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/logging/__init__.py\", line 1114, in emit\n",
            "    self.flush()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/logging/__init__.py\", line 1094, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 1002, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 296, in _run_job\n",
            "    self._function()\n",
            "  File \"/var/tmp/ipykernel_3836044/1136645875.py\", line 6, in train_with_lora_config\n",
            "    with wandb.init(config=config):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 3642, in __exit__\n",
            "    self._finish(exit_code=exit_code)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 400, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2303, in _finish\n",
            "    self._atexit_cleanup(exit_code=exit_code)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2498, in _atexit_cleanup\n",
            "    self._on_finish()\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2706, in _on_finish\n",
            "    self._console_stop()  # TODO: there's a race here with jupyter console logging\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2527, in _console_stop\n",
            "    self._restore()\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2474, in _restore\n",
            "    logger.info(\"restore done\")\n",
            "Message: 'restore done'\n",
            "Arguments: ()\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>█▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>learning_rate</td><td>▆█▇▇▆▅▄▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>total_params</td><td>▁</td></tr><tr><td>train_loss</td><td>██▇▇▆▃▃▃▃▃▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainable_params</td><td>▁</td></tr><tr><td>trainable_percent</td><td>▁</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>0.52118</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>step</td><td>440</td></tr><tr><td>total_params</td><td>109708038</td></tr><tr><td>train_loss</td><td>0.44263</td></tr><tr><td>trainable_params</td><td>223491</td></tr><tr><td>trainable_percent</td><td>0.20371</td></tr><tr><td>val_loss</td><td>0.52225</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 967, in save\n",
            "    _save(\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 1268, in _save\n",
            "    zip_file.write_record(name, storage, num_bytes)\n",
            "RuntimeError: [enforce fail at inline_container.cc:858] . PytorchStreamWriter failed writing file data/263: file write failed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/var/tmp/ipykernel_3836044/1136645875.py\", line 80, in train_with_lora_config\n",
            "    trained_model = train_lora_with_wandb_logging(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/var/tmp/ipykernel_3836044/1780291689.py\", line 130, in train_lora_with_wandb_logging\n",
            "    torch.save(model_to_save.state_dict(), output_model_file)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 966, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 798, in __exit__\n",
            "    self.file_like.write_end_of_file()\n",
            "RuntimeError: [enforce fail at inline_container.cc:664] . unexpected pos 417688768 vs 417688656\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/logging/__init__.py\", line 1114, in emit\n",
            "    self.flush()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/logging/__init__.py\", line 1094, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 1002, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 296, in _run_job\n",
            "    self._function()\n",
            "  File \"/var/tmp/ipykernel_3836044/1136645875.py\", line 6, in train_with_lora_config\n",
            "    with wandb.init(config=config):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 3642, in __exit__\n",
            "    self._finish(exit_code=exit_code)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 400, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2303, in _finish\n",
            "    self._atexit_cleanup(exit_code=exit_code)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2511, in _atexit_cleanup\n",
            "    Run._footer(\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 3820, in _footer\n",
            "    Run._footer_sync_info(\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 3862, in _footer_sync_info\n",
            "    logger.info(\"logging synced files\")\n",
            "Message: 'logging synced files'\n",
            "Arguments: ()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">robust-sweep-3</strong> at: <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/runs/jzxi6mvt' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep/runs/jzxi6mvt</a><br> View project at: <a href='https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-lora-hyperparameter-sweep</a><br>Synced 2 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251217_063158-jzxi6mvt/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 967, in save\n",
            "    _save(\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 1268, in _save\n",
            "    zip_file.write_record(name, storage, num_bytes)\n",
            "RuntimeError: [enforce fail at inline_container.cc:858] . PytorchStreamWriter failed writing file data/263: file write failed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/var/tmp/ipykernel_3836044/1136645875.py\", line 80, in train_with_lora_config\n",
            "    trained_model = train_lora_with_wandb_logging(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/var/tmp/ipykernel_3836044/1780291689.py\", line 130, in train_lora_with_wandb_logging\n",
            "    torch.save(model_to_save.state_dict(), output_model_file)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 966, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/torch/serialization.py\", line 798, in __exit__\n",
            "    self.file_like.write_end_of_file()\n",
            "RuntimeError: [enforce fail at inline_container.cc:664] . unexpected pos 417688768 vs 417688656\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/logging/__init__.py\", line 1192, in close\n",
            "    self.flush()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/logging/__init__.py\", line 1094, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "OSError: [Errno 28] No space left on device\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 296, in _run_job\n",
            "    self._function()\n",
            "  File \"/var/tmp/ipykernel_3836044/1136645875.py\", line 6, in train_with_lora_config\n",
            "    with wandb.init(config=config):\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 3642, in __exit__\n",
            "    self._finish(exit_code=exit_code)\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 400, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 2309, in _finish\n",
            "    hook.call()\n",
            "  File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/wandb_init.py\", line 703, in dispose_handler\n",
            "    handler.close()\n",
            "  File \"/home/si2449/.pyenv/versions/3.11.8/lib/python3.11/logging/__init__.py\", line 1197, in close\n",
            "    stream.close()\n",
            "OSError: [Errno 28] No space left on device\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run jzxi6mvt errored: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ffw0fn8h errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m During handling of the above exception, another exception occurred:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 287, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     config_util.save_config_file_from_dict(sweep_param_path, job.config)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/lib/config_util.py\", line 60, in save_config_file_from_dict\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     with open(config_filename, \"w\") as conf_file:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 4imdymml errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m During handling of the above exception, another exception occurred:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 287, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     config_util.save_config_file_from_dict(sweep_param_path, job.config)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/lib/config_util.py\", line 60, in save_config_file_from_dict\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     with open(config_filename, \"w\") as conf_file:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run kpgp5idj errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m During handling of the above exception, another exception occurred:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 287, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     config_util.save_config_file_from_dict(sweep_param_path, job.config)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/lib/config_util.py\", line 60, in save_config_file_from_dict\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     with open(config_filename, \"w\") as conf_file:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run g5cy1hqf errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m During handling of the above exception, another exception occurred:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 287, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     config_util.save_config_file_from_dict(sweep_param_path, job.config)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/lib/config_util.py\", line 60, in save_config_file_from_dict\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     with open(config_filename, \"w\") as conf_file:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run emxve0ka errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m During handling of the above exception, another exception occurred:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 287, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     config_util.save_config_file_from_dict(sweep_param_path, job.config)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/lib/config_util.py\", line 60, in save_config_file_from_dict\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     with open(config_filename, \"w\") as conf_file:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 070sx1nm errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m During handling of the above exception, another exception occurred:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 287, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     config_util.save_config_file_from_dict(sweep_param_path, job.config)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/lib/config_util.py\", line 60, in save_config_file_from_dict\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     with open(config_filename, \"w\") as conf_file:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run d8ivg177 errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m During handling of the above exception, another exception occurred:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 287, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     config_util.save_config_file_from_dict(sweep_param_path, job.config)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/lib/config_util.py\", line 60, in save_config_file_from_dict\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     with open(config_filename, \"w\") as conf_file:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run tzodwg7e errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m During handling of the above exception, another exception occurred:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 287, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     config_util.save_config_file_from_dict(sweep_param_path, job.config)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/lib/config_util.py\", line 60, in save_config_file_from_dict\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     with open(config_filename, \"w\") as conf_file:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run fddtie5h errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m During handling of the above exception, another exception occurred:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 287, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     config_util.save_config_file_from_dict(sweep_param_path, job.config)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/lib/config_util.py\", line 60, in save_config_file_from_dict\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     with open(config_filename, \"w\") as conf_file:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ighr4dfc errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m During handling of the above exception, another exception occurred:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 287, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     config_util.save_config_file_from_dict(sweep_param_path, job.config)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/lib/config_util.py\", line 60, in save_config_file_from_dict\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     with open(config_filename, \"w\") as conf_file:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 0xmaehcr errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m During handling of the above exception, another exception occurred:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 287, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     config_util.save_config_file_from_dict(sweep_param_path, job.config)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/lib/config_util.py\", line 60, in save_config_file_from_dict\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     with open(config_filename, \"w\") as conf_file:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run d8g3f0bp errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m During handling of the above exception, another exception occurred:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 287, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     config_util.save_config_file_from_dict(sweep_param_path, job.config)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/si2449/hpml-project/venv/lib/python3.11/site-packages/wandb/sdk/lib/config_util.py\", line 60, in save_config_file_from_dict\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     with open(config_filename, \"w\") as conf_file:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: [Errno 28] No space left on device\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "LORA SWEEP COMPLETED\n",
            "================================================================================\n",
            "View results at: https://wandb.ai/your-username/finbert-lora-hyperparameter-sweep/sweeps/wgeew1ms\n"
          ]
        }
      ],
      "source": [
        "# Run the sweep\n",
        "# count: number of runs to execute (increase for more thorough search)\n",
        "wandb.agent(sweep_id, function=train_with_lora_config, count=15)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"LORA SWEEP COMPLETED\")\n",
        "print(\"=\"*80)\n",
        "print(f\"View results at: https://wandb.ai/{WANDB_ENTITY or 'your-username'}/{WANDB_PROJECT}/sweeps/{sweep_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_with_wandb_logging(finbert, train_data, model, use_lora: bool):\n",
        "    validation_examples = finbert.get_data(\"validation\")\n",
        "    train_dataloader = finbert.get_loader(train_data, \"train\")\n",
        "\n",
        "    build_optimizer_and_scheduler(model, finbert, train_dataloader)\n",
        "\n",
        "    global_step = 0\n",
        "    finbert.validation_losses = []\n",
        "\n",
        "    step_number = len(train_dataloader)\n",
        "    i = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in trange(int(finbert.config.num_train_epochs), desc=\"Epoch\"):\n",
        "        model.train()\n",
        "        tr_loss = 0.0\n",
        "        nb_tr_steps = 0\n",
        "\n",
        "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
        "            if finbert.config.gradual_unfreeze and (not use_lora) and i == 0:\n",
        "                backbone = get_bert_backbone(model)\n",
        "                for param in backbone.parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "            if (step_number // 3) > 0 and (step % (step_number // 3)) == 0:\n",
        "                i += 1\n",
        "\n",
        "            if finbert.config.gradual_unfreeze and (not use_lora):\n",
        "                backbone = get_bert_backbone(model)\n",
        "                enc = backbone.encoder.layer\n",
        "                enc_no = finbert.config.encoder_no\n",
        "\n",
        "                if i > 1 and i < enc_no:\n",
        "                    for k in range(i - 1):\n",
        "                        for param in enc[enc_no - 1 - k].parameters():\n",
        "                            param.requires_grad = True\n",
        "\n",
        "                if i > enc_no + 1:\n",
        "                    for param in backbone.embeddings.parameters():\n",
        "                        param.requires_grad = True\n",
        "\n",
        "            batch = tuple(t.to(finbert.device) for t in batch)\n",
        "            input_ids, attention_mask, token_type_ids, label_ids, agree_ids = batch\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "            logits = outputs[0] if isinstance(outputs, (tuple, list)) else outputs.logits\n",
        "\n",
        "            weights = finbert.class_weights.to(finbert.device)\n",
        "            loss_fct = CrossEntropyLoss(weight=weights)\n",
        "            loss = loss_fct(logits.view(-1, finbert.num_labels), label_ids.view(-1))\n",
        "\n",
        "            grad_acc = getattr(finbert.config, \"gradient_accumulation_steps\", 1) or 1\n",
        "            loss = loss / grad_acc\n",
        "            loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_steps += 1\n",
        "\n",
        "            if (step + 1) % grad_acc == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                finbert.optimizer.step()\n",
        "                finbert.scheduler.step()\n",
        "                finbert.optimizer.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if global_step % 10 == 0:\n",
        "                    wandb.log({\n",
        "                        \"train_loss\": tr_loss / max(nb_tr_steps, 1),\n",
        "                        \"learning_rate\": finbert.optimizer.param_groups[0][\"lr\"],\n",
        "                        \"epoch\": epoch,\n",
        "                        \"step\": global_step,\n",
        "                    })\n",
        "\n",
        "        validation_loader = finbert.get_loader(validation_examples, \"eval\")\n",
        "        model.eval()\n",
        "\n",
        "        valid_loss = 0.0\n",
        "        nb_valid_steps = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for input_ids, attention_mask, token_type_ids, label_ids, agree_ids in tqdm(validation_loader, desc=\"Validating\"):\n",
        "                input_ids = input_ids.to(finbert.device)\n",
        "                attention_mask = attention_mask.to(finbert.device)\n",
        "                token_type_ids = token_type_ids.to(finbert.device)\n",
        "                label_ids = label_ids.to(finbert.device)\n",
        "\n",
        "                outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "                logits = outputs[0] if isinstance(outputs, (tuple, list)) else outputs.logits\n",
        "\n",
        "                tmp_valid_loss = loss_fct(logits.view(-1, finbert.num_labels), label_ids.view(-1))\n",
        "                valid_loss += float(tmp_valid_loss.item())\n",
        "                nb_valid_steps += 1\n",
        "\n",
        "        valid_loss /= max(nb_valid_steps, 1)\n",
        "        finbert.validation_losses.append(valid_loss)\n",
        "\n",
        "        wandb.log({\n",
        "            \"val_loss\": valid_loss,\n",
        "            \"epoch\": epoch,\n",
        "            \"best_val_loss\": min(finbert.validation_losses),\n",
        "        })\n",
        "\n",
        "        print(f\"Epoch {epoch}: Validation loss = {valid_loss:.4f}\")\n",
        "\n",
        "        if valid_loss == min(finbert.validation_losses):\n",
        "            best_model = epoch\n",
        "            os.makedirs(finbert.config.model_dir, exist_ok=True)\n",
        "            torch.save({\"epoch\": int(epoch), \"state_dict\": model.state_dict()},\n",
        "                       Path(finbert.config.model_dir) / f\"temporary_{epoch}.pt\")\n",
        "\n",
        "    if best_model is not None:\n",
        "        ckpt = torch.load(Path(finbert.config.model_dir) / f\"temporary_{best_model}.pt\", map_location=finbert.device)\n",
        "        model.load_state_dict(ckpt[\"state_dict\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "import math\n",
        "import wandb\n",
        "\n",
        "def train_with_config():\n",
        "    cfg = wandb.config\n",
        "    finbert = FinBert(cfg)\n",
        "\n",
        "    # --- build train loader FIRST so we can compute total optimizer steps ---\n",
        "    train_data = finbert.get_data(\"train\")\n",
        "    train_dataloader = finbert.get_loader(train_data, \"train\")\n",
        "\n",
        "    grad_acc = getattr(cfg, \"gradient_accumulation_steps\", 1) or 1\n",
        "    steps_per_epoch = math.ceil(len(train_dataloader) / grad_acc)\n",
        "    finbert.num_train_optimization_steps = steps_per_epoch * int(cfg.num_train_epochs)\n",
        "\n",
        "    # --- now create base model (this was crashing before) ---\n",
        "    model = finbert.create_the_model()\n",
        "\n",
        "    # --- apply LoRA AFTER model exists ---\n",
        "    if cfg.use_lora:\n",
        "        from peft import LoraConfig, TaskType, get_peft_model\n",
        "\n",
        "        target_modules = [s.strip() for s in str(cfg.lora_target).split(\",\") if s.strip()]\n",
        "\n",
        "        lora_cfg = LoraConfig(\n",
        "            r=int(cfg.lora_r),\n",
        "            lora_alpha=int(cfg.lora_alpha),\n",
        "            lora_dropout=float(cfg.lora_dropout),\n",
        "            target_modules=target_modules,\n",
        "            bias=\"none\",\n",
        "            task_type=TaskType.SEQ_CLS,\n",
        "        )\n",
        "        model = get_peft_model(model, lora_cfg)\n",
        "        model.to(finbert.device)\n",
        "        model.print_trainable_parameters()\n",
        "\n",
        "    # train (you can reuse train_data; your train fn will rebuild loader internally)\n",
        "    model = train_with_wandb_logging(finbert, train_data, model, use_lora=bool(cfg.use_lora))\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Analyze Results\n",
        "\n",
        "After the sweep completes, examine the best configuration from the W&B dashboard.\n",
        "\n",
        "Key metrics to compare:\n",
        "- **val_loss**: Primary optimization target\n",
        "- **final_test_accuracy**: Test set performance\n",
        "- **final_f1_macro**: Balanced F1 across classes\n",
        "- **trainable_params**: Parameter efficiency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best LoRA configuration (update after sweep):\n",
            "  lora_r: 8\n",
            "  lora_alpha: 16\n",
            "  lora_dropout: 0.1\n",
            "  lora_target_modules: ['query', 'value']\n",
            "  learning_rate: 0.0005\n",
            "  num_train_epochs: 10\n",
            "  train_batch_size: 32\n",
            "  warm_up_proportion: 0.2\n",
            "  max_seq_length: 64\n",
            "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
          ]
        }
      ],
      "source": [
        "# Once you've identified the best config from the W&B dashboard, record it here:\n",
        "# Example (update with your actual best values from the sweep)\n",
        "best_lora_config = {\n",
        "    # LoRA parameters\n",
        "    'lora_r': 8,\n",
        "    'lora_alpha': 16,\n",
        "    'lora_dropout': 0.1,\n",
        "    'lora_target_modules': ['query', 'value'],\n",
        "    # Training parameters\n",
        "    'learning_rate': 5e-4,\n",
        "    'num_train_epochs': 10,\n",
        "    'train_batch_size': 32,\n",
        "    'warm_up_proportion': 0.2,\n",
        "    'max_seq_length': 64,\n",
        "}\n",
        "\n",
        "print(\"Best LoRA configuration (update after sweep):\")\n",
        "for k, v in best_lora_config.items():\n",
        "    print(f\"  {k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Retrain with Best Config (Optional)\n",
        "\n",
        "Use the best configuration to train a final model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to retrain with best config\n",
        "# train_with_lora_config(config=best_lora_config)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
