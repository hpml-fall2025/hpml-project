{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FinBERT Profiling: Medium FinBert + Knowledge Distilation\n",
        "\n",
        "This notebook is intentionally **thin**: it reuses the profiling utilities in `pipelines/finBERT/finbert/` (especially `finbert/finbert_profile.py` and `finbert/profile_utils.py`) instead of copying large code blocks.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import os\n",
        "import logging\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from textblob import TextBlob\n",
        "from pprint import pprint\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "from finbert.finbert import *\n",
        "from finbert.finbert_profile import *\n",
        "from finbert.profile_utils import get_model_size_mb, print_device_info, setup_nltk_data\n",
        "import finbert.utils as tools\n",
        "\n",
        "from finbert.finbert_kd_trainer import KDFinBert\n",
        "\n",
        "\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "project_dir = Path.cwd().parent\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/srm2245/hpml-project/pipelines/finBERT/notebooks/wandb/run-20251216_163654-1ooi9lx4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/1ooi9lx4' target=\"_blank\">training-distilled_bert-profiled</a></strong> to <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/1ooi9lx4' target=\"_blank\">https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/1ooi9lx4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/si2449-columbia-university/finbert-experiments/runs/1ooi9lx4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f1db8282830>"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(\n",
        "    entity=\"si2449-columbia-university\",\n",
        "    project=\"finbert-experiments\",\n",
        "    name=\"training-distilled_bert-profiled\",\n",
        "    group=\"knowledge-distillation\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "cl_path = project_dir/'models'/'student'\n",
        "cl_data_path = project_dir/'data'/'sentiment_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-medium and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    shutil.rmtree(cl_path) \n",
        "except:\n",
        "    pass\n",
        "\n",
        "bertmodel = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-medium\", cache_dir=None, num_labels=3)\n",
        "\n",
        "\n",
        "config = Config(   data_dir=cl_data_path,\n",
        "                   bert_model=bertmodel,\n",
        "                   num_train_epochs=4,\n",
        "                   model_dir=cl_path,\n",
        "                   max_seq_length = 48,\n",
        "                   train_batch_size = 32,\n",
        "                   learning_rate = 1e-5,\n",
        "                   output_mode='classification',\n",
        "                   warm_up_proportion=0.1,\n",
        "                   local_rank=-1,\n",
        "                   discriminate=True,\n",
        "                   gradual_unfreeze=True,\n",
        "                   encoder_no = 8)\n",
        "\n",
        "config.profile_train_steps = 20\n",
        "config.num_hidden_layers = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "from contextlib import nullcontext\n",
        "from typing import Any\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "def timed_eval(\n",
        "    *, finbert: FinBert, model: torch.nn.Module, examples, use_amp: bool\n",
        ") -> tuple[pd.DataFrame, dict[str, Any]]:\n",
        "    \"\"\"Evaluation loop with optional CUDA autocast + timing (kept small for notebook use).\"\"\"\n",
        "    loader = finbert.get_loader(examples, phase=\"eval\")\n",
        "    device = finbert.device\n",
        "\n",
        "    model.eval()\n",
        "    preds: list[np.ndarray] = []\n",
        "    labels: list[int] = []\n",
        "\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize(device)\n",
        "\n",
        "    start = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, attention_mask, token_type_ids, label_ids, _agree_ids = batch\n",
        "\n",
        "            logits = model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
        "\n",
        "            preds.extend(logits.detach().cpu().numpy())\n",
        "            labels.extend(label_ids.detach().cpu().numpy().tolist())\n",
        "\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize(device)\n",
        "\n",
        "    wall_s = time.perf_counter() - start\n",
        "    n = len(labels)\n",
        "\n",
        "    results_df = pd.DataFrame({\"predictions\": preds, \"labels\": labels})\n",
        "\n",
        "    timing = {\n",
        "        \"eval_wall_s\": float(wall_s),\n",
        "        \"eval_num_samples\": int(n),\n",
        "        \"eval_samples_per_s\": float(n / wall_s) if wall_s > 0 else float(\"inf\"),\n",
        "    }\n",
        "    return results_df, timing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "finbert = ProfiledFinBert(config)\n",
        "finbert.config.base_model = 'prajjwal1/bert-medium'\n",
        "finbert.config.discriminate=True\n",
        "finbert.config.gradual_unfreeze=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/16/2025 16:36:57 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n"
          ]
        }
      ],
      "source": [
        "finbert.prepare_model(label_list=['positive','negative','neutral'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = finbert.get_data('train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = finbert.create_the_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/16/2025 16:36:59 - INFO - finbert.utils -   *** Example ***\n",
            "12/16/2025 16:36:59 - INFO - finbert.utils -   guid: train-1\n",
            "12/16/2025 16:36:59 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/16/2025 16:36:59 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:36:59 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:36:59 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:36:59 - INFO - finbert.utils -   label: positive (id = 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/16/2025 16:37:00 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/16/2025 16:37:00 - INFO - finbert.finbert -     Num examples = 3488\n",
            "12/16/2025 16:37:00 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/16/2025 16:37:00 - INFO - finbert.finbert -     Num steps = 48\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Starting Profiled Training\n",
            "Device: cuda\n",
            "Profiling activities: [<ProfilerActivity.CPU: 0>, <ProfilerActivity.CUDA: 2>]\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration:  17%|█▋        | 19/109 [00:00<00:03, 28.37it/s]\n",
            "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Profiling complete for first epoch (20 steps)\n",
            "Continuing full training without profiling...\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "PROFILING RESULTS - Training\n",
            "================================================================================\n",
            "\n",
            "\n",
            "By CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                               aten::to         0.11%     722.450us        52.75%     343.664ms       1.067ms       0.000us         0.00%     461.111us       1.432us           0 B           0 B       7.76 MB           0 B           322  \n",
            "                                         aten::_to_copy         0.15%     996.536us        52.64%     342.942ms       2.143ms       0.000us         0.00%     461.111us       2.882us           0 B           0 B       7.76 MB           0 B           160  \n",
            "                                       loss_calculation         0.53%       3.426ms        52.61%     342.750ms      17.138ms       0.000us         0.00%     149.025us       7.451us           0 B           0 B      21.00 KB     -19.00 KB            20  \n",
            "                                            aten::copy_         0.20%       1.313ms        52.38%     341.211ms       1.896ms     528.502us         0.10%     528.502us       2.936us           0 B           0 B           0 B           0 B           180  \n",
            "                                  cudaStreamSynchronize        51.78%     337.298ms        51.78%     337.298ms       2.108ms       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           160  \n",
            "                                           forward_pass        10.17%      66.274ms        32.51%     211.814ms      10.591ms       0.000us         0.00%     516.884ms      25.844ms           0 B         -80 B       1.25 MB      -9.69 GB            20  \n",
            "                                           aten::linear         1.31%       8.529ms        10.79%      70.266ms      70.266us       0.000us         0.00%     428.505ms     428.505us           0 B           0 B       4.22 GB           0 B          1000  \n",
            "                                            aten::addmm         4.96%      32.292ms         7.24%      47.142ms      47.142us     428.505ms        82.46%     428.505ms     428.505us           0 B           0 B       4.22 GB       4.22 GB          1000  \n",
            "                                         optimizer_step         2.05%      13.330ms         5.82%      37.937ms       1.897ms       0.000us         0.00%       1.917ms      95.848us           8 B           0 B    -117.00 KB     -80.00 KB            20  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...         1.75%      11.410ms         4.81%      31.353ms       1.568ms       0.000us         0.00%       0.000us       0.000us     730.00 KB     -27.26 KB           0 B           0 B            20  \n",
            "                                       cudaLaunchKernel         4.15%      27.055ms         4.15%      27.055ms       8.238us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B          3284  \n",
            "                              Optimizer.step#AdamW.step         1.74%      11.335ms         2.79%      18.181ms     909.035us       0.000us         0.00%       1.234ms      61.721us           8 B        -160 B      13.00 KB    -130.00 KB            20  \n",
            "                                          aten::dropout         0.25%       1.651ms         2.66%      17.341ms      48.170us       0.000us         0.00%      10.618ms      29.494us           0 B           0 B    1021.25 MB    -255.31 MB           360  \n",
            "                                       aten::layer_norm         0.27%       1.770ms         2.53%      16.457ms      48.403us       0.000us         0.00%      13.403ms      39.420us           0 B           0 B    1020.21 MB      -3.78 MB           340  \n",
            "                                   aten::native_dropout         0.89%       5.766ms         2.41%      15.690ms      43.584us      10.618ms         2.04%      10.618ms      29.494us           0 B           0 B       1.25 GB           0 B           360  \n",
            "                     aten::scaled_dot_product_attention         0.31%       2.028ms         2.31%      15.044ms      94.024us       0.000us         0.00%      32.809ms     205.057us           0 B      -2.50 KB     480.00 MB           0 B           160  \n",
            "                                aten::native_layer_norm         0.96%       6.268ms         2.25%      14.687ms      43.196us      13.403ms         2.58%      13.403ms      39.420us           0 B           0 B    1023.98 MB           0 B           340  \n",
            "                                          backward_pass         2.05%      13.360ms         2.19%      14.238ms     711.918us       0.000us         0.00%      41.149us       2.057us           0 B           0 B      -1.14 MB      -1.15 MB            20  \n",
            "                                           aten::select         1.55%      10.094ms         2.03%      13.224ms       4.107us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B          3220  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.27%       1.732ms         1.84%      11.987ms      74.917us       0.000us         0.00%      32.809ms     205.057us       2.50 KB           0 B     480.00 MB           0 B           160  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 651.458ms\n",
            "Self CUDA time total: 519.679ms\n",
            "\n",
            "\n",
            "By CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us     533.940ms       102.74%     533.940ms      26.697ms           0 B           0 B           0 B           0 B            20  \n",
            "                                           forward_pass        10.17%      66.274ms        32.51%     211.814ms      10.591ms       0.000us         0.00%     516.884ms      25.844ms           0 B         -80 B       1.25 MB      -9.69 GB            20  \n",
            "                                           aten::linear         1.31%       8.529ms        10.79%      70.266ms      70.266us       0.000us         0.00%     428.505ms     428.505us           0 B           0 B       4.22 GB           0 B          1000  \n",
            "                                            aten::addmm         4.96%      32.292ms         7.24%      47.142ms      47.142us     428.505ms        82.46%     428.505ms     428.505us           0 B           0 B       4.22 GB       4.22 GB          1000  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     293.650ms        56.51%     293.650ms     373.600us           0 B           0 B           0 B           0 B           786  \n",
            "                                 volta_sgemm_128x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     133.038ms        25.60%     133.038ms     842.011us           0 B           0 B           0 B           0 B           158  \n",
            "                     aten::scaled_dot_product_attention         0.31%       2.028ms         2.31%      15.044ms      94.024us       0.000us         0.00%      32.809ms     205.057us           0 B      -2.50 KB     480.00 MB           0 B           160  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.27%       1.732ms         1.84%      11.987ms      74.917us       0.000us         0.00%      32.809ms     205.057us       2.50 KB           0 B     480.00 MB           0 B           160  \n",
            "                     aten::_efficient_attention_forward         0.51%       3.301ms         1.22%       7.946ms      49.663us      32.809ms         6.31%      32.809ms     205.057us       2.50 KB           0 B     480.00 MB           0 B           160  \n",
            "fmha_cutlassF_f32_aligned_64x64_rf_sm75(PyTorchMemEf...         0.00%       0.000us         0.00%       0.000us       0.000us      32.809ms         6.31%      32.809ms     208.975us           0 B           0 B           0 B           0 B           157  \n",
            "                                             aten::gelu         0.37%       2.412ms         0.58%       3.753ms      23.454us      16.826ms         3.24%      16.826ms     105.160us           0 B           0 B       1.88 GB       1.88 GB           160  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      16.826ms         3.24%      16.826ms     106.491us           0 B           0 B           0 B           0 B           158  \n",
            "                                       aten::layer_norm         0.27%       1.770ms         2.53%      16.457ms      48.403us       0.000us         0.00%      13.403ms      39.420us           0 B           0 B    1020.21 MB      -3.78 MB           340  \n",
            "                                aten::native_layer_norm         0.96%       6.268ms         2.25%      14.687ms      43.196us      13.403ms         2.58%      13.403ms      39.420us           0 B           0 B    1023.98 MB           0 B           340  \n",
            "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us      13.403ms         2.58%      13.403ms      40.008us           0 B           0 B           0 B           0 B           335  \n",
            "                                              aten::add         0.78%       5.071ms         1.16%       7.549ms      20.970us      12.834ms         2.47%      12.834ms      35.649us           0 B           0 B    1020.01 MB    1020.01 MB           360  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      12.788ms         2.46%      12.788ms      38.174us           0 B           0 B           0 B           0 B           335  \n",
            "                                          aten::dropout         0.25%       1.651ms         2.66%      17.341ms      48.170us       0.000us         0.00%      10.618ms      29.494us           0 B           0 B    1021.25 MB    -255.31 MB           360  \n",
            "                                   aten::native_dropout         0.89%       5.766ms         2.41%      15.690ms      43.584us      10.618ms         2.04%      10.618ms      29.494us           0 B           0 B       1.25 GB           0 B           360  \n",
            "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us      10.618ms         2.04%      10.618ms      29.910us           0 B           0 B           0 B           0 B           355  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 651.458ms\n",
            "Self CUDA time total: 519.679ms\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "⚠ Failed to log profiler table: 'FunctionEventAvg' object has no attribute 'cuda_time_total'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:03<00:00, 27.62it/s]\n",
            "12/16/2025 16:37:13 - INFO - finbert.utils -   *** Example ***\n",
            "12/16/2025 16:37:13 - INFO - finbert.utils -   guid: validation-1\n",
            "12/16/2025 16:37:13 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/16/2025 16:37:13 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:13 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:13 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:13 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/16/2025 16:37:13 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/16/2025 16:37:13 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/16/2025 16:37:13 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/16/2025 16:37:13 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 39.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [1.072305679321289]\n",
            "No best model found\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:07<00:00, 15.52it/s]\n",
            "12/16/2025 16:37:20 - INFO - finbert.utils -   *** Example ***\n",
            "12/16/2025 16:37:20 - INFO - finbert.utils -   guid: validation-1\n",
            "12/16/2025 16:37:20 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/16/2025 16:37:20 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:20 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:20 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:20 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/16/2025 16:37:20 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/16/2025 16:37:20 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/16/2025 16:37:20 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/16/2025 16:37:20 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 38.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [1.072305679321289, 0.9563326927331778]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:08<00:00, 12.52it/s]\n",
            "12/16/2025 16:37:30 - INFO - finbert.utils -   *** Example ***\n",
            "12/16/2025 16:37:30 - INFO - finbert.utils -   guid: validation-1\n",
            "12/16/2025 16:37:30 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/16/2025 16:37:30 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:30 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:30 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:30 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/16/2025 16:37:30 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/16/2025 16:37:30 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/16/2025 16:37:30 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/16/2025 16:37:30 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 39.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [1.072305679321289, 0.9563326927331778, 0.8792280508921697]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:09<00:00, 12.10it/s]\n",
            "12/16/2025 16:37:39 - INFO - finbert.utils -   *** Example ***\n",
            "12/16/2025 16:37:39 - INFO - finbert.utils -   guid: validation-1\n",
            "12/16/2025 16:37:39 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/16/2025 16:37:39 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:39 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:39 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:39 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/16/2025 16:37:39 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/16/2025 16:37:39 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/16/2025 16:37:39 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/16/2025 16:37:39 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 40.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [1.072305679321289, 0.9563326927331778, 0.8792280508921697, 0.8541812254832342]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 4/4 [00:31<00:00,  7.85s/it]\n"
          ]
        }
      ],
      "source": [
        "start = time.perf_counter()\n",
        "trained_model = finbert.train(train_examples = train_data, model = model)\n",
        "train_wall_s = time.perf_counter() - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/16/2025 16:37:41 - INFO - finbert.utils -   *** Example ***\n",
            "12/16/2025 16:37:41 - INFO - finbert.utils -   guid: test-1\n",
            "12/16/2025 16:37:41 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/16/2025 16:37:41 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:41 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:41 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:41 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/16/2025 16:37:41 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/16/2025 16:37:41 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/16/2025 16:37:41 - INFO - finbert.finbert -     Batch size = 32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/16/2025 16:37:41 - INFO - finbert.finbert -     Num steps = 120\n",
            "12/16/2025 16:37:41 - INFO - finbert.finbert -   ***** Running evaluation ***** \n",
            "12/16/2025 16:37:41 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/16/2025 16:37:41 - INFO - finbert.finbert -     Batch size = 32\n",
            "Testing: 100%|██████████| 31/31 [00:00<00:00, 38.20it/s]\n"
          ]
        }
      ],
      "source": [
        "test_data = finbert.get_data(\"test\")\n",
        "\n",
        "results = finbert.evaluate(examples=test_data, model=trained_model)\n",
        "\n",
        "eval_df, eval_timing = timed_eval(\n",
        "    finbert=finbert, model=trained_model, examples=test_data, use_amp=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "def report(df, cols=['label','prediction','logits']):\n",
        "    #print('Validation loss:{0:.2f}'.format(metrics['best_validation_loss']))\n",
        "    cs = CrossEntropyLoss(weight=finbert.class_weights)\n",
        "    loss = cs(torch.tensor(list(df[cols[2]])),torch.tensor(list(df[cols[0]])))\n",
        "    print(\"Loss:{0:.2f}\".format(loss))\n",
        "    print(\"Accuracy:{0:.2f}\".format((df[cols[0]] == df[cols[1]]).sum() / df.shape[0]) )\n",
        "    print(\"\\nClassification Report:\")\n",
        "    return_val = classification_report(df[cols[0]], df[cols[1]], output_dict=True)\n",
        "    print(return_val)\n",
        "    return_val[\"Loss\"] = loss\n",
        "    return_val[\"Accuracy\"] = (df[cols[0]] == df[cols[1]]).sum() / df.shape[0]\n",
        "    return return_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "results['prediction'] = results.predictions.apply(lambda x: np.argmax(x,axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.88\n",
            "Accuracy:0.64\n",
            "\n",
            "Classification Report:\n",
            "{'0': {'precision': 0.4530386740331492, 'recall': 0.30711610486891383, 'f1-score': 0.36607142857142855, 'support': 267.0}, '1': {'precision': 0.3904761904761905, 'recall': 0.640625, 'f1-score': 0.48520710059171596, 'support': 128.0}, '2': {'precision': 0.7944732297063903, 'recall': 0.8, 'f1-score': 0.7972270363951474, 'support': 575.0}, 'accuracy': 0.643298969072165, 'macro avg': {'precision': 0.5459960314052433, 'recall': 0.582580368289638, 'f1-score': 0.5495018551860973, 'support': 970.0}, 'weighted avg': {'precision': 0.6471797787927605, 'recall': 0.643298969072165, 'f1-score': 0.6373743569397122, 'support': 970.0}}\n"
          ]
        }
      ],
      "source": [
        "wandb_report = report(results,cols=['labels','prediction','predictions'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "teacher_path = project_dir/'models'/'teacher'\n",
        "teacher = AutoModelForSequenceClassification.from_pretrained(\n",
        "    teacher_path, num_labels=3, cache_dir=None\n",
        ")\n",
        "student = trained_model\n",
        "\n",
        "new_path = project_dir/'models'/'distilled_student'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = Config(   data_dir=cl_data_path,\n",
        "                   bert_model=None,\n",
        "                   num_train_epochs=2,\n",
        "                   model_dir=new_path,\n",
        "                   max_seq_length = 48,\n",
        "                   train_batch_size = 32,\n",
        "                   learning_rate = 5e-6,\n",
        "                   output_mode='classification',\n",
        "                   warm_up_proportion=0.1,\n",
        "                   local_rank=-1,\n",
        "                   discriminate=True,\n",
        "                   gradual_unfreeze=True,\n",
        "                   encoder_no = 4,\n",
        "                   base_model='prajjwal1/bert-medium')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "kd = KDFinBert(teacher=teacher, student=student, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "kd.prepare_model(label_list=[\"positive\", \"negative\", \"neutral\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = kd.get_data('train')\n",
        "model = kd.create_the_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/16/2025 16:37:46 - INFO - finbert.utils -   *** Example ***\n",
            "12/16/2025 16:37:46 - INFO - finbert.utils -   guid: train-1\n",
            "12/16/2025 16:37:46 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/16/2025 16:37:46 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:46 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:46 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:37:46 - INFO - finbert.utils -   label: positive (id = 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/16/2025 16:37:46 - INFO - finbert.finbert_kd_trainer -   ***** Loading data *****\n",
            "12/16/2025 16:37:46 - INFO - finbert.finbert_kd_trainer -     Num examples = 3488\n",
            "12/16/2025 16:37:46 - INFO - finbert.finbert_kd_trainer -     Batch size = 32\n",
            "12/16/2025 16:37:46 - INFO - finbert.finbert_kd_trainer -     Num steps = 24\n",
            "/home/srm2245/hpml-project/pipelines/finBERT/notebooks/../finbert/finbert_kd_trainer.py:314: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=self.config.use_amp)\n",
            "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]/home/srm2245/hpml-project/pipelines/finBERT/notebooks/../finbert/finbert_kd_trainer.py:356: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config.use_amp):\n",
            "Iteration:  17%|█▋        | 19/109 [00:03<00:15,  5.84it/s]\n",
            "Epoch:   0%|          | 0/2 [00:03<?, ?it/s]\n",
            "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]/home/srm2245/hpml-project/pipelines/finBERT/notebooks/../finbert/finbert_kd_trainer.py:425: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config.use_amp):\n",
            "Iteration: 100%|██████████| 109/109 [00:17<00:00,  6.09it/s]\n",
            "12/16/2025 16:38:27 - INFO - finbert.utils -   *** Example ***\n",
            "12/16/2025 16:38:27 - INFO - finbert.utils -   guid: validation-1\n",
            "12/16/2025 16:38:27 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/16/2025 16:38:27 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:38:27 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:38:27 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:38:27 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/16/2025 16:38:27 - INFO - finbert.finbert_kd_trainer -   ***** Loading data *****\n",
            "12/16/2025 16:38:27 - INFO - finbert.finbert_kd_trainer -     Num examples = 388\n",
            "12/16/2025 16:38:27 - INFO - finbert.finbert_kd_trainer -     Batch size = 32\n",
            "12/16/2025 16:38:27 - INFO - finbert.finbert_kd_trainer -     Num steps = 24\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 38.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.7298611815159137]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:18<00:00,  5.76it/s]\n",
            "12/16/2025 16:38:46 - INFO - finbert.utils -   *** Example ***\n",
            "12/16/2025 16:38:46 - INFO - finbert.utils -   guid: validation-1\n",
            "12/16/2025 16:38:46 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/16/2025 16:38:46 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:38:46 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:38:46 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:38:46 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/16/2025 16:38:46 - INFO - finbert.finbert_kd_trainer -   ***** Loading data *****\n",
            "12/16/2025 16:38:46 - INFO - finbert.finbert_kd_trainer -     Num examples = 388\n",
            "12/16/2025 16:38:46 - INFO - finbert.finbert_kd_trainer -     Batch size = 32\n",
            "12/16/2025 16:38:46 - INFO - finbert.finbert_kd_trainer -     Num steps = 24\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 37.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.7298611815159137, 0.6765608145640447]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 2/2 [00:38<00:00, 19.15s/it]\n"
          ]
        }
      ],
      "source": [
        "start = time.perf_counter()\n",
        "trained_model = kd.train(train_examples = train_data, teacher=teacher, student=student)\n",
        "train_wall_s = time.perf_counter() - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/16/2025 16:38:48 - INFO - finbert.utils -   *** Example ***\n",
            "12/16/2025 16:38:48 - INFO - finbert.utils -   guid: test-1\n",
            "12/16/2025 16:38:48 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/16/2025 16:38:48 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:38:48 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:38:48 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/16/2025 16:38:48 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/16/2025 16:38:48 - INFO - finbert.finbert_kd_trainer -   ***** Loading data *****\n",
            "12/16/2025 16:38:48 - INFO - finbert.finbert_kd_trainer -     Num examples = 970\n",
            "12/16/2025 16:38:48 - INFO - finbert.finbert_kd_trainer -     Batch size = 32\n",
            "12/16/2025 16:38:48 - INFO - finbert.finbert_kd_trainer -     Num steps = 60\n",
            "12/16/2025 16:38:48 - INFO - finbert.finbert_kd_trainer -   ***** Running evaluation ***** \n",
            "12/16/2025 16:38:48 - INFO - finbert.finbert_kd_trainer -     Num examples = 970\n",
            "12/16/2025 16:38:48 - INFO - finbert.finbert_kd_trainer -     Batch size = 32\n",
            "Testing:   0%|          | 0/31 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing: 100%|██████████| 31/31 [00:00<00:00, 37.46it/s]\n"
          ]
        }
      ],
      "source": [
        "test_data = kd.get_data(\"test\")\n",
        "\n",
        "results = kd.evaluate(examples=test_data, model=trained_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "results['prediction'] = results.predictions.apply(lambda x: np.argmax(x,axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def kd_report(df, cols=['label','prediction','logits']):\n",
        "    #print('Validation loss:{0:.2f}'.format(metrics['best_validation_loss']))\n",
        "    cs = CrossEntropyLoss(weight=finbert.class_weights)\n",
        "    loss = cs(torch.tensor(list(df[cols[2]])),torch.tensor(list(df[cols[0]])))\n",
        "    print(\"Loss:{0:.2f}\".format(loss))\n",
        "    print(\"Accuracy:{0:.2f}\".format((df[cols[0]] == df[cols[1]]).sum() / df.shape[0]) )\n",
        "    print(\"\\nClassification Report:\")\n",
        "    return_val = classification_report(df[cols[0]], df[cols[1]], output_dict=True)\n",
        "    \n",
        "    \n",
        "    new_report = {}\n",
        "    \n",
        "    for key in return_val.keys():\n",
        "        new_report[key + \"_post_kd\"] = return_val[key]\n",
        "    \n",
        "    print(new_report)\n",
        "    new_report[\"Loss_post_kd\"] = loss\n",
        "    new_report[\"Accuracy_post_kd\"] = (df[cols[0]] == df[cols[1]]).sum() / df.shape[0]\n",
        "    return new_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.72\n",
            "Accuracy:0.73\n",
            "\n",
            "Classification Report:\n",
            "{'0': {'precision': 0.6037037037037037, 'recall': 0.6104868913857678, 'f1-score': 0.6070763500931099, 'support': 267.0}, '1': {'precision': 0.5789473684210527, 'recall': 0.7734375, 'f1-score': 0.6622073578595318, 'support': 128.0}, '2': {'precision': 0.8506616257088847, 'recall': 0.782608695652174, 'f1-score': 0.8152173913043478, 'support': 575.0}, 'accuracy': 0.734020618556701, 'macro avg': {'precision': 0.6777708992778804, 'recall': 0.7221776956793139, 'f1-score': 0.6948336997523298, 'support': 970.0}, 'weighted avg': {'precision': 0.7468294709581363, 'recall': 0.734020618556701, 'f1-score': 0.7377339456503922, 'support': 970.0}}\n"
          ]
        }
      ],
      "source": [
        "wandb_kd_report = kd_report(results,cols=['labels','prediction','predictions'])\n",
        "\n",
        "summary = {\n",
        "        \"device\": str(finbert.device),\n",
        "        \"model_dir\": str(cl_path),\n",
        "        \"train_wall_s\": float(train_wall_s),\n",
        "        \"train_examples\": int(len(train_data)),\n",
        "        \"train_examples_per_s\": float((len(train_data) * finbert.config.num_train_epochs) / train_wall_s)\n",
        "        if train_wall_s > 0\n",
        "        else float(\"inf\"),\n",
        "        \"model_size_mb\": float(get_model_size_mb(trained_model)),\n",
        "        \"profile_train_steps\": finbert.config.profile_train_steps,\n",
        "        **(finbert.profile_results.get(\"training_summary\", {}) or {}),\n",
        "        **eval_timing,\n",
        "        **wandb_report,\n",
        "        **wandb_kd_report,\n",
        "    }\n",
        "\n",
        "wandb.log(summary)\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
