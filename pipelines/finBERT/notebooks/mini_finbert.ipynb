{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FinBERT Profiling: Mini FinBert + Knowledge Distillation\n",
        "\n",
        "This notebook is intentionally **thin**: it reuses the profiling utilities in `pipelines/finBERT/finbert/` (especially `finbert/finbert_profile.py` and `finbert/profile_utils.py`) instead of copying large code blocks.\n",
        "\n",
        "The purpose of this notebook is to profile finetuning and distilling a 'mini-bert' model on financial sentiment analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Helper utilities loaded\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import os\n",
        "import logging\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from textblob import TextBlob\n",
        "from pprint import pprint\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "from finbert.finbert import *\n",
        "from finbert.finbert_profile import *\n",
        "from finbert.profile_utils import get_model_size_mb, print_device_info, setup_nltk_data, timed_eval\n",
        "import finbert.utils as tools\n",
        "\n",
        "from finbert.finbert_kd_trainer import KDFinBert\n",
        "\n",
        "\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "project_dir = Path.cwd().parent\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshriya-mahakala\u001b[0m (\u001b[33maqlab\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/srm2245/hpml-project/pipelines/finBERT/notebooks/wandb/run-20251217_030236-nutmbn5f</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/si2449-columbia-university/Project-Runs/runs/nutmbn5f' target=\"_blank\">finetuning/distilling-mini_bert</a></strong> to <a href='https://wandb.ai/si2449-columbia-university/Project-Runs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/si2449-columbia-university/Project-Runs' target=\"_blank\">https://wandb.ai/si2449-columbia-university/Project-Runs</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/si2449-columbia-university/Project-Runs/runs/nutmbn5f' target=\"_blank\">https://wandb.ai/si2449-columbia-university/Project-Runs/runs/nutmbn5f</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/si2449-columbia-university/Project-Runs/runs/nutmbn5f?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fe7ec187f70>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(\n",
        "    entity=\"si2449-columbia-university\",\n",
        "    project=\"Project-Runs\",\n",
        "    name=\"finetuning/distilling-mini_bert\",\n",
        "    group=\"knowledge-distillation\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "cl_path = project_dir/'models'/'student'\n",
        "cl_data_path = project_dir/'data'/'sentiment_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-mini and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    shutil.rmtree(cl_path) \n",
        "except:\n",
        "    pass\n",
        "\n",
        "bertmodel = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-mini\", cache_dir=None, num_labels=3)\n",
        "\n",
        "\n",
        "config = Config(   data_dir=cl_data_path,\n",
        "                   bert_model=bertmodel,\n",
        "                   num_train_epochs=6,\n",
        "                   model_dir=cl_path,\n",
        "                   max_seq_length = 64,\n",
        "                   train_batch_size = 32,\n",
        "                   learning_rate = 0.00001420326287435756,\n",
        "                   output_mode='classification',\n",
        "                   warm_up_proportion=0.14386028719686458,\n",
        "                   local_rank=-1,\n",
        "                   discriminate=True,\n",
        "                   gradual_unfreeze=False,\n",
        "                   encoder_no = 4)\n",
        "\n",
        "config.profile_train_steps = 20\n",
        "config.num_hidden_layers = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "finbert = ProfiledFinBert(config)\n",
        "finbert.config.base_model = 'prajjwal1/bert-mini'\n",
        "finbert.config.discriminate=True\n",
        "finbert.config.gradual_unfreeze=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 03:02:39 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n"
          ]
        }
      ],
      "source": [
        "finbert.prepare_model(label_list=['positive','negative','neutral'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = finbert.get_data('train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = finbert.create_the_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 03:02:42 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 03:02:42 - INFO - finbert.utils -   guid: train-1\n",
            "12/17/2025 03:02:42 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/17/2025 03:02:42 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:02:42 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:02:42 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:02:42 - INFO - finbert.utils -   label: positive (id = 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 03:02:42 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 03:02:42 - INFO - finbert.finbert -     Num examples = 3488\n",
            "12/17/2025 03:02:42 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 03:02:42 - INFO - finbert.finbert -     Num steps = 72\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Starting Profiled Training\n",
            "Device: cuda\n",
            "Profiling activities: [<ProfilerActivity.CPU: 0>, <ProfilerActivity.CUDA: 2>]\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration:  17%|█▋        | 19/109 [00:01<00:04, 18.62it/s]\n",
            "Epoch:   0%|          | 0/6 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Profiling complete for first epoch (20 steps)\n",
            "Continuing full training without profiling...\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "PROFILING RESULTS - Training\n",
            "================================================================================\n",
            "\n",
            "\n",
            "By CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                       cudaLaunchKernel         7.29%      89.383ms        27.72%     339.962ms      45.780us       0.000us         0.00%       8.972ms       1.208us           0 B           0 B           0 B           0 B          7426  \n",
            "                                           forward_pass         3.52%      43.131ms        24.52%     300.788ms      15.039ms       0.000us         0.00%     122.267ms       6.113ms       1.25 KB         -80 B       2.69 GB    -784.43 MB            20  \n",
            "                                          backward_pass        20.70%     253.844ms        23.57%     289.106ms      14.455ms       0.000us         0.00%      48.095us       2.405us      -1.25 KB      -1.25 KB      -1.84 GB      -1.84 GB            20  \n",
            "                       Runtime Triggered Module Loading        22.94%     281.419ms        22.94%     281.419ms       4.264ms       5.882ms         1.29%       5.882ms      89.114us           0 B           0 B           0 B           0 B            66  \n",
            "                                         optimizer_step         1.46%      17.899ms        22.45%     275.372ms      13.769ms       0.000us         0.00%     106.151ms       5.308ms         292 B           0 B    -770.56 MB    -790.00 KB            20  \n",
            "                              Optimizer.step#AdamW.step         4.96%      60.843ms        14.84%     182.000ms       9.100ms       0.000us         0.00%      92.272ms       4.614ms         292 B      -1.09 KB      85.62 MB    -856.18 MB            20  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.84%      10.275ms         8.31%     101.907ms     195.975us       0.000us         0.00%     164.757ms     316.840us           0 B           0 B    -746.09 MB      -2.38 GB           520  \n",
            "                                           aten::linear         0.43%       5.220ms         7.03%      86.187ms     165.744us       0.000us         0.00%      90.140ms     173.346us           0 B           0 B       1.42 GB           0 B           520  \n",
            "                                            aten::addmm         2.34%      28.751ms         5.74%      70.360ms     135.308us      89.316ms        19.52%      90.140ms     173.346us           0 B           0 B       1.42 GB       1.42 GB           520  \n",
            "                                         AddmmBackward0         0.56%       6.819ms         4.98%      61.022ms     117.350us       0.000us         0.00%     151.467ms     291.283us           0 B           0 B       1.65 GB           0 B           520  \n",
            "                                  cudaStreamSynchronize         4.56%      55.971ms         4.56%      55.971ms     349.819us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           160  \n",
            "                                      aten::masked_fill         0.01%     148.581us         4.39%      53.811ms       2.691ms       0.000us         0.00%     186.362us       9.318us           0 B           0 B      10.00 MB           0 B            20  \n",
            "                                     aten::masked_fill_         0.02%     205.929us         4.32%      52.987ms       2.649ms      75.294us         0.02%      90.174us       4.509us           0 B           0 B           0 B           0 B            20  \n",
            "                                       loss_calculation         0.33%       4.077ms         4.01%      49.136ms       2.457ms       0.000us         0.00%     172.344us       8.617us           0 B           0 B      21.00 KB     -19.00 KB            20  \n",
            "                                             aten::item         0.41%       5.073ms         3.79%      46.493ms      15.696us       0.000us         0.00%      65.662us       0.022us           0 B           0 B           0 B           0 B          2962  \n",
            "                              aten::_local_scalar_dense         0.21%       2.546ms         3.38%      41.420ms      13.984us      65.662us         0.01%      65.662us       0.022us           0 B           0 B           0 B           0 B          2962  \n",
            "                                               aten::mm         2.17%      26.594ms         3.34%      40.998ms      39.422us     151.467ms        33.11%     151.467ms     145.642us           0 B           0 B       1.65 GB       1.65 GB          1040  \n",
            "                                               aten::to         0.15%       1.809ms         3.02%      36.991ms      16.715us       0.000us         0.00%     544.109us       0.246us           0 B           0 B      13.47 MB           0 B          2213  \n",
            "                                    aten::_foreach_sqrt         0.47%       5.726ms         2.92%      35.821ms     127.931us       9.899ms         2.16%      10.757ms      38.417us           0 B           0 B     856.18 MB           0 B           280  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...         1.10%      13.520ms         2.89%      35.433ms       1.772ms       0.000us         0.00%       0.000us       0.000us     970.00 KB     -27.26 KB           0 B           0 B            20  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.227s\n",
            "Self CUDA time total: 457.502ms\n",
            "\n",
            "\n",
            "By CUDA Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us     311.167ms        68.01%     311.167ms      15.558ms           0 B           0 B           0 B           0 B            20  \n",
            "                              Optimizer.step#AdamW.step         0.00%       0.000us         0.00%       0.000us       0.000us     173.894ms        38.01%     173.894ms       8.695ms           0 B           0 B           0 B           0 B            20  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.84%      10.275ms         8.31%     101.907ms     195.975us       0.000us         0.00%     164.757ms     316.840us           0 B           0 B    -746.09 MB      -2.38 GB           520  \n",
            "                                         AddmmBackward0         0.56%       6.819ms         4.98%      61.022ms     117.350us       0.000us         0.00%     151.467ms     291.283us           0 B           0 B       1.65 GB           0 B           520  \n",
            "                                               aten::mm         2.17%      26.594ms         3.34%      40.998ms      39.422us     151.467ms        33.11%     151.467ms     145.642us           0 B           0 B       1.65 GB       1.65 GB          1040  \n",
            "                                           forward_pass         3.52%      43.131ms        24.52%     300.788ms      15.039ms       0.000us         0.00%     122.267ms       6.113ms       1.25 KB         -80 B       2.69 GB    -784.43 MB            20  \n",
            "                                         optimizer_step         1.46%      17.899ms        22.45%     275.372ms      13.769ms       0.000us         0.00%     106.151ms       5.308ms         292 B           0 B    -770.56 MB    -790.00 KB            20  \n",
            "                              Optimizer.step#AdamW.step         4.96%      60.843ms        14.84%     182.000ms       9.100ms       0.000us         0.00%      92.272ms       4.614ms         292 B      -1.09 KB      85.62 MB    -856.18 MB            20  \n",
            "                                           aten::linear         0.43%       5.220ms         7.03%      86.187ms     165.744us       0.000us         0.00%      90.140ms     173.346us           0 B           0 B       1.42 GB           0 B           520  \n",
            "                                            aten::addmm         2.34%      28.751ms         5.74%      70.360ms     135.308us      89.316ms        19.52%      90.140ms     173.346us           0 B           0 B       1.42 GB       1.42 GB           520  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      88.686ms        19.38%      88.686ms     184.764us           0 B           0 B           0 B           0 B           480  \n",
            "                                         optimizer_step         0.00%       0.000us         0.00%       0.000us       0.000us      87.029ms        19.02%      87.029ms       4.351ms           0 B           0 B           0 B           0 B            20  \n",
            "                                  volta_sgemm_128x64_nt         0.00%       0.000us         0.00%       0.000us       0.000us      70.089ms        15.32%      70.089ms     146.019us           0 B           0 B           0 B           0 B           480  \n",
            "                                  volta_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us      49.385ms        10.79%      49.385ms     308.658us           0 B           0 B           0 B           0 B           160  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.14%       1.702ms         2.27%      27.856ms     348.202us       0.000us         0.00%      33.683ms     421.037us      -1.25 KB      -1.25 KB    -332.50 MB    -812.50 MB            80  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.06%     730.985us         2.13%      26.154ms     326.922us       0.000us         0.00%      33.683ms     421.037us           0 B           0 B     480.00 MB           0 B            80  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.14%       1.667ms         2.07%      25.423ms     317.785us       0.000us         0.00%      33.683ms     421.037us           0 B           0 B     480.00 MB           0 B            80  \n",
            "                    aten::_efficient_attention_backward         0.25%       3.021ms         1.72%      21.154ms     264.420us      29.577ms         6.46%      33.683ms     421.037us           0 B           0 B     480.00 MB    -325.16 MB            80  \n",
            "fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm75(PyT...         0.00%       0.000us         0.00%       0.000us       0.000us      29.577ms         6.46%      29.577ms     369.716us           0 B           0 B           0 B           0 B            80  \n",
            "                                 volta_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us      28.815ms         6.30%      28.815ms      90.046us           0 B           0 B           0 B           0 B           320  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.227s\n",
            "Self CUDA time total: 457.502ms\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "⚠ Failed to log profiler table: 'FunctionEventAvg' object has no attribute 'cuda_time_total'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:02<00:00, 43.88it/s]\n",
            "12/17/2025 03:03:02 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 03:03:02 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 03:03:02 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 03:03:02 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:02 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:02 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:02 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 03:03:02 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 03:03:02 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 03:03:02 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 03:03:02 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 176.34it/s]\n",
            "Epoch:  17%|█▋        | 1/6 [00:02<00:13,  2.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [1.0473814927614653]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:02<00:00, 44.75it/s]\n",
            "12/17/2025 03:03:05 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 03:03:05 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 03:03:05 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 03:03:05 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:05 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:05 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:05 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 03:03:05 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 03:03:05 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 03:03:05 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 03:03:05 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 183.46it/s]\n",
            "Epoch:  33%|███▎      | 2/6 [00:05<00:10,  2.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [1.0473814927614653, 0.9731460855557368]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:02<00:00, 45.27it/s]\n",
            "12/17/2025 03:03:07 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 03:03:07 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 03:03:07 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 03:03:07 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:07 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:07 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:07 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 03:03:07 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 03:03:07 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 03:03:07 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 03:03:07 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 179.09it/s]\n",
            "Epoch:  50%|█████     | 3/6 [00:08<00:08,  2.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [1.0473814927614653, 0.9731460855557368, 0.9198884413792536]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:02<00:00, 45.57it/s]\n",
            "12/17/2025 03:03:10 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 03:03:10 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 03:03:10 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 03:03:10 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:10 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:10 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:10 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 03:03:10 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 03:03:10 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 03:03:10 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 03:03:10 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 187.05it/s]\n",
            "Epoch:  67%|██████▋   | 4/6 [00:10<00:05,  2.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [1.0473814927614653, 0.9731460855557368, 0.9198884413792536, 0.8852779039969811]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:02<00:00, 45.44it/s]\n",
            "12/17/2025 03:03:13 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 03:03:13 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 03:03:13 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 03:03:13 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:13 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:13 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:13 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 03:03:13 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 03:03:13 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 03:03:13 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 03:03:13 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 183.87it/s]\n",
            "Epoch:  83%|████████▎ | 5/6 [00:13<00:02,  2.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [1.0473814927614653, 0.9731460855557368, 0.9198884413792536, 0.8852779039969811, 0.8637106602008526]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:02<00:00, 45.27it/s]\n",
            "12/17/2025 03:03:15 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 03:03:15 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 03:03:15 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 03:03:15 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:15 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:15 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:15 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 03:03:15 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 03:03:15 - INFO - finbert.finbert -     Num examples = 388\n",
            "12/17/2025 03:03:15 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 03:03:15 - INFO - finbert.finbert -     Num steps = 72\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 175.16it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:16<00:00,  2.67s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [1.0473814927614653, 0.9731460855557368, 0.9198884413792536, 0.8852779039969811, 0.8637106602008526, 0.8555622054980352]\n"
          ]
        }
      ],
      "source": [
        "start = time.perf_counter()\n",
        "trained_model = finbert.train(train_examples = train_data, model = model)\n",
        "train_wall_s = time.perf_counter() - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 03:03:16 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 03:03:16 - INFO - finbert.utils -   guid: test-1\n",
            "12/17/2025 03:03:16 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/17/2025 03:03:16 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:16 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:16 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:16 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/17/2025 03:03:16 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 03:03:16 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/17/2025 03:03:16 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 03:03:16 - INFO - finbert.finbert -     Num steps = 180\n",
            "12/17/2025 03:03:16 - INFO - finbert.finbert -   ***** Running evaluation ***** \n",
            "12/17/2025 03:03:16 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/17/2025 03:03:16 - INFO - finbert.finbert -     Batch size = 32\n",
            "Testing:   0%|          | 0/31 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing: 100%|██████████| 31/31 [00:00<00:00, 151.65it/s]\n",
            "12/17/2025 03:03:16 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 03:03:16 - INFO - finbert.utils -   guid: test-1\n",
            "12/17/2025 03:03:16 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/17/2025 03:03:16 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:16 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:16 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:16 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/17/2025 03:03:16 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "12/17/2025 03:03:16 - INFO - finbert.finbert -     Num examples = 970\n",
            "12/17/2025 03:03:16 - INFO - finbert.finbert -     Batch size = 32\n",
            "12/17/2025 03:03:16 - INFO - finbert.finbert -     Num steps = 180\n"
          ]
        }
      ],
      "source": [
        "test_data = finbert.get_data(\"test\")\n",
        "\n",
        "results = finbert.evaluate(examples=test_data, model=trained_model)\n",
        "\n",
        "eval_df, eval_timing = timed_eval(\n",
        "    finbert=finbert, model=trained_model, examples=test_data, use_amp=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def report(df, cols=['label','prediction','logits']):\n",
        "    #print('Validation loss:{0:.2f}'.format(metrics['best_validation_loss']))\n",
        "    cs = CrossEntropyLoss(weight=finbert.class_weights)\n",
        "    loss = cs(torch.tensor(list(df[cols[2]])),torch.tensor(list(df[cols[0]])))\n",
        "    print(\"Evaluation Loss:{0:.2f}\".format(loss))\n",
        "    print(\"Evaluation Accuracy:{0:.2f}\".format((df[cols[0]] == df[cols[1]]).sum() / df.shape[0]) )\n",
        "    print(\"\\nClassification Report:\")\n",
        "    return_val = classification_report(df[cols[0]], df[cols[1]], output_dict=True)\n",
        "    \n",
        "    \n",
        "    new_report = {}\n",
        "    \n",
        "    for key in return_val.keys():\n",
        "        new_report[\"Finetuning \" + key] = return_val[key]\n",
        "    \n",
        "    new_report[\"Finetuning Evalaution Loss\"] = loss\n",
        "    new_report[\"Fintuning Evaluation Accuracy\"] = (df[cols[0]] == df[cols[1]]).sum() / df.shape[0]\n",
        "    \n",
        "    \n",
        "    print(new_report)\n",
        "        \n",
        "    return new_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "results['prediction'] = results.predictions.apply(lambda x: np.argmax(x,axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Loss:0.89\n",
            "Evaluation Accuracy:0.64\n",
            "\n",
            "Classification Report:\n",
            "{'Finetuning 0': {'precision': 0.4666666666666667, 'recall': 0.26217228464419473, 'f1-score': 0.33573141486810554, 'support': 267.0}, 'Finetuning 1': {'precision': 0.3835616438356164, 'recall': 0.65625, 'f1-score': 0.484149855907781, 'support': 128.0}, 'Finetuning 2': {'precision': 0.778702163061564, 'recall': 0.8139130434782609, 'f1-score': 0.7959183673469388, 'support': 575.0}, 'Finetuning accuracy': 0.6412371134020619, 'Finetuning macro avg': {'precision': 0.5429768245212824, 'recall': 0.5774451093741518, 'f1-score': 0.5385998793742751, 'support': 970.0}, 'Finetuning weighted avg': {'precision': 0.6406697259498538, 'recall': 0.6412371134020619, 'f1-score': 0.6281077634540928, 'support': 970.0}, 'Finetuning Evalaution Loss': tensor(0.8872), 'Fintuning Evaluation Accuracy': np.float64(0.6412371134020619)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/tmp/ipykernel_173151/142971867.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  loss = cs(torch.tensor(list(df[cols[2]])),torch.tensor(list(df[cols[0]])))\n"
          ]
        }
      ],
      "source": [
        "wandb_report = report(results,cols=['labels','prediction','predictions'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "teacher_path = project_dir/'models'/'teacher'\n",
        "teacher = AutoModelForSequenceClassification.from_pretrained(\n",
        "    teacher_path, num_labels=3, cache_dir=None\n",
        ")\n",
        "student = trained_model\n",
        "\n",
        "new_path = project_dir/'models'/'distilled_student'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = Config(   data_dir=cl_data_path,\n",
        "                   bert_model=None,\n",
        "                   num_train_epochs=2,\n",
        "                   model_dir=new_path,\n",
        "                   max_seq_length = 48,\n",
        "                   train_batch_size = 32,\n",
        "                   learning_rate = 5e-6,\n",
        "                   output_mode='classification',\n",
        "                   warm_up_proportion=0.1,\n",
        "                   local_rank=-1,\n",
        "                   discriminate=True,\n",
        "                   gradual_unfreeze=True,\n",
        "                   encoder_no = 4,\n",
        "                   base_model='prajjwal1/bert-mini')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "kd = KDFinBert(teacher=teacher, student=student, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "kd.prepare_model(label_list=[\"positive\", \"negative\", \"neutral\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = kd.get_data('train')\n",
        "model = kd.create_the_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 03:03:21 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 03:03:21 - INFO - finbert.utils -   guid: train-1\n",
            "12/17/2025 03:03:21 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "12/17/2025 03:03:21 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:21 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:21 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:21 - INFO - finbert.utils -   label: positive (id = 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 03:03:21 - INFO - finbert.finbert_kd_trainer -   ***** Loading data *****\n",
            "12/17/2025 03:03:21 - INFO - finbert.finbert_kd_trainer -     Num examples = 3488\n",
            "12/17/2025 03:03:21 - INFO - finbert.finbert_kd_trainer -     Batch size = 32\n",
            "12/17/2025 03:03:21 - INFO - finbert.finbert_kd_trainer -     Num steps = 24\n",
            "/home/srm2245/hpml-project/pipelines/finBERT/notebooks/../finbert/finbert_kd_trainer.py:314: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=self.config.use_amp)\n",
            "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]/home/srm2245/hpml-project/pipelines/finBERT/notebooks/../finbert/finbert_kd_trainer.py:356: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config.use_amp):\n",
            "Iteration:  17%|█▋        | 19/109 [00:02<00:09,  9.28it/s]\n",
            "Epoch:   0%|          | 0/2 [00:02<?, ?it/s]\n",
            "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]/home/srm2245/hpml-project/pipelines/finBERT/notebooks/../finbert/finbert_kd_trainer.py:425: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.config.use_amp):\n",
            "Iteration: 100%|██████████| 109/109 [00:10<00:00, 10.15it/s]\n",
            "12/17/2025 03:03:48 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 03:03:48 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 03:03:48 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 03:03:48 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:48 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:48 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:03:48 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 03:03:49 - INFO - finbert.finbert_kd_trainer -   ***** Loading data *****\n",
            "12/17/2025 03:03:49 - INFO - finbert.finbert_kd_trainer -     Num examples = 388\n",
            "12/17/2025 03:03:49 - INFO - finbert.finbert_kd_trainer -     Batch size = 32\n",
            "12/17/2025 03:03:49 - INFO - finbert.finbert_kd_trainer -     Num steps = 24\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 200.75it/s]\n",
            "Epoch:  50%|█████     | 1/2 [00:10<00:10, 10.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.8395374967501714]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:11<00:00,  9.81it/s]\n",
            "12/17/2025 03:04:00 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 03:04:00 - INFO - finbert.utils -   guid: validation-1\n",
            "12/17/2025 03:04:00 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "12/17/2025 03:04:00 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:04:00 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:04:00 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:04:00 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "12/17/2025 03:04:00 - INFO - finbert.finbert_kd_trainer -   ***** Loading data *****\n",
            "12/17/2025 03:04:00 - INFO - finbert.finbert_kd_trainer -     Num examples = 388\n",
            "12/17/2025 03:04:00 - INFO - finbert.finbert_kd_trainer -     Batch size = 32\n",
            "12/17/2025 03:04:00 - INFO - finbert.finbert_kd_trainer -     Num steps = 24\n",
            "Validating: 100%|██████████| 13/13 [00:00<00:00, 194.76it/s]\n",
            "Epoch: 100%|██████████| 2/2 [00:22<00:00, 11.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.8395374967501714, 0.8252754394824688]\n"
          ]
        }
      ],
      "source": [
        "start = time.perf_counter()\n",
        "trained_model = kd.train(train_examples = train_data, teacher=teacher, student=student)\n",
        "train_wall_s = time.perf_counter() - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 03:04:01 - INFO - finbert.utils -   *** Example ***\n",
            "12/17/2025 03:04:01 - INFO - finbert.utils -   guid: test-1\n",
            "12/17/2025 03:04:01 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "12/17/2025 03:04:01 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:04:01 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:04:01 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/17/2025 03:04:01 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "12/17/2025 03:04:01 - INFO - finbert.finbert_kd_trainer -   ***** Loading data *****\n",
            "12/17/2025 03:04:01 - INFO - finbert.finbert_kd_trainer -     Num examples = 970\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12/17/2025 03:04:01 - INFO - finbert.finbert_kd_trainer -     Batch size = 32\n",
            "12/17/2025 03:04:01 - INFO - finbert.finbert_kd_trainer -     Num steps = 60\n",
            "12/17/2025 03:04:01 - INFO - finbert.finbert_kd_trainer -   ***** Running evaluation ***** \n",
            "12/17/2025 03:04:01 - INFO - finbert.finbert_kd_trainer -     Num examples = 970\n",
            "12/17/2025 03:04:01 - INFO - finbert.finbert_kd_trainer -     Batch size = 32\n",
            "Testing: 100%|██████████| 31/31 [00:00<00:00, 178.27it/s]\n"
          ]
        }
      ],
      "source": [
        "test_data = kd.get_data(\"test\")\n",
        "\n",
        "results = kd.evaluate(examples=test_data, model=trained_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "results['prediction'] = results.predictions.apply(lambda x: np.argmax(x,axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def kd_report(df, cols=['label','prediction','logits']):\n",
        "    #print('Validation loss:{0:.2f}'.format(metrics['best_validation_loss']))\n",
        "    cs = CrossEntropyLoss(weight=finbert.class_weights)\n",
        "    loss = cs(torch.tensor(list(df[cols[2]])),torch.tensor(list(df[cols[0]])))\n",
        "    print(\"Loss:{0:.2f}\".format(loss))\n",
        "    print(\"Accuracy:{0:.2f}\".format((df[cols[0]] == df[cols[1]]).sum() / df.shape[0]) )\n",
        "    print(\"\\nClassification Report:\")\n",
        "    return_val = classification_report(df[cols[0]], df[cols[1]], output_dict=True)\n",
        "    \n",
        "    return_val[\"Evaluation Loss\"] = loss\n",
        "    return_val[\"Evaluation Accuracy\"] = (df[cols[0]] == df[cols[1]]).sum() / df.shape[0]\n",
        "    return return_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.86\n",
            "Accuracy:0.69\n",
            "\n",
            "Classification Report:\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Evaluation Accuracy</td><td>▁</td></tr><tr><td>Evaluation Loss</td><td>▁</td></tr><tr><td>Finetuning Evalaution Loss</td><td>▁</td></tr><tr><td>Finetuning accuracy</td><td>▁</td></tr><tr><td>Fintuning Evaluation Accuracy</td><td>▁</td></tr><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▂▂▂▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇██████</td></tr><tr><td>eval_num_samples</td><td>▁</td></tr><tr><td>eval_samples_per_s</td><td>▁</td></tr><tr><td>eval_wall_s</td><td>▁</td></tr><tr><td>+14</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Evaluation Accuracy</td><td>0.69278</td></tr><tr><td>Evaluation Loss</td><td>0.86448</td></tr><tr><td>Finetuning Evalaution Loss</td><td>0.88721</td></tr><tr><td>Finetuning accuracy</td><td>0.64124</td></tr><tr><td>Fintuning Evaluation Accuracy</td><td>0.64124</td></tr><tr><td>accuracy</td><td>0.69278</td></tr><tr><td>device</td><td>cuda</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>eval_num_samples</td><td>970</td></tr><tr><td>eval_samples_per_s</td><td>5427.78828</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">finetuning/distilling-mini_bert</strong> at: <a href='https://wandb.ai/si2449-columbia-university/Project-Runs/runs/nutmbn5f' target=\"_blank\">https://wandb.ai/si2449-columbia-university/Project-Runs/runs/nutmbn5f</a><br> View project at: <a href='https://wandb.ai/si2449-columbia-university/Project-Runs' target=\"_blank\">https://wandb.ai/si2449-columbia-university/Project-Runs</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251217_030236-nutmbn5f/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb_kd_report = kd_report(results,cols=['labels','prediction','predictions'])\n",
        "\n",
        "summary = {\n",
        "        \"device\": str(finbert.device),\n",
        "        \"model_dir\": str(cl_path),\n",
        "        \"train_wall_s\": float(train_wall_s),\n",
        "        \"train_examples\": int(len(train_data)),\n",
        "        \"train_examples_per_s\": float((len(train_data) * finbert.config.num_train_epochs) / train_wall_s)\n",
        "        if train_wall_s > 0\n",
        "        else float(\"inf\"),\n",
        "        \"model_size_mb\": float(get_model_size_mb(trained_model)),\n",
        "        \"profile_train_steps\": finbert.config.profile_train_steps,\n",
        "        **(finbert.profile_results.get(\"training_summary\", {}) or {}),\n",
        "        **eval_timing,\n",
        "        **wandb_report,\n",
        "        **wandb_kd_report,\n",
        "    }\n",
        "\n",
        "wandb.log(summary)\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
